{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971e3324",
   "metadata": {},
   "source": [
    "# Part II: Approach A - Classification with Preextracted DinoV2 Features\n",
    "## Feature Extraction Using DinoV2\n",
    "- Input to DinoV2: Ensure that the images you feed into the DinoV2 model\n",
    "for feature extraction have undergone the full pre-processing pipeline\n",
    "defined in Part I (resizing to 224x224 with aspect-ratio-preserving padding,\n",
    "conversion to tensor, and ImageNet normalization). This is crucial because\n",
    "the DinoV2 model expects its input in this specific format.\n",
    "- Batch Processing: Feature extraction can be time-consuming if done\n",
    "image by image. It's much more efficient to process images in batches.\n",
    "Your feature extraction script should ideally load images using a the\n",
    "custom Dataset you have implemented and PyTorch DataLoader and pass\n",
    "batches of pre-processed images to the DinoV2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3841b1a4",
   "metadata": {},
   "source": [
    "We start by preparing our data from our autocontained method. We use batch sampling of size 64 for efficiency and break correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20509b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/bwhpc/common/jupyter/ai/2025-02-20/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data6/home/tu/tu_tu/tu_zxoxe46/Practical Deep Learning/Assignment 2\n"
     ]
    }
   ],
   "source": [
    "%cd \"yourpath\"\n",
    "from load_transform import load_data\n",
    "\n",
    "train_loader, val_loader, test_loader, label_to_idx = load_data(batch_size=64, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830085f",
   "metadata": {},
   "source": [
    "Inspect the datasets and first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ce4d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10821\n",
      "2706\n",
      "3382\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# See if all the elements are loaded correctly\n",
    "print(len(train_loader.dataset))\n",
    "print(len(val_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "print(len(label_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3778fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "tensor(-2.1179) tensor(2.6400)\n",
      "tensor(0.3512) tensor(1.9591)\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch from the train_loader\n",
    "batch_data, _ = next(iter(train_loader))\n",
    "print(batch_data.shape)\n",
    "print(type(batch_data))\n",
    "print(batch_data.dtype)\n",
    "print(batch_data.min(), batch_data.max())\n",
    "print(batch_data.mean(), batch_data.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc2e43",
   "metadata": {},
   "source": [
    "- Utilizing the Provided Snippet: You are provided with a code snippet (or\n",
    "you can find examples online using the official DinoV2 repository that loads\n",
    "a pre-trained DinoV2 model and uses it to extract features.\n",
    "- Obtaining Features: The DinoV2 model, when used as a feature extractor,\n",
    "will output a feature vector for each image.\n",
    "- Storage Strategy: Once you extract the feature vectors for all images in\n",
    "your training, validation, and test sets, you need to save them to disk. This\n",
    "is because feature extraction is computationally intensive, and you don't\n",
    "want to repeat it every time you train your downstream classifier.\n",
    "    1. Common strategies include saving them as:\n",
    "    2. .npy files (using numpy.save): You could save all training features in one\n",
    "    large NumPy array, and similarly for validation and test sets. You'd also\n",
    "    need to save the corresponding labels separately.\n",
    "    3. .pt files (using torch.save): You could save lists of tensors, or\n",
    "    dictionaries mapping image identifiers to their feature tensors.\n",
    "    4. A separate file per image: Less common for this scale, but possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1887970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tu/tu_tu/tu_zxoxe46/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/tu/tu_tu/tu_zxoxe46/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/tu/tu_tu/tu_zxoxe46/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/tu/tu_tu/tu_zxoxe46/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Load the DINOv2 model\n",
    "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dinov2_vits14.to(device).eval()\n",
    "# Batch inference\n",
    "all_train_feats = []\n",
    "all_train_ids   = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        feats  = dinov2_vits14(images)\n",
    "        all_train_feats.append(feats.cpu())\n",
    "        all_train_ids.extend(labels.numpy())\n",
    "# Save the features and labels\n",
    "torch.save({\n",
    "    \"features\": torch.cat(all_train_feats, dim=0),\n",
    "    \"labels\":   torch.tensor(all_train_ids)\n",
    "}, \"train_dinov2_feats.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b61c9d",
   "metadata": {},
   "source": [
    "- Report the dimensionality (i.e., the length of the vector) of the extracted\n",
    "DinoV2 features. This will be the input size for your MLP in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecdc2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tu/tu_tu/tu_zxoxe46/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "images_batch = batch_data.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "dinov2_vits14 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\").to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    feats = dinov2_vits14(images_batch)\n",
    "print(feats.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4977c",
   "metadata": {},
   "source": [
    "For more robustness and to save our time from extra debugging we register metadata, a smoke test and helper funcions to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa2c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation k-NN top-1 accuracy: 0.5920\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "# Helper to reload features\n",
    "def load_features(split: str):\n",
    "    \"\"\"\n",
    "    Return (X, y) for split in ['train','val','test'].\n",
    "    \"\"\"\n",
    "    path = f\"{split}_dinov2_feats.pt\"\n",
    "    data = torch.load(path)\n",
    "    X = data[\"features\"]\n",
    "    y = data.get(\"labels\", None)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Register metadata\n",
    "metadata = {\n",
    "    \"model\":       \"dinov2_vits14\",\n",
    "    \"feature_dim\": 384,\n",
    "    \"script\":      \"Assignment2_Part2.ipynb\",\n",
    "    \"date\":        __import__(\"datetime\").datetime.utcnow().isoformat() + \"Z\"\n",
    "}\n",
    "with open(\"dinov2_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# k-NN smoke test on validation set\n",
    "X_train, y_train = load_features(\"train\")\n",
    "X_train = X_train.numpy()\n",
    "y_train = y_train.numpy()\n",
    "\n",
    "all_val_feats = []\n",
    "all_val_ids   = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        feats  = dinov2_vits14(images)\n",
    "        all_val_feats.append(feats.cpu())\n",
    "        all_val_ids.extend(labels.numpy())\n",
    "\n",
    "torch.save({\n",
    "    \"features\": torch.cat(all_val_feats, dim=0),\n",
    "    \"labels\":   torch.tensor(all_val_ids)\n",
    "}, \"val_dinov2_feats.pt\")\n",
    "\n",
    "X_val, y_val = load_features(\"val\")\n",
    "X_val = X_val.numpy()\n",
    "y_val = y_val.numpy()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)               # train k-NN\n",
    "acc = knn.score(X_val, y_val)           # compute accuracy\n",
    "print(f\"Validation k-NN top-1 accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a2635",
   "metadata": {},
   "source": [
    "## Training and Hyper-parameters \n",
    "- Define your MLP model architecture using torch.nn.Module.\n",
    "- Clearly state your initial choices for the number of hidden layers and\n",
    "neurons per layer (you will tune these later)\n",
    "\n",
    "We do a initial configuration for the first try that aims to be as parsimonious as possible. It consists of a relatively small neural network that passes the vector of size 384 that Dino V2 provides us through a hidden layer for the final output that includes the number of classes. We run it for few epochs to test the architecture and prepare for further steps of hyperparameter tuning\n",
    "\n",
    "Initial Hyperparameters:\n",
    "- Activation fx: ReLU\n",
    "- Optimizer: Adam\n",
    "- LR: 1*10^-3\n",
    "- LR Scheduler?: None\n",
    "- Batch Size: 64\n",
    "- Epochs: 100 (early stopping, patience = 5)\n",
    "- Hidden layers: (256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32094321",
   "metadata": {},
   "source": [
    "## Early Stopping - Learning Rate Scheduling\n",
    "\n",
    "In addition we add the rest of the model features specified in the instructions.\n",
    "- Implement early stopping in your training loop. Explain your chosen\n",
    "patience value and how you track the \"best model\" weights.\n",
    "    - We set a initial patience of 5 such that after 5 epochs not getting better, we stop. We can change this later\n",
    "- Learning rate scheduling/ Decay\n",
    "    - We don't use it now because we need a lot of epochs for this to show (and set some hyperparameters beforehand) and in this short example it's not enough\n",
    "    - We will try for our parameter search the CosineAnnealing method from the torch packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class HyperConfig:\n",
    "    # hyperparameters\n",
    "    batch_size:     int          = 64\n",
    "    learning_rate:  float        = 1e-3\n",
    "    hidden_width:   int          = 256\n",
    "    num_layers:     int          = 1\n",
    "    epochs:         int          = 100\n",
    "    patience:       int          = 10\n",
    "    # Parameters\n",
    "    input_dim:      int          = 384\n",
    "    num_classes:    int          = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1974964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 | val_loss 1.0923 | val_acc 0.5939\n",
      "epoch 002 | val_loss 1.0653 | val_acc 0.6094\n",
      "epoch 003 | val_loss 1.0603 | val_acc 0.6050\n",
      "epoch 004 | val_loss 1.0283 | val_acc 0.6205\n",
      "epoch 005 | val_loss 1.0620 | val_acc 0.6120\n",
      "epoch 006 | val_loss 1.0219 | val_acc 0.6286\n",
      "epoch 007 | val_loss 1.0427 | val_acc 0.6245\n",
      "epoch 008 | val_loss 1.0697 | val_acc 0.6201\n",
      "epoch 009 | val_loss 1.0920 | val_acc 0.6160\n",
      "epoch 010 | val_loss 1.1113 | val_acc 0.5983\n",
      "epoch 011 | val_loss 1.0763 | val_acc 0.6260\n",
      "epoch 012 | val_loss 1.1483 | val_acc 0.6061\n",
      "epoch 013 | val_loss 1.1571 | val_acc 0.5998\n",
      "epoch 014 | val_loss 1.1557 | val_acc 0.6256\n",
      "epoch 015 | val_loss 1.1729 | val_acc 0.6197\n",
      "epoch 016 | val_loss 1.2764 | val_acc 0.5887\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load features\n",
    "train_data = torch.load(\"train_dinov2_feats.pt\")\n",
    "val_data   = torch.load(\"val_dinov2_feats.pt\")\n",
    "\n",
    "train_ds = TensorDataset(train_data[\"features\"], train_data[\"labels\"])\n",
    "val_ds   = TensorDataset(val_data[\"features\"],   val_data[\"labels\"])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=HyperConfig.batch_size,\n",
    "                          shuffle=True, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=HyperConfig.batch_size,\n",
    "                          shuffle=False, pin_memory=True)\n",
    "\n",
    "# MLP definition\n",
    "class DressMLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 hidden_width: int,\n",
    "                 num_layers: int,\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "        layers, prev = [], in_dim\n",
    "        for _ in range(num_layers):\n",
    "            layers += [nn.Linear(prev, hidden_width), nn.ReLU(inplace=True)]\n",
    "            prev = hidden_width\n",
    "        layers.append(nn.Linear(prev, n_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = DressMLP(HyperConfig.input_dim, HyperConfig.hidden_width, HyperConfig.num_layers, HyperConfig.num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=HyperConfig.learning_rate)\n",
    "\n",
    "# train loop\n",
    "best_val_loss, patience_ctr = float(\"inf\"), 0\n",
    "for epoch in range(1, HyperConfig.epochs + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(X), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validate\n",
    "    model.eval()\n",
    "    val_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            val_loss += criterion(logits, y).item() * X.size(0)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc   = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"epoch {epoch:03d} | val_loss {val_loss:.4f} | val_acc {val_acc:.4f}\")\n",
    "\n",
    "    # early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= HyperConfig.patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e5cca",
   "metadata": {},
   "source": [
    "In this very short test run we get an accuracy slightly higher than with knn, but knowing the short computation time that we set for this test it's reasonable. The next step is to find a way to find the perfect hyperparameters in the most efficient way possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308922c8",
   "metadata": {},
   "source": [
    "## Dealing with Computational Constraints \n",
    "Guided Search Strategy:\n",
    "1. Initial LR & Architecture Scan: Start by fixing a batch size (e.g., 64) and\n",
    "optimizer (e.g., Adam). Run short training sessions (e.g., few epochs, or\n",
    "until early stopping triggers quickly) to find a promising range for the\n",
    "Learning Rate and a basic MLP architecture (e.g., 1 hidden layer with 256\n",
    "neurons).\n",
    "2. Refine Architecture: With a good LR, try varying the number of hidden\n",
    "layers and neurons.\n",
    "3. Test Batch Size: With a good LR and architecture, see if changing the\n",
    "batch size (e.g., to 128) offers benefits.\n",
    "4. Introduce LR Scheduler: Apply your chosen LR scheduler to your best\n",
    "configuration so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8decf",
   "metadata": {},
   "source": [
    "For a cleaner code, we implement the \"official\" classes that we wrap into each other to carry out hyperparameter search and training. We redefine also a cleaner class for the MLP model. This gives us:\n",
    "- DressMLP: The model itself\n",
    "- Trainer: We encapsulate the training loop here\n",
    "- HyperParameter Searcher: We use ASHA in this case, following the guided search strategy specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3230a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:14:19.971495: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-14 16:14:23.273291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749910464.419113  621261 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749910464.836357  621261 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-14 16:14:27.600653: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports/Utilities\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "\n",
    "# reproducibility\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d64ce",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a78274ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "@dataclass\n",
    "class HyperConfig:\n",
    "    # search spaces\n",
    "    lr_range: Tuple[float, float] = (1e-4, 1e-2)\n",
    "    hidden_choices: List[int] = field(default_factory=lambda: [128, 256, 384, 512, 768])\n",
    "    layer_choices:  List[int] = field(default_factory=lambda: [1, 2, 3])\n",
    "    batch_choices:  List[int] = field(default_factory=lambda: [32, 64, 128])\n",
    "    sched_choices:  List[bool] = field(default_factory=lambda: [False, True])\n",
    "\n",
    "    # global training constants\n",
    "    seed: int = 42\n",
    "    epochs:   int = 100\n",
    "    patience: int = 10\n",
    "    input_dim: int = 384\n",
    "    num_classes: int = 10\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Defaults for one run\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 1e-3\n",
    "    hidden_width: int = 256\n",
    "    num_layers: int = 1\n",
    "    use_scheduler: bool = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DressMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: Tuple[int, ...], num_classes: int, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        in_d = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(in_d, h, bias=False))\n",
    "            layers.append(nn.BatchNorm1d(h, momentum=0.01))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_d = h\n",
    "        layers.append(nn.Linear(in_d, num_classes))  # logits\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e78ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        run_dir: Path,\n",
    "        *,\n",
    "        learning_rate: float = HyperConfig.learning_rate,\n",
    "        epochs: int = HyperConfig.epochs,\n",
    "        patience: int = HyperConfig.patience,\n",
    "        use_scheduler: bool = HyperConfig.use_scheduler,\n",
    "        device: str | torch.device = HyperConfig.device,\n",
    "    ) -> None:\n",
    "        self.device = torch.device(device) if isinstance(device, str) else device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        self.scheduler = (\n",
    "            optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=epochs)\n",
    "            if use_scheduler\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.writer = SummaryWriter(log_dir=run_dir)\n",
    "        self.csv_path = run_dir / \"metrics.csv\"\n",
    "        self.csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(self.csv_path, \"w\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"lr\"])\n",
    "\n",
    "    def _run_epoch(self) -> Tuple[float, float]:\n",
    "        self.model.train()\n",
    "        losses, correct, total = 0.0, 0, 0\n",
    "        for X, y in self.train_loader:\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(X)\n",
    "            loss = self.criterion(logits, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses += loss.item() * X.size(0)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            total += X.size(0)\n",
    "        return losses / total, correct / total\n",
    "\n",
    "    def _validate(self) -> Tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        losses, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                logits = self.model(X)\n",
    "                losses += self.criterion(logits, y).item() * X.size(0)\n",
    "                correct += (logits.argmax(1) == y).sum().item()\n",
    "                total += X.size(0)\n",
    "        return losses / total, correct / total\n",
    "\n",
    "    def train(self, trial: optuna.Trial | None = None) -> dict:\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_ctr = 0\n",
    "        best_state: dict | None = None\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            start_t = time.time()\n",
    "            train_loss, train_acc = self._run_epoch()\n",
    "            val_loss, val_acc = self._validate()\n",
    "\n",
    "            # Pruning\n",
    "            if trial is not None:\n",
    "                trial.report(val_loss, step=epoch)\n",
    "                if trial.should_prune():\n",
    "                    print(f\"Trial pruned at epoch {epoch}\")\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()  # step per epoch\n",
    "\n",
    "            lr_now = self.optimizer.param_groups[0][\"lr\"]\n",
    "            self.writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
    "            self.writer.add_scalars(\"Accuracy\", {\"train\": train_acc, \"val\": val_acc}, epoch)\n",
    "            self.writer.add_scalar(\"LR\", lr_now, epoch)\n",
    "\n",
    "            # CSV\n",
    "            with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([epoch, train_loss, train_acc, val_loss, val_acc, lr_now])\n",
    "\n",
    "            print(\n",
    "                f\"epoch {epoch:03d} | \"\n",
    "                f\"train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | \"\n",
    "                f\"train_acc {train_acc:.4f} | val_acc {val_acc:.4f} | \"\n",
    "                f\"lr {lr_now:.2e} | {time.time() - start_t:.1f}s\"\n",
    "            )\n",
    "\n",
    "            # Early‑stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = self.model.state_dict()\n",
    "                patience_ctr = 0\n",
    "            else:\n",
    "                patience_ctr += 1\n",
    "                if patience_ctr >= self.patience:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if best_state is not None:\n",
    "            ckpt_path = Path(self.writer.log_dir) / \"best_model.pt\"\n",
    "            torch.save(best_state, ckpt_path)\n",
    "        self.writer.flush()\n",
    "        self.writer.close()\n",
    "        return {\"best_val_loss\": best_val_loss, \"log_dir\": self.writer.log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb84eb",
   "metadata": {},
   "source": [
    "ASHA searcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d039b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASHASearch:\n",
    "    \"\"\"Hyper‑parameter search using Optuna + ASHA pruner.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_tensors: Tuple[torch.Tensor, torch.Tensor],\n",
    "        val_tensors: Tuple[torch.Tensor, torch.Tensor],\n",
    "        cfg: HyperConfig,\n",
    "        use_pruning: bool = True,\n",
    "        *,\n",
    "        base_dir: str = \"runs/asha\",\n",
    "    ) -> None:\n",
    "        set_seed(cfg.seed)\n",
    "        self.cfg = cfg\n",
    "        self.X_train, self.y_train = train_tensors\n",
    "        self.X_val, self.y_val = val_tensors\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if use_pruning:\n",
    "            pruner = SuccessiveHalvingPruner(min_resource=10, reduction_factor=2)\n",
    "        else:\n",
    "            pruner = optuna.pruners.NopPruner()\n",
    "\n",
    "\n",
    "        self.use_pruning = use_pruning\n",
    "        self.study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "\n",
    "    def _make_loaders(self, batch_size: int) -> Tuple[DataLoader, DataLoader]:\n",
    "        train_ds = TensorDataset(self.X_train, self.y_train)\n",
    "        val_ds = TensorDataset(self.X_val, self.y_val)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "        return train_loader, val_loader\n",
    "\n",
    "    def _objective(self, trial: optuna.Trial) -> float:\n",
    "        # 1 LR\n",
    "        lr = trial.suggest_float(\"lr\", *self.cfg.lr_range, log=True)\n",
    "        # 2.1 Number of hidden layers\n",
    "        num_layers = trial.suggest_categorical(\"num_layers\", self.cfg.layer_choices)\n",
    "        # 2.2 Number of neurons per hidden layer\n",
    "        hidden_width = trial.suggest_categorical(\"hidden_width\", self.cfg.hidden_choices)\n",
    "        # 3 Optimizer. From the pdf: \"Use Adam as a good default. Your primary tuning here will be its learning rate.\" <- I assume we only use Adam\n",
    "        # 4 Batch size\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", self.cfg.batch_choices)\n",
    "\n",
    "        # 5 Scheduler vs no scheduler\n",
    "        use_scheduler = trial.suggest_categorical(\"use_scheduler\", self.cfg.sched_choices)\n",
    "\n",
    "        hidden_dims = tuple([hidden_width] * num_layers)\n",
    "        model = DressMLP(input_dim=self.cfg.input_dim, hidden_dims=hidden_dims, num_classes=self.cfg.num_classes).to(self.device)\n",
    "\n",
    "        train_loader, val_loader = self._make_loaders(batch_size)\n",
    "\n",
    "        run_dir = self.base_dir / f\"trial_{trial.number:04d}\"\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            run_dir,\n",
    "            learning_rate=lr,\n",
    "            epochs=self.cfg.epochs,\n",
    "            patience=self.cfg.patience,\n",
    "            use_scheduler=use_scheduler,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        history = trainer.train(trial)\n",
    "        val_loss = history[\"best_val_loss\"]\n",
    "\n",
    "        # Free memory\n",
    "        del model, trainer\n",
    "        torch.cuda.empty_cache()\n",
    "        return val_loss\n",
    "\n",
    "    def run(self, n_trials: int = 30, timeout: int | None = None):\n",
    "        self.study.optimize(self._objective, n_trials=n_trials, timeout=timeout)\n",
    "        best = self.study.best_trial\n",
    "        summary = {\n",
    "            \"best_val_loss\": best.value,\n",
    "            \"params\": best.params,\n",
    "            \"trial_number\": best.number,\n",
    "        }\n",
    "        with open(self.base_dir / \"study_summary.json\", \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec0a07",
   "metadata": {},
   "source": [
    "Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "670b7692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { max-height: 200px !important; overflow: auto; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:54:15,744] A new study created in memory with name: no-name-1a14f880-7f01-44c0-a798-625b9490af2a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 | train_loss 1.6471 | val_loss 1.3693 | train_acc 0.4420 | val_acc 0.5510 | lr 1.56e-04 | 0.9s\n",
      "epoch 002 | train_loss 1.2820 | val_loss 1.1878 | train_acc 0.5515 | val_acc 0.5905 | lr 1.56e-04 | 0.8s\n",
      "epoch 003 | train_loss 1.1892 | val_loss 1.1363 | train_acc 0.5811 | val_acc 0.5953 | lr 1.56e-04 | 0.8s\n",
      "epoch 004 | train_loss 1.1331 | val_loss 1.1074 | train_acc 0.5921 | val_acc 0.6035 | lr 1.56e-04 | 0.8s\n",
      "epoch 005 | train_loss 1.0958 | val_loss 1.0858 | train_acc 0.6072 | val_acc 0.6127 | lr 1.56e-04 | 0.8s\n",
      "epoch 006 | train_loss 1.0686 | val_loss 1.0591 | train_acc 0.6136 | val_acc 0.6168 | lr 1.56e-04 | 0.8s\n",
      "epoch 007 | train_loss 1.0349 | val_loss 1.0439 | train_acc 0.6245 | val_acc 0.6268 | lr 1.56e-04 | 0.8s\n",
      "epoch 008 | train_loss 1.0134 | val_loss 1.0332 | train_acc 0.6346 | val_acc 0.6249 | lr 1.56e-04 | 0.8s\n",
      "epoch 009 | train_loss 0.9883 | val_loss 1.0328 | train_acc 0.6424 | val_acc 0.6227 | lr 1.56e-04 | 0.8s\n",
      "epoch 010 | train_loss 0.9666 | val_loss 1.0185 | train_acc 0.6500 | val_acc 0.6216 | lr 1.56e-04 | 0.8s\n",
      "epoch 011 | train_loss 0.9561 | val_loss 1.0190 | train_acc 0.6515 | val_acc 0.6260 | lr 1.56e-04 | 0.8s\n",
      "epoch 012 | train_loss 0.9309 | val_loss 1.0130 | train_acc 0.6560 | val_acc 0.6275 | lr 1.56e-04 | 0.8s\n",
      "epoch 013 | train_loss 0.9180 | val_loss 1.0446 | train_acc 0.6640 | val_acc 0.6109 | lr 1.56e-04 | 0.8s\n",
      "epoch 014 | train_loss 0.8989 | val_loss 1.0081 | train_acc 0.6709 | val_acc 0.6360 | lr 1.56e-04 | 0.8s\n",
      "epoch 015 | train_loss 0.8812 | val_loss 1.0165 | train_acc 0.6822 | val_acc 0.6256 | lr 1.56e-04 | 0.8s\n",
      "epoch 016 | train_loss 0.8707 | val_loss 1.0070 | train_acc 0.6864 | val_acc 0.6305 | lr 1.56e-04 | 0.8s\n",
      "epoch 017 | train_loss 0.8449 | val_loss 1.0109 | train_acc 0.6908 | val_acc 0.6279 | lr 1.56e-04 | 0.8s\n",
      "epoch 018 | train_loss 0.8327 | val_loss 1.0009 | train_acc 0.6971 | val_acc 0.6319 | lr 1.56e-04 | 0.8s\n",
      "epoch 019 | train_loss 0.8181 | val_loss 1.0059 | train_acc 0.6996 | val_acc 0.6341 | lr 1.56e-04 | 0.8s\n",
      "epoch 020 | train_loss 0.8085 | val_loss 0.9980 | train_acc 0.7074 | val_acc 0.6360 | lr 1.56e-04 | 0.8s\n",
      "epoch 021 | train_loss 0.8051 | val_loss 1.0011 | train_acc 0.7048 | val_acc 0.6264 | lr 1.56e-04 | 0.8s\n",
      "epoch 022 | train_loss 0.7711 | val_loss 1.0089 | train_acc 0.7206 | val_acc 0.6308 | lr 1.56e-04 | 0.8s\n",
      "epoch 023 | train_loss 0.7743 | val_loss 0.9989 | train_acc 0.7163 | val_acc 0.6275 | lr 1.56e-04 | 0.8s\n",
      "epoch 024 | train_loss 0.7567 | val_loss 1.0166 | train_acc 0.7245 | val_acc 0.6201 | lr 1.56e-04 | 0.8s\n",
      "epoch 025 | train_loss 0.7322 | val_loss 1.0045 | train_acc 0.7336 | val_acc 0.6268 | lr 1.56e-04 | 0.8s\n",
      "epoch 026 | train_loss 0.7225 | val_loss 1.0111 | train_acc 0.7369 | val_acc 0.6308 | lr 1.56e-04 | 0.8s\n",
      "epoch 027 | train_loss 0.7182 | val_loss 1.0164 | train_acc 0.7361 | val_acc 0.6253 | lr 1.56e-04 | 0.8s\n",
      "epoch 028 | train_loss 0.7089 | val_loss 1.0150 | train_acc 0.7400 | val_acc 0.6216 | lr 1.56e-04 | 0.8s\n",
      "epoch 029 | train_loss 0.6981 | val_loss 1.0106 | train_acc 0.7449 | val_acc 0.6271 | lr 1.56e-04 | 0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:54:40,126] Trial 0 finished with value: 0.9980425350946227 and parameters: {'lr': 0.00015600027835816066, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 64, 'use_scheduler': False}. Best is trial 0 with value: 0.9980425350946227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 030 | train_loss 0.6793 | val_loss 1.0335 | train_acc 0.7582 | val_acc 0.6297 | lr 1.56e-04 | 0.8s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3363 | val_loss 1.1822 | train_acc 0.5258 | val_acc 0.5658 | lr 3.96e-03 | 1.7s\n",
      "epoch 002 | train_loss 1.1878 | val_loss 1.0913 | train_acc 0.5685 | val_acc 0.5942 | lr 3.96e-03 | 1.6s\n",
      "epoch 003 | train_loss 1.1174 | val_loss 1.1374 | train_acc 0.5967 | val_acc 0.5698 | lr 3.96e-03 | 1.6s\n",
      "epoch 004 | train_loss 1.0876 | val_loss 1.0991 | train_acc 0.6006 | val_acc 0.5979 | lr 3.96e-03 | 1.6s\n",
      "epoch 005 | train_loss 1.0649 | val_loss 1.1120 | train_acc 0.6054 | val_acc 0.5928 | lr 3.96e-03 | 1.6s\n",
      "epoch 006 | train_loss 1.0469 | val_loss 1.0637 | train_acc 0.6126 | val_acc 0.6020 | lr 3.96e-03 | 1.6s\n",
      "epoch 007 | train_loss 1.0144 | val_loss 1.0593 | train_acc 0.6242 | val_acc 0.6142 | lr 3.96e-03 | 1.6s\n",
      "epoch 008 | train_loss 1.0076 | val_loss 1.0939 | train_acc 0.6297 | val_acc 0.5857 | lr 3.96e-03 | 1.6s\n",
      "epoch 009 | train_loss 0.9948 | val_loss 1.0704 | train_acc 0.6294 | val_acc 0.6072 | lr 3.96e-03 | 1.6s\n",
      "epoch 010 | train_loss 0.9816 | val_loss 1.0334 | train_acc 0.6349 | val_acc 0.6216 | lr 3.96e-03 | 1.6s\n",
      "epoch 011 | train_loss 0.9670 | val_loss 1.0453 | train_acc 0.6390 | val_acc 0.6094 | lr 3.96e-03 | 1.6s\n",
      "epoch 012 | train_loss 0.9664 | val_loss 1.0319 | train_acc 0.6423 | val_acc 0.6197 | lr 3.96e-03 | 1.6s\n",
      "epoch 013 | train_loss 0.9569 | val_loss 1.0369 | train_acc 0.6437 | val_acc 0.6264 | lr 3.96e-03 | 1.6s\n",
      "epoch 014 | train_loss 0.9434 | val_loss 1.0542 | train_acc 0.6465 | val_acc 0.6053 | lr 3.96e-03 | 1.6s\n",
      "epoch 015 | train_loss 0.9342 | val_loss 1.0729 | train_acc 0.6557 | val_acc 0.6027 | lr 3.96e-03 | 1.6s\n",
      "epoch 016 | train_loss 0.9177 | val_loss 1.0509 | train_acc 0.6587 | val_acc 0.6086 | lr 3.96e-03 | 1.6s\n",
      "epoch 017 | train_loss 0.9267 | val_loss 1.0510 | train_acc 0.6513 | val_acc 0.6157 | lr 3.96e-03 | 1.6s\n",
      "epoch 018 | train_loss 0.9088 | val_loss 1.0378 | train_acc 0.6612 | val_acc 0.6286 | lr 3.96e-03 | 1.6s\n",
      "epoch 019 | train_loss 0.9015 | val_loss 1.0506 | train_acc 0.6631 | val_acc 0.6197 | lr 3.96e-03 | 1.6s\n",
      "epoch 020 | train_loss 0.8917 | val_loss 1.0332 | train_acc 0.6633 | val_acc 0.6120 | lr 3.96e-03 | 1.6s\n",
      "epoch 021 | train_loss 0.8863 | val_loss 1.1119 | train_acc 0.6709 | val_acc 0.6027 | lr 3.96e-03 | 1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:55:15,950] Trial 1 finished with value: 1.0319446621342931 and parameters: {'lr': 0.003956884006962734, 'num_layers': 2, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 0 with value: 0.9980425350946227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.8869 | val_loss 1.0354 | train_acc 0.6676 | val_acc 0.6345 | lr 3.96e-03 | 1.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5432 | val_loss 1.2350 | train_acc 0.4720 | val_acc 0.5721 | lr 1.50e-04 | 1.6s\n",
      "epoch 002 | train_loss 1.2422 | val_loss 1.1296 | train_acc 0.5601 | val_acc 0.5990 | lr 1.50e-04 | 1.6s\n",
      "epoch 003 | train_loss 1.1606 | val_loss 1.1004 | train_acc 0.5842 | val_acc 0.5994 | lr 1.50e-04 | 1.6s\n",
      "epoch 004 | train_loss 1.1145 | val_loss 1.0559 | train_acc 0.5962 | val_acc 0.6205 | lr 1.50e-04 | 1.6s\n",
      "epoch 005 | train_loss 1.0789 | val_loss 1.0417 | train_acc 0.6108 | val_acc 0.6216 | lr 1.50e-04 | 1.6s\n",
      "epoch 006 | train_loss 1.0527 | val_loss 1.0256 | train_acc 0.6193 | val_acc 0.6293 | lr 1.50e-04 | 1.6s\n",
      "epoch 007 | train_loss 1.0208 | val_loss 1.0200 | train_acc 0.6315 | val_acc 0.6301 | lr 1.50e-04 | 1.6s\n",
      "epoch 008 | train_loss 1.0018 | val_loss 1.0046 | train_acc 0.6358 | val_acc 0.6397 | lr 1.50e-04 | 1.6s\n",
      "epoch 009 | train_loss 0.9739 | val_loss 1.0075 | train_acc 0.6434 | val_acc 0.6316 | lr 1.50e-04 | 1.6s\n",
      "epoch 010 | train_loss 0.9576 | val_loss 1.0055 | train_acc 0.6507 | val_acc 0.6338 | lr 1.50e-04 | 1.6s\n",
      "epoch 011 | train_loss 0.9272 | val_loss 0.9941 | train_acc 0.6606 | val_acc 0.6408 | lr 1.50e-04 | 1.6s\n",
      "epoch 012 | train_loss 0.9270 | val_loss 0.9958 | train_acc 0.6604 | val_acc 0.6371 | lr 1.50e-04 | 1.6s\n",
      "epoch 013 | train_loss 0.9021 | val_loss 0.9952 | train_acc 0.6713 | val_acc 0.6334 | lr 1.50e-04 | 1.6s\n",
      "epoch 014 | train_loss 0.8825 | val_loss 0.9929 | train_acc 0.6785 | val_acc 0.6397 | lr 1.50e-04 | 1.6s\n",
      "epoch 015 | train_loss 0.8676 | val_loss 0.9919 | train_acc 0.6837 | val_acc 0.6390 | lr 1.50e-04 | 1.6s\n",
      "epoch 016 | train_loss 0.8547 | val_loss 1.0091 | train_acc 0.6900 | val_acc 0.6305 | lr 1.50e-04 | 1.6s\n",
      "epoch 017 | train_loss 0.8363 | val_loss 0.9883 | train_acc 0.6956 | val_acc 0.6386 | lr 1.50e-04 | 1.6s\n",
      "epoch 018 | train_loss 0.8230 | val_loss 1.0096 | train_acc 0.7005 | val_acc 0.6338 | lr 1.50e-04 | 1.6s\n",
      "epoch 019 | train_loss 0.8142 | val_loss 1.0017 | train_acc 0.6990 | val_acc 0.6382 | lr 1.50e-04 | 1.6s\n",
      "epoch 020 | train_loss 0.8054 | val_loss 0.9952 | train_acc 0.7058 | val_acc 0.6434 | lr 1.50e-04 | 1.6s\n",
      "epoch 021 | train_loss 0.7779 | val_loss 1.0103 | train_acc 0.7200 | val_acc 0.6378 | lr 1.50e-04 | 1.6s\n",
      "epoch 022 | train_loss 0.7756 | val_loss 1.0027 | train_acc 0.7143 | val_acc 0.6390 | lr 1.50e-04 | 1.6s\n",
      "epoch 023 | train_loss 0.7590 | val_loss 1.0151 | train_acc 0.7205 | val_acc 0.6345 | lr 1.50e-04 | 1.6s\n",
      "epoch 024 | train_loss 0.7399 | val_loss 1.0035 | train_acc 0.7302 | val_acc 0.6404 | lr 1.50e-04 | 1.6s\n",
      "epoch 025 | train_loss 0.7308 | val_loss 1.0111 | train_acc 0.7334 | val_acc 0.6341 | lr 1.50e-04 | 1.6s\n",
      "epoch 026 | train_loss 0.7267 | val_loss 1.0205 | train_acc 0.7346 | val_acc 0.6460 | lr 1.50e-04 | 1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:55:59,376] Trial 2 finished with value: 0.9882662446077718 and parameters: {'lr': 0.00014989663237103884, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 027 | train_loss 0.7138 | val_loss 1.0203 | train_acc 0.7388 | val_acc 0.6441 | lr 1.50e-04 | 1.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2820 | val_loss 1.5156 | train_acc 0.5400 | val_acc 0.5517 | lr 9.69e-03 | 0.4s\n",
      "epoch 002 | train_loss 1.1130 | val_loss 1.3445 | train_acc 0.5939 | val_acc 0.5617 | lr 9.68e-03 | 0.3s\n",
      "epoch 003 | train_loss 1.0409 | val_loss 1.0951 | train_acc 0.6206 | val_acc 0.6090 | lr 9.67e-03 | 0.3s\n",
      "epoch 004 | train_loss 1.0029 | val_loss 1.1082 | train_acc 0.6279 | val_acc 0.6038 | lr 9.65e-03 | 0.3s\n",
      "epoch 005 | train_loss 0.9649 | val_loss 1.1108 | train_acc 0.6423 | val_acc 0.6168 | lr 9.63e-03 | 0.3s\n",
      "epoch 006 | train_loss 0.9383 | val_loss 1.0514 | train_acc 0.6486 | val_acc 0.6190 | lr 9.61e-03 | 0.3s\n",
      "epoch 007 | train_loss 0.9076 | val_loss 1.1128 | train_acc 0.6637 | val_acc 0.6175 | lr 9.58e-03 | 0.3s\n",
      "epoch 008 | train_loss 0.8927 | val_loss 1.0765 | train_acc 0.6703 | val_acc 0.6194 | lr 9.54e-03 | 0.3s\n",
      "epoch 009 | train_loss 0.8766 | val_loss 1.1158 | train_acc 0.6766 | val_acc 0.6083 | lr 9.50e-03 | 0.3s\n",
      "epoch 010 | train_loss 0.8491 | val_loss 1.0887 | train_acc 0.6842 | val_acc 0.6201 | lr 9.46e-03 | 0.3s\n",
      "epoch 011 | train_loss 0.8335 | val_loss 1.0804 | train_acc 0.6873 | val_acc 0.6068 | lr 9.41e-03 | 0.3s\n",
      "epoch 012 | train_loss 0.8128 | val_loss 1.0758 | train_acc 0.6974 | val_acc 0.6216 | lr 9.35e-03 | 0.3s\n",
      "epoch 013 | train_loss 0.7925 | val_loss 1.0969 | train_acc 0.7083 | val_acc 0.6142 | lr 9.29e-03 | 0.3s\n",
      "epoch 014 | train_loss 0.7794 | val_loss 1.1037 | train_acc 0.7152 | val_acc 0.6072 | lr 9.23e-03 | 0.3s\n",
      "epoch 015 | train_loss 0.7614 | val_loss 1.1071 | train_acc 0.7185 | val_acc 0.6160 | lr 9.16e-03 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:04,403] Trial 3 finished with value: 1.0514095238377585 and parameters: {'lr': 0.009692976960320928, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 016 | train_loss 0.7415 | val_loss 1.1518 | train_acc 0.7213 | val_acc 0.6072 | lr 9.09e-03 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4914 | val_loss 1.2690 | train_acc 0.4842 | val_acc 0.5776 | lr 1.24e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.1890 | val_loss 1.1222 | train_acc 0.5784 | val_acc 0.5950 | lr 1.24e-04 | 0.4s\n",
      "epoch 003 | train_loss 1.1103 | val_loss 1.0771 | train_acc 0.6031 | val_acc 0.6149 | lr 1.23e-04 | 0.4s\n",
      "epoch 004 | train_loss 1.0596 | val_loss 1.0525 | train_acc 0.6140 | val_acc 0.6160 | lr 1.23e-04 | 0.4s\n",
      "epoch 005 | train_loss 1.0202 | val_loss 1.0390 | train_acc 0.6290 | val_acc 0.6212 | lr 1.23e-04 | 0.4s\n",
      "epoch 006 | train_loss 0.9871 | val_loss 1.0187 | train_acc 0.6463 | val_acc 0.6312 | lr 1.23e-04 | 0.4s\n",
      "epoch 007 | train_loss 0.9526 | val_loss 1.0157 | train_acc 0.6534 | val_acc 0.6282 | lr 1.22e-04 | 0.4s\n",
      "epoch 008 | train_loss 0.9349 | val_loss 1.0044 | train_acc 0.6571 | val_acc 0.6378 | lr 1.22e-04 | 0.4s\n",
      "epoch 009 | train_loss 0.9017 | val_loss 1.0052 | train_acc 0.6703 | val_acc 0.6305 | lr 1.21e-04 | 0.4s\n",
      "epoch 010 | train_loss 0.8813 | val_loss 1.0122 | train_acc 0.6805 | val_acc 0.6260 | lr 1.21e-04 | 0.4s\n",
      "epoch 011 | train_loss 0.8524 | val_loss 1.0120 | train_acc 0.6915 | val_acc 0.6312 | lr 1.20e-04 | 0.4s\n",
      "epoch 012 | train_loss 0.8341 | val_loss 0.9914 | train_acc 0.6971 | val_acc 0.6404 | lr 1.19e-04 | 0.4s\n",
      "epoch 013 | train_loss 0.8046 | val_loss 0.9957 | train_acc 0.7079 | val_acc 0.6364 | lr 1.19e-04 | 0.4s\n",
      "epoch 014 | train_loss 0.7833 | val_loss 0.9967 | train_acc 0.7245 | val_acc 0.6401 | lr 1.18e-04 | 0.4s\n",
      "epoch 015 | train_loss 0.7614 | val_loss 0.9997 | train_acc 0.7253 | val_acc 0.6393 | lr 1.17e-04 | 0.4s\n",
      "epoch 016 | train_loss 0.7481 | val_loss 0.9976 | train_acc 0.7292 | val_acc 0.6364 | lr 1.16e-04 | 0.3s\n",
      "epoch 017 | train_loss 0.7249 | val_loss 1.0169 | train_acc 0.7325 | val_acc 0.6323 | lr 1.15e-04 | 0.3s\n",
      "epoch 018 | train_loss 0.7105 | val_loss 1.0095 | train_acc 0.7432 | val_acc 0.6393 | lr 1.14e-04 | 0.3s\n",
      "epoch 019 | train_loss 0.6886 | val_loss 1.0363 | train_acc 0.7482 | val_acc 0.6386 | lr 1.13e-04 | 0.3s\n",
      "epoch 020 | train_loss 0.6676 | val_loss 1.0166 | train_acc 0.7592 | val_acc 0.6360 | lr 1.12e-04 | 0.3s\n",
      "epoch 021 | train_loss 0.6551 | val_loss 1.0095 | train_acc 0.7641 | val_acc 0.6434 | lr 1.11e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:12,853] Trial 4 finished with value: 0.9913747438394134 and parameters: {'lr': 0.00012372982246467142, 'num_layers': 2, 'hidden_width': 512, 'batch_size': 64, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.6410 | val_loss 1.0279 | train_acc 0.7673 | val_acc 0.6308 | lr 1.10e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2932 | val_loss 1.3799 | train_acc 0.5359 | val_acc 0.5735 | lr 3.59e-03 | 0.4s\n",
      "epoch 002 | train_loss 1.1482 | val_loss 1.1296 | train_acc 0.5815 | val_acc 0.5813 | lr 3.59e-03 | 0.3s\n",
      "epoch 003 | train_loss 1.0714 | val_loss 1.0822 | train_acc 0.6062 | val_acc 0.5979 | lr 3.58e-03 | 0.3s\n",
      "epoch 004 | train_loss 1.0340 | val_loss 1.0351 | train_acc 0.6140 | val_acc 0.6179 | lr 3.58e-03 | 0.3s\n",
      "epoch 005 | train_loss 0.9980 | val_loss 1.0407 | train_acc 0.6348 | val_acc 0.6157 | lr 3.57e-03 | 0.3s\n",
      "epoch 006 | train_loss 0.9706 | val_loss 1.0628 | train_acc 0.6411 | val_acc 0.6120 | lr 3.56e-03 | 0.3s\n",
      "epoch 007 | train_loss 0.9512 | val_loss 1.0302 | train_acc 0.6513 | val_acc 0.6223 | lr 3.55e-03 | 0.3s\n",
      "epoch 008 | train_loss 0.9049 | val_loss 1.0161 | train_acc 0.6644 | val_acc 0.6268 | lr 3.53e-03 | 0.3s\n",
      "epoch 009 | train_loss 0.8827 | val_loss 1.0420 | train_acc 0.6684 | val_acc 0.6231 | lr 3.52e-03 | 0.3s\n",
      "epoch 010 | train_loss 0.8747 | val_loss 1.0668 | train_acc 0.6742 | val_acc 0.6075 | lr 3.50e-03 | 0.3s\n",
      "epoch 011 | train_loss 0.8480 | val_loss 1.0256 | train_acc 0.6824 | val_acc 0.6301 | lr 3.48e-03 | 0.3s\n",
      "epoch 012 | train_loss 0.8063 | val_loss 1.0540 | train_acc 0.6951 | val_acc 0.6216 | lr 3.46e-03 | 0.3s\n",
      "epoch 013 | train_loss 0.7885 | val_loss 1.0694 | train_acc 0.7059 | val_acc 0.6201 | lr 3.44e-03 | 0.3s\n",
      "epoch 014 | train_loss 0.7715 | val_loss 1.0885 | train_acc 0.7161 | val_acc 0.6197 | lr 3.42e-03 | 0.3s\n",
      "epoch 015 | train_loss 0.7662 | val_loss 1.0595 | train_acc 0.7118 | val_acc 0.6305 | lr 3.40e-03 | 0.3s\n",
      "epoch 016 | train_loss 0.7416 | val_loss 1.0910 | train_acc 0.7231 | val_acc 0.6197 | lr 3.37e-03 | 0.3s\n",
      "epoch 017 | train_loss 0.7170 | val_loss 1.1075 | train_acc 0.7306 | val_acc 0.6268 | lr 3.34e-03 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:18,624] Trial 5 finished with value: 1.0161407275809593 and parameters: {'lr': 0.0035909120638193594, 'num_layers': 2, 'hidden_width': 512, 'batch_size': 64, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.7056 | val_loss 1.0720 | train_acc 0.7394 | val_acc 0.6260 | lr 3.31e-03 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2727 | val_loss 1.3419 | train_acc 0.5493 | val_acc 0.5654 | lr 5.06e-03 | 0.3s\n",
      "epoch 002 | train_loss 1.1098 | val_loss 1.1219 | train_acc 0.5923 | val_acc 0.6013 | lr 5.05e-03 | 0.3s\n",
      "epoch 003 | train_loss 1.0448 | val_loss 1.0858 | train_acc 0.6151 | val_acc 0.5976 | lr 5.05e-03 | 0.3s\n",
      "epoch 004 | train_loss 1.0004 | val_loss 1.0679 | train_acc 0.6292 | val_acc 0.6116 | lr 5.04e-03 | 0.3s\n",
      "epoch 005 | train_loss 0.9568 | val_loss 1.0522 | train_acc 0.6479 | val_acc 0.6308 | lr 5.03e-03 | 0.3s\n",
      "epoch 006 | train_loss 0.9283 | val_loss 1.0292 | train_acc 0.6500 | val_acc 0.6297 | lr 5.01e-03 | 0.3s\n",
      "epoch 007 | train_loss 0.8902 | val_loss 1.0703 | train_acc 0.6716 | val_acc 0.6231 | lr 5.00e-03 | 0.3s\n",
      "epoch 008 | train_loss 0.8711 | val_loss 1.0466 | train_acc 0.6759 | val_acc 0.6212 | lr 4.98e-03 | 0.3s\n",
      "epoch 009 | train_loss 0.8531 | val_loss 1.0751 | train_acc 0.6824 | val_acc 0.6183 | lr 4.96e-03 | 0.3s\n",
      "epoch 010 | train_loss 0.8317 | val_loss 1.0818 | train_acc 0.6912 | val_acc 0.6260 | lr 4.93e-03 | 0.3s\n",
      "epoch 011 | train_loss 0.8234 | val_loss 1.0495 | train_acc 0.6974 | val_acc 0.6249 | lr 4.91e-03 | 0.3s\n",
      "epoch 012 | train_loss 0.7812 | val_loss 1.0967 | train_acc 0.7091 | val_acc 0.6312 | lr 4.88e-03 | 0.3s\n",
      "epoch 013 | train_loss 0.7886 | val_loss 1.0712 | train_acc 0.7082 | val_acc 0.6175 | lr 4.85e-03 | 0.3s\n",
      "epoch 014 | train_loss 0.7524 | val_loss 1.0857 | train_acc 0.7148 | val_acc 0.6282 | lr 4.82e-03 | 0.3s\n",
      "epoch 015 | train_loss 0.7344 | val_loss 1.0960 | train_acc 0.7246 | val_acc 0.6105 | lr 4.78e-03 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:22,971] Trial 6 finished with value: 1.029172418651454 and parameters: {'lr': 0.0050586101112542105, 'num_layers': 1, 'hidden_width': 512, 'batch_size': 64, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 016 | train_loss 0.7235 | val_loss 1.1288 | train_acc 0.7293 | val_acc 0.6175 | lr 4.75e-03 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4190 | val_loss 1.4296 | train_acc 0.5025 | val_acc 0.5809 | lr 4.18e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.1350 | val_loss 1.1512 | train_acc 0.5920 | val_acc 0.6171 | lr 4.18e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.0620 | val_loss 1.0463 | train_acc 0.6115 | val_acc 0.6279 | lr 4.18e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.0048 | val_loss 1.0384 | train_acc 0.6330 | val_acc 0.6175 | lr 4.18e-04 | 0.2s\n",
      "epoch 005 | train_loss 0.9542 | val_loss 1.0083 | train_acc 0.6520 | val_acc 0.6349 | lr 4.18e-04 | 0.2s\n",
      "epoch 006 | train_loss 0.9188 | val_loss 1.0098 | train_acc 0.6644 | val_acc 0.6275 | lr 4.18e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.8804 | val_loss 1.0060 | train_acc 0.6812 | val_acc 0.6323 | lr 4.18e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.8403 | val_loss 1.0242 | train_acc 0.6912 | val_acc 0.6308 | lr 4.18e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.8133 | val_loss 1.0289 | train_acc 0.7042 | val_acc 0.6279 | lr 4.18e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.7877 | val_loss 1.0236 | train_acc 0.7087 | val_acc 0.6349 | lr 4.18e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.7537 | val_loss 1.0290 | train_acc 0.7249 | val_acc 0.6419 | lr 4.18e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.7286 | val_loss 1.0740 | train_acc 0.7314 | val_acc 0.6305 | lr 4.18e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.6825 | val_loss 1.0586 | train_acc 0.7478 | val_acc 0.6297 | lr 4.18e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.6579 | val_loss 1.0681 | train_acc 0.7539 | val_acc 0.6382 | lr 4.18e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.6650 | val_loss 1.0925 | train_acc 0.7525 | val_acc 0.6386 | lr 4.18e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.6185 | val_loss 1.1058 | train_acc 0.7717 | val_acc 0.6345 | lr 4.18e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:26,761] Trial 7 finished with value: 1.0060360386736378 and parameters: {'lr': 0.0004182444844788966, 'num_layers': 3, 'hidden_width': 512, 'batch_size': 128, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.5994 | val_loss 1.0948 | train_acc 0.7783 | val_acc 0.6378 | lr 4.18e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3977 | val_loss 1.2465 | train_acc 0.5140 | val_acc 0.5547 | lr 3.66e-04 | 0.2s\n",
      "epoch 002 | train_loss 1.1060 | val_loss 1.0962 | train_acc 0.6060 | val_acc 0.5983 | lr 3.66e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.0334 | val_loss 1.0593 | train_acc 0.6302 | val_acc 0.6075 | lr 3.66e-04 | 0.2s\n",
      "epoch 004 | train_loss 0.9846 | val_loss 1.0318 | train_acc 0.6407 | val_acc 0.6220 | lr 3.66e-04 | 0.2s\n",
      "epoch 005 | train_loss 0.9462 | val_loss 1.0398 | train_acc 0.6571 | val_acc 0.6212 | lr 3.66e-04 | 0.2s\n",
      "epoch 006 | train_loss 0.9080 | val_loss 1.0106 | train_acc 0.6770 | val_acc 0.6334 | lr 3.66e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.8815 | val_loss 1.0131 | train_acc 0.6822 | val_acc 0.6286 | lr 3.66e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.8472 | val_loss 1.0078 | train_acc 0.6912 | val_acc 0.6327 | lr 3.66e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.8184 | val_loss 1.0047 | train_acc 0.7014 | val_acc 0.6308 | lr 3.66e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.7896 | val_loss 1.0042 | train_acc 0.7169 | val_acc 0.6386 | lr 3.66e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.7689 | val_loss 1.0024 | train_acc 0.7205 | val_acc 0.6378 | lr 3.66e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.7449 | val_loss 1.0226 | train_acc 0.7317 | val_acc 0.6397 | lr 3.66e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.7124 | val_loss 1.0147 | train_acc 0.7461 | val_acc 0.6341 | lr 3.66e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.6908 | val_loss 1.0330 | train_acc 0.7535 | val_acc 0.6341 | lr 3.66e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.6658 | val_loss 1.0105 | train_acc 0.7645 | val_acc 0.6412 | lr 3.66e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.6417 | val_loss 1.0219 | train_acc 0.7715 | val_acc 0.6419 | lr 3.66e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.6306 | val_loss 1.0653 | train_acc 0.7808 | val_acc 0.6297 | lr 3.66e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.6097 | val_loss 1.0342 | train_acc 0.7838 | val_acc 0.6423 | lr 3.66e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.5858 | val_loss 1.0437 | train_acc 0.7914 | val_acc 0.6378 | lr 3.66e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.5679 | val_loss 1.0341 | train_acc 0.8073 | val_acc 0.6415 | lr 3.66e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:30,422] Trial 8 finished with value: 1.0023619627300582 and parameters: {'lr': 0.00036596039534616637, 'num_layers': 1, 'hidden_width': 512, 'batch_size': 128, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 021 | train_loss 0.5415 | val_loss 1.0565 | train_acc 0.8152 | val_acc 0.6338 | lr 3.66e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2424 | val_loss 1.1277 | train_acc 0.5502 | val_acc 0.5924 | lr 2.03e-03 | 0.3s\n",
      "epoch 002 | train_loss 1.0896 | val_loss 1.0751 | train_acc 0.5990 | val_acc 0.5990 | lr 2.03e-03 | 0.3s\n",
      "epoch 003 | train_loss 1.0307 | val_loss 1.0787 | train_acc 0.6209 | val_acc 0.6090 | lr 2.03e-03 | 0.3s\n",
      "epoch 004 | train_loss 1.0005 | val_loss 1.0521 | train_acc 0.6328 | val_acc 0.6101 | lr 2.02e-03 | 0.3s\n",
      "epoch 005 | train_loss 0.9539 | val_loss 1.0478 | train_acc 0.6493 | val_acc 0.6220 | lr 2.02e-03 | 0.3s\n",
      "epoch 006 | train_loss 0.9256 | val_loss 1.0249 | train_acc 0.6580 | val_acc 0.6242 | lr 2.01e-03 | 0.3s\n",
      "epoch 007 | train_loss 0.8941 | val_loss 1.0312 | train_acc 0.6705 | val_acc 0.6341 | lr 2.01e-03 | 0.3s\n",
      "epoch 008 | train_loss 0.8750 | val_loss 1.0185 | train_acc 0.6758 | val_acc 0.6367 | lr 2.00e-03 | 0.3s\n",
      "epoch 009 | train_loss 0.8468 | val_loss 1.0286 | train_acc 0.6882 | val_acc 0.6286 | lr 1.99e-03 | 0.3s\n",
      "epoch 010 | train_loss 0.8191 | val_loss 1.0347 | train_acc 0.6965 | val_acc 0.6308 | lr 1.98e-03 | 0.3s\n",
      "epoch 011 | train_loss 0.7919 | val_loss 1.0659 | train_acc 0.7042 | val_acc 0.6279 | lr 1.97e-03 | 0.3s\n",
      "epoch 012 | train_loss 0.7805 | val_loss 1.0408 | train_acc 0.7083 | val_acc 0.6319 | lr 1.96e-03 | 0.3s\n",
      "epoch 013 | train_loss 0.7643 | val_loss 1.0269 | train_acc 0.7182 | val_acc 0.6382 | lr 1.95e-03 | 0.3s\n",
      "epoch 014 | train_loss 0.7500 | val_loss 1.0463 | train_acc 0.7218 | val_acc 0.6319 | lr 1.94e-03 | 0.3s\n",
      "epoch 015 | train_loss 0.7187 | val_loss 1.0785 | train_acc 0.7310 | val_acc 0.6223 | lr 1.92e-03 | 0.3s\n",
      "epoch 016 | train_loss 0.7123 | val_loss 1.0669 | train_acc 0.7339 | val_acc 0.6301 | lr 1.91e-03 | 0.3s\n",
      "epoch 017 | train_loss 0.6838 | val_loss 1.0678 | train_acc 0.7512 | val_acc 0.6293 | lr 1.89e-03 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:56:35,283] Trial 9 finished with value: 1.0185219689994411 and parameters: {'lr': 0.0020329692860973064, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 64, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.6558 | val_loss 1.0652 | train_acc 0.7563 | val_acc 0.6290 | lr 1.87e-03 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5043 | val_loss 1.1975 | train_acc 0.4777 | val_acc 0.5765 | lr 6.77e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.2696 | val_loss 1.1201 | train_acc 0.5528 | val_acc 0.5987 | lr 6.77e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.1988 | val_loss 1.0894 | train_acc 0.5700 | val_acc 0.6035 | lr 6.77e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1474 | val_loss 1.0652 | train_acc 0.5850 | val_acc 0.6105 | lr 6.77e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1252 | val_loss 1.0420 | train_acc 0.5927 | val_acc 0.6131 | lr 6.77e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.1006 | val_loss 1.0452 | train_acc 0.6021 | val_acc 0.6190 | lr 6.77e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0867 | val_loss 1.0358 | train_acc 0.6053 | val_acc 0.6201 | lr 6.77e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0670 | val_loss 1.0448 | train_acc 0.6118 | val_acc 0.6205 | lr 6.77e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0533 | val_loss 1.0173 | train_acc 0.6195 | val_acc 0.6290 | lr 6.77e-04 | 0.6s\n",
      "epoch 010 | train_loss 1.0364 | val_loss 1.0119 | train_acc 0.6181 | val_acc 0.6238 | lr 6.77e-04 | 0.6s\n",
      "epoch 011 | train_loss 1.0127 | val_loss 1.0037 | train_acc 0.6351 | val_acc 0.6256 | lr 6.77e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9936 | val_loss 1.0105 | train_acc 0.6330 | val_acc 0.6242 | lr 6.77e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.9900 | val_loss 1.0039 | train_acc 0.6372 | val_acc 0.6349 | lr 6.77e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9750 | val_loss 1.0115 | train_acc 0.6442 | val_acc 0.6290 | lr 6.77e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9588 | val_loss 1.0016 | train_acc 0.6469 | val_acc 0.6293 | lr 6.77e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.9560 | val_loss 0.9915 | train_acc 0.6506 | val_acc 0.6338 | lr 6.77e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.9430 | val_loss 1.0021 | train_acc 0.6571 | val_acc 0.6308 | lr 6.77e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.9327 | val_loss 1.0264 | train_acc 0.6598 | val_acc 0.6149 | lr 6.77e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.9194 | val_loss 1.0099 | train_acc 0.6625 | val_acc 0.6305 | lr 6.77e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.9138 | val_loss 1.0021 | train_acc 0.6633 | val_acc 0.6305 | lr 6.77e-04 | 2.0s\n",
      "epoch 021 | train_loss 0.8919 | val_loss 1.0072 | train_acc 0.6762 | val_acc 0.6305 | lr 6.77e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.8925 | val_loss 1.0023 | train_acc 0.6744 | val_acc 0.6330 | lr 6.77e-04 | 2.0s\n",
      "epoch 023 | train_loss 0.8818 | val_loss 0.9988 | train_acc 0.6771 | val_acc 0.6390 | lr 6.77e-04 | 2.0s\n",
      "epoch 024 | train_loss 0.8649 | val_loss 1.0275 | train_acc 0.6822 | val_acc 0.6205 | lr 6.77e-04 | 2.0s\n",
      "epoch 025 | train_loss 0.8583 | val_loss 1.0184 | train_acc 0.6887 | val_acc 0.6345 | lr 6.77e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:57:06,754] Trial 10 finished with value: 0.9915294552060823 and parameters: {'lr': 0.0006770635676917495, 'num_layers': 3, 'hidden_width': 128, 'batch_size': 32, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 026 | train_loss 0.8665 | val_loss 1.0050 | train_acc 0.6831 | val_acc 0.6404 | lr 6.77e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3885 | val_loss 1.1438 | train_acc 0.5131 | val_acc 0.5979 | lr 1.02e-04 | 1.7s\n",
      "epoch 002 | train_loss 1.1351 | val_loss 1.0753 | train_acc 0.5899 | val_acc 0.6120 | lr 1.02e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.0620 | val_loss 1.0565 | train_acc 0.6200 | val_acc 0.6153 | lr 1.01e-04 | 0.7s\n",
      "epoch 004 | train_loss 1.0174 | val_loss 1.0274 | train_acc 0.6335 | val_acc 0.6242 | lr 1.01e-04 | 0.7s\n",
      "epoch 005 | train_loss 0.9742 | val_loss 1.0330 | train_acc 0.6450 | val_acc 0.6275 | lr 1.01e-04 | 0.7s\n",
      "epoch 006 | train_loss 0.9426 | val_loss 1.0153 | train_acc 0.6515 | val_acc 0.6397 | lr 1.01e-04 | 0.6s\n",
      "epoch 007 | train_loss 0.8948 | val_loss 1.0041 | train_acc 0.6739 | val_acc 0.6434 | lr 1.00e-04 | 0.6s\n",
      "epoch 008 | train_loss 0.8632 | val_loss 1.0179 | train_acc 0.6869 | val_acc 0.6282 | lr 1.00e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.8347 | val_loss 1.0134 | train_acc 0.6969 | val_acc 0.6353 | lr 9.96e-05 | 0.6s\n",
      "epoch 010 | train_loss 0.7951 | val_loss 1.0202 | train_acc 0.7074 | val_acc 0.6297 | lr 9.91e-05 | 0.6s\n",
      "epoch 011 | train_loss 0.7767 | val_loss 1.0075 | train_acc 0.7197 | val_acc 0.6404 | lr 9.86e-05 | 0.6s\n",
      "epoch 012 | train_loss 0.7535 | val_loss 1.0289 | train_acc 0.7227 | val_acc 0.6305 | lr 9.81e-05 | 0.6s\n",
      "epoch 013 | train_loss 0.7202 | val_loss 1.0225 | train_acc 0.7378 | val_acc 0.6353 | lr 9.75e-05 | 0.6s\n",
      "epoch 014 | train_loss 0.6993 | val_loss 1.0098 | train_acc 0.7436 | val_acc 0.6397 | lr 9.68e-05 | 0.6s\n",
      "epoch 015 | train_loss 0.6723 | val_loss 1.0411 | train_acc 0.7594 | val_acc 0.6327 | lr 9.61e-05 | 0.6s\n",
      "epoch 016 | train_loss 0.6491 | val_loss 1.0496 | train_acc 0.7623 | val_acc 0.6371 | lr 9.53e-05 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:57:17,873] Trial 11 finished with value: 1.0040516500021912 and parameters: {'lr': 0.00010162978000149953, 'num_layers': 2, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.6313 | val_loss 1.0488 | train_acc 0.7725 | val_acc 0.6415 | lr 9.46e-05 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5805 | val_loss 1.2728 | train_acc 0.4640 | val_acc 0.5673 | lr 2.32e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2943 | val_loss 1.1643 | train_acc 0.5453 | val_acc 0.5957 | lr 2.32e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.2039 | val_loss 1.1193 | train_acc 0.5725 | val_acc 0.6046 | lr 2.32e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1577 | val_loss 1.0945 | train_acc 0.5836 | val_acc 0.6035 | lr 2.31e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.1184 | val_loss 1.0740 | train_acc 0.6016 | val_acc 0.6116 | lr 2.31e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.1018 | val_loss 1.0467 | train_acc 0.5989 | val_acc 0.6205 | lr 2.30e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0737 | val_loss 1.0446 | train_acc 0.6105 | val_acc 0.6171 | lr 2.30e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0522 | val_loss 1.0464 | train_acc 0.6208 | val_acc 0.6231 | lr 2.29e-04 | 0.5s\n",
      "epoch 009 | train_loss 1.0388 | val_loss 1.0268 | train_acc 0.6221 | val_acc 0.6249 | lr 2.28e-04 | 0.5s\n",
      "epoch 010 | train_loss 1.0143 | val_loss 1.0379 | train_acc 0.6306 | val_acc 0.6186 | lr 2.27e-04 | 0.5s\n",
      "epoch 011 | train_loss 1.0038 | val_loss 1.0117 | train_acc 0.6350 | val_acc 0.6275 | lr 2.25e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9918 | val_loss 1.0135 | train_acc 0.6388 | val_acc 0.6249 | lr 2.24e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9681 | val_loss 1.0136 | train_acc 0.6444 | val_acc 0.6260 | lr 2.23e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9614 | val_loss 1.0049 | train_acc 0.6515 | val_acc 0.6367 | lr 2.21e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.9487 | val_loss 1.0095 | train_acc 0.6566 | val_acc 0.6364 | lr 2.20e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.9359 | val_loss 1.0041 | train_acc 0.6536 | val_acc 0.6264 | lr 2.18e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.9278 | val_loss 1.0229 | train_acc 0.6581 | val_acc 0.6201 | lr 2.16e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.9127 | val_loss 1.0045 | train_acc 0.6656 | val_acc 0.6271 | lr 2.14e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.9071 | val_loss 1.0004 | train_acc 0.6684 | val_acc 0.6323 | lr 2.12e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8885 | val_loss 1.0087 | train_acc 0.6730 | val_acc 0.6330 | lr 2.10e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8769 | val_loss 1.0068 | train_acc 0.6788 | val_acc 0.6327 | lr 2.08e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8674 | val_loss 0.9998 | train_acc 0.6847 | val_acc 0.6386 | lr 2.06e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.8554 | val_loss 1.0233 | train_acc 0.6863 | val_acc 0.6242 | lr 2.03e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.8476 | val_loss 1.0093 | train_acc 0.6901 | val_acc 0.6341 | lr 2.01e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.8500 | val_loss 1.0159 | train_acc 0.6928 | val_acc 0.6275 | lr 1.98e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.8359 | val_loss 1.0137 | train_acc 0.6945 | val_acc 0.6264 | lr 1.96e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.8321 | val_loss 1.0176 | train_acc 0.6945 | val_acc 0.6338 | lr 1.93e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.8283 | val_loss 1.0134 | train_acc 0.6971 | val_acc 0.6297 | lr 1.90e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.8163 | val_loss 1.0134 | train_acc 0.6977 | val_acc 0.6286 | lr 1.87e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.8034 | val_loss 1.0116 | train_acc 0.7013 | val_acc 0.6371 | lr 1.84e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.7929 | val_loss 1.0223 | train_acc 0.7122 | val_acc 0.6334 | lr 1.81e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:57:35,491] Trial 12 finished with value: 0.9998411295243043 and parameters: {'lr': 0.00023236815511415386, 'num_layers': 2, 'hidden_width': 128, 'batch_size': 32, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 032 | train_loss 0.7999 | val_loss 1.0213 | train_acc 0.7035 | val_acc 0.6290 | lr 1.78e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6098 | val_loss 1.3690 | train_acc 0.4579 | val_acc 0.5595 | lr 1.01e-04 | 0.4s\n",
      "epoch 002 | train_loss 1.2780 | val_loss 1.1908 | train_acc 0.5493 | val_acc 0.5876 | lr 1.01e-04 | 0.3s\n",
      "epoch 003 | train_loss 1.1906 | val_loss 1.1302 | train_acc 0.5804 | val_acc 0.5983 | lr 1.01e-04 | 0.3s\n",
      "epoch 004 | train_loss 1.1281 | val_loss 1.0939 | train_acc 0.5983 | val_acc 0.6083 | lr 1.01e-04 | 0.3s\n",
      "epoch 005 | train_loss 1.0966 | val_loss 1.0712 | train_acc 0.6067 | val_acc 0.6112 | lr 1.01e-04 | 0.3s\n",
      "epoch 006 | train_loss 1.0535 | val_loss 1.0551 | train_acc 0.6176 | val_acc 0.6197 | lr 1.01e-04 | 0.3s\n",
      "epoch 007 | train_loss 1.0348 | val_loss 1.0451 | train_acc 0.6284 | val_acc 0.6194 | lr 1.01e-04 | 0.3s\n",
      "epoch 008 | train_loss 1.0117 | val_loss 1.0354 | train_acc 0.6389 | val_acc 0.6253 | lr 1.01e-04 | 0.3s\n",
      "epoch 009 | train_loss 0.9813 | val_loss 1.0254 | train_acc 0.6439 | val_acc 0.6275 | lr 1.01e-04 | 0.3s\n",
      "epoch 010 | train_loss 0.9603 | val_loss 1.0166 | train_acc 0.6536 | val_acc 0.6341 | lr 1.01e-04 | 0.3s\n",
      "epoch 011 | train_loss 0.9378 | val_loss 1.0184 | train_acc 0.6590 | val_acc 0.6353 | lr 1.01e-04 | 0.3s\n",
      "epoch 012 | train_loss 0.9226 | val_loss 1.0107 | train_acc 0.6636 | val_acc 0.6312 | lr 1.01e-04 | 0.3s\n",
      "epoch 013 | train_loss 0.9073 | val_loss 0.9994 | train_acc 0.6746 | val_acc 0.6441 | lr 1.01e-04 | 0.3s\n",
      "epoch 014 | train_loss 0.8890 | val_loss 0.9924 | train_acc 0.6758 | val_acc 0.6390 | lr 1.01e-04 | 0.3s\n",
      "epoch 015 | train_loss 0.8677 | val_loss 0.9934 | train_acc 0.6834 | val_acc 0.6426 | lr 1.01e-04 | 0.3s\n",
      "epoch 016 | train_loss 0.8565 | val_loss 1.0042 | train_acc 0.6904 | val_acc 0.6349 | lr 1.01e-04 | 0.3s\n",
      "epoch 017 | train_loss 0.8439 | val_loss 0.9950 | train_acc 0.6933 | val_acc 0.6382 | lr 1.01e-04 | 0.3s\n",
      "epoch 018 | train_loss 0.8236 | val_loss 1.0042 | train_acc 0.7010 | val_acc 0.6330 | lr 1.01e-04 | 0.3s\n",
      "epoch 019 | train_loss 0.8105 | val_loss 1.0014 | train_acc 0.7053 | val_acc 0.6393 | lr 1.01e-04 | 0.3s\n",
      "epoch 020 | train_loss 0.7949 | val_loss 0.9965 | train_acc 0.7103 | val_acc 0.6382 | lr 1.01e-04 | 0.3s\n",
      "epoch 021 | train_loss 0.7794 | val_loss 1.0118 | train_acc 0.7193 | val_acc 0.6260 | lr 1.01e-04 | 0.3s\n",
      "epoch 022 | train_loss 0.7702 | val_loss 1.0066 | train_acc 0.7168 | val_acc 0.6390 | lr 1.01e-04 | 0.3s\n",
      "epoch 023 | train_loss 0.7484 | val_loss 1.0044 | train_acc 0.7290 | val_acc 0.6367 | lr 1.01e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:57:43,121] Trial 13 finished with value: 0.9924260921506466 and parameters: {'lr': 0.00010116055336885013, 'num_layers': 2, 'hidden_width': 384, 'batch_size': 64, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.7391 | val_loss 0.9979 | train_acc 0.7305 | val_acc 0.6419 | lr 1.01e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2859 | val_loss 1.1599 | train_acc 0.5376 | val_acc 0.5831 | lr 1.11e-03 | 0.6s\n",
      "epoch 002 | train_loss 1.1251 | val_loss 1.1271 | train_acc 0.5920 | val_acc 0.5806 | lr 1.11e-03 | 0.6s\n",
      "epoch 003 | train_loss 1.0692 | val_loss 1.0993 | train_acc 0.6119 | val_acc 0.5846 | lr 1.11e-03 | 0.6s\n",
      "epoch 004 | train_loss 1.0222 | val_loss 1.0470 | train_acc 0.6214 | val_acc 0.6157 | lr 1.10e-03 | 0.6s\n",
      "epoch 005 | train_loss 0.9716 | val_loss 1.0503 | train_acc 0.6406 | val_acc 0.6050 | lr 1.10e-03 | 0.6s\n",
      "epoch 006 | train_loss 0.9426 | val_loss 1.0782 | train_acc 0.6485 | val_acc 0.6135 | lr 1.10e-03 | 0.6s\n",
      "epoch 007 | train_loss 0.9087 | val_loss 1.0419 | train_acc 0.6575 | val_acc 0.6245 | lr 1.10e-03 | 0.6s\n",
      "epoch 008 | train_loss 0.8753 | val_loss 1.0876 | train_acc 0.6740 | val_acc 0.6046 | lr 1.09e-03 | 0.6s\n",
      "epoch 009 | train_loss 0.8470 | val_loss 1.0675 | train_acc 0.6830 | val_acc 0.6186 | lr 1.09e-03 | 0.6s\n",
      "epoch 010 | train_loss 0.8066 | val_loss 1.0384 | train_acc 0.6945 | val_acc 0.6316 | lr 1.08e-03 | 0.6s\n",
      "epoch 011 | train_loss 0.7632 | val_loss 1.0858 | train_acc 0.7090 | val_acc 0.6282 | lr 1.08e-03 | 0.6s\n",
      "epoch 012 | train_loss 0.7441 | val_loss 1.0881 | train_acc 0.7230 | val_acc 0.6086 | lr 1.07e-03 | 0.6s\n",
      "epoch 013 | train_loss 0.7166 | val_loss 1.0880 | train_acc 0.7331 | val_acc 0.6212 | lr 1.06e-03 | 0.6s\n",
      "epoch 014 | train_loss 0.6995 | val_loss 1.1052 | train_acc 0.7356 | val_acc 0.6146 | lr 1.06e-03 | 0.6s\n",
      "epoch 015 | train_loss 0.6493 | val_loss 1.1188 | train_acc 0.7563 | val_acc 0.6234 | lr 1.05e-03 | 0.6s\n",
      "epoch 016 | train_loss 0.6271 | val_loss 1.1188 | train_acc 0.7640 | val_acc 0.6256 | lr 1.04e-03 | 0.6s\n",
      "epoch 017 | train_loss 0.6007 | val_loss 1.1712 | train_acc 0.7753 | val_acc 0.6382 | lr 1.03e-03 | 0.6s\n",
      "epoch 018 | train_loss 0.5883 | val_loss 1.1407 | train_acc 0.7831 | val_acc 0.6223 | lr 1.02e-03 | 0.6s\n",
      "epoch 019 | train_loss 0.5573 | val_loss 1.1766 | train_acc 0.7864 | val_acc 0.6319 | lr 1.01e-03 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:57:54,278] Trial 14 finished with value: 1.0384072164033662 and parameters: {'lr': 0.001108891693116283, 'num_layers': 2, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.5215 | val_loss 1.1856 | train_acc 0.8034 | val_acc 0.6341 | lr 1.00e-03 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4829 | val_loss 1.2369 | train_acc 0.4863 | val_acc 0.5717 | lr 2.59e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2002 | val_loss 1.1297 | train_acc 0.5773 | val_acc 0.6031 | lr 2.59e-04 | 0.3s\n",
      "epoch 003 | train_loss 1.1253 | val_loss 1.0832 | train_acc 0.5939 | val_acc 0.6090 | lr 2.59e-04 | 0.3s\n",
      "epoch 004 | train_loss 1.0802 | val_loss 1.0632 | train_acc 0.6147 | val_acc 0.6142 | lr 2.59e-04 | 0.3s\n",
      "epoch 005 | train_loss 1.0439 | val_loss 1.0320 | train_acc 0.6265 | val_acc 0.6282 | lr 2.59e-04 | 0.3s\n",
      "epoch 006 | train_loss 1.0117 | val_loss 1.0203 | train_acc 0.6341 | val_acc 0.6282 | lr 2.59e-04 | 0.3s\n",
      "epoch 007 | train_loss 0.9805 | val_loss 1.0142 | train_acc 0.6465 | val_acc 0.6312 | lr 2.59e-04 | 0.3s\n",
      "epoch 008 | train_loss 0.9491 | val_loss 1.0066 | train_acc 0.6527 | val_acc 0.6356 | lr 2.59e-04 | 0.3s\n",
      "epoch 009 | train_loss 0.9275 | val_loss 1.0040 | train_acc 0.6640 | val_acc 0.6323 | lr 2.59e-04 | 0.3s\n",
      "epoch 010 | train_loss 0.8953 | val_loss 1.0206 | train_acc 0.6721 | val_acc 0.6216 | lr 2.59e-04 | 0.3s\n",
      "epoch 011 | train_loss 0.8917 | val_loss 1.0079 | train_acc 0.6748 | val_acc 0.6308 | lr 2.59e-04 | 0.3s\n",
      "epoch 012 | train_loss 0.8697 | val_loss 1.0277 | train_acc 0.6837 | val_acc 0.6179 | lr 2.59e-04 | 0.3s\n",
      "epoch 013 | train_loss 0.8457 | val_loss 1.0044 | train_acc 0.6934 | val_acc 0.6334 | lr 2.59e-04 | 0.3s\n",
      "epoch 014 | train_loss 0.8268 | val_loss 1.0222 | train_acc 0.6989 | val_acc 0.6297 | lr 2.59e-04 | 0.3s\n",
      "epoch 015 | train_loss 0.8172 | val_loss 1.0251 | train_acc 0.7010 | val_acc 0.6305 | lr 2.59e-04 | 0.3s\n",
      "epoch 016 | train_loss 0.7952 | val_loss 1.0131 | train_acc 0.7084 | val_acc 0.6301 | lr 2.59e-04 | 0.3s\n",
      "epoch 017 | train_loss 0.7746 | val_loss 1.0099 | train_acc 0.7137 | val_acc 0.6290 | lr 2.59e-04 | 0.3s\n",
      "epoch 018 | train_loss 0.7660 | val_loss 1.0217 | train_acc 0.7206 | val_acc 0.6367 | lr 2.59e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:00,313] Trial 15 finished with value: 1.0039938174612153 and parameters: {'lr': 0.00025926127909686253, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 64, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 019 | train_loss 0.7491 | val_loss 1.0192 | train_acc 0.7232 | val_acc 0.6297 | lr 2.59e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3260 | val_loss 1.2115 | train_acc 0.5286 | val_acc 0.5565 | lr 6.25e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.1428 | val_loss 1.0748 | train_acc 0.5920 | val_acc 0.6042 | lr 6.24e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.0827 | val_loss 1.0894 | train_acc 0.6023 | val_acc 0.5976 | lr 6.23e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.0459 | val_loss 1.0351 | train_acc 0.6164 | val_acc 0.6112 | lr 6.22e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.0052 | val_loss 1.0214 | train_acc 0.6265 | val_acc 0.6212 | lr 6.21e-04 | 0.6s\n",
      "epoch 006 | train_loss 0.9695 | val_loss 1.0687 | train_acc 0.6447 | val_acc 0.6072 | lr 6.19e-04 | 0.6s\n",
      "epoch 007 | train_loss 0.9449 | val_loss 1.0175 | train_acc 0.6499 | val_acc 0.6312 | lr 6.17e-04 | 0.6s\n",
      "epoch 008 | train_loss 0.9186 | val_loss 1.0219 | train_acc 0.6612 | val_acc 0.6271 | lr 6.15e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.8792 | val_loss 1.0266 | train_acc 0.6708 | val_acc 0.6208 | lr 6.12e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.8650 | val_loss 1.0666 | train_acc 0.6793 | val_acc 0.6068 | lr 6.10e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.8408 | val_loss 1.0330 | train_acc 0.6869 | val_acc 0.6194 | lr 6.06e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.7981 | val_loss 1.0336 | train_acc 0.7015 | val_acc 0.6286 | lr 6.03e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.7791 | val_loss 1.0533 | train_acc 0.7060 | val_acc 0.6305 | lr 5.99e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.7540 | val_loss 1.0738 | train_acc 0.7225 | val_acc 0.6360 | lr 5.95e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.7399 | val_loss 1.0763 | train_acc 0.7231 | val_acc 0.6386 | lr 5.91e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.7179 | val_loss 1.0960 | train_acc 0.7274 | val_acc 0.6216 | lr 5.86e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:11,357] Trial 16 finished with value: 1.017547747688829 and parameters: {'lr': 0.0006248417062760933, 'num_layers': 3, 'hidden_width': 512, 'batch_size': 32, 'use_scheduler': True}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.6851 | val_loss 1.1185 | train_acc 0.7494 | val_acc 0.6371 | lr 5.81e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5000 | val_loss 1.2202 | train_acc 0.4848 | val_acc 0.5780 | lr 1.83e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2199 | val_loss 1.1239 | train_acc 0.5682 | val_acc 0.5965 | lr 1.83e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1424 | val_loss 1.0797 | train_acc 0.5920 | val_acc 0.6064 | lr 1.83e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.0908 | val_loss 1.0555 | train_acc 0.6092 | val_acc 0.6142 | lr 1.83e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0577 | val_loss 1.0394 | train_acc 0.6156 | val_acc 0.6268 | lr 1.83e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0264 | val_loss 1.0300 | train_acc 0.6275 | val_acc 0.6183 | lr 1.83e-04 | 0.5s\n",
      "epoch 007 | train_loss 0.9902 | val_loss 1.0116 | train_acc 0.6421 | val_acc 0.6308 | lr 1.83e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9720 | val_loss 1.0092 | train_acc 0.6517 | val_acc 0.6341 | lr 1.83e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9548 | val_loss 1.0079 | train_acc 0.6503 | val_acc 0.6327 | lr 1.83e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9246 | val_loss 0.9989 | train_acc 0.6657 | val_acc 0.6330 | lr 1.83e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9116 | val_loss 1.0023 | train_acc 0.6630 | val_acc 0.6341 | lr 1.83e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.8976 | val_loss 1.0032 | train_acc 0.6688 | val_acc 0.6282 | lr 1.83e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.8740 | val_loss 0.9994 | train_acc 0.6815 | val_acc 0.6408 | lr 1.83e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8553 | val_loss 1.0057 | train_acc 0.6898 | val_acc 0.6375 | lr 1.83e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.8422 | val_loss 1.0134 | train_acc 0.6916 | val_acc 0.6290 | lr 1.83e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8245 | val_loss 1.0054 | train_acc 0.7016 | val_acc 0.6349 | lr 1.83e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8038 | val_loss 1.0137 | train_acc 0.7034 | val_acc 0.6467 | lr 1.83e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.7892 | val_loss 1.0150 | train_acc 0.7071 | val_acc 0.6319 | lr 1.83e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.7754 | val_loss 1.0222 | train_acc 0.7145 | val_acc 0.6356 | lr 1.83e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:22,454] Trial 17 finished with value: 0.9989291962569322 and parameters: {'lr': 0.00018304261005862218, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.7559 | val_loss 1.0086 | train_acc 0.7222 | val_acc 0.6463 | lr 1.83e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3717 | val_loss 1.1665 | train_acc 0.5157 | val_acc 0.5817 | lr 1.30e-03 | 0.4s\n",
      "epoch 002 | train_loss 1.1611 | val_loss 1.0963 | train_acc 0.5779 | val_acc 0.5990 | lr 1.30e-03 | 0.3s\n",
      "epoch 003 | train_loss 1.1155 | val_loss 1.0776 | train_acc 0.5930 | val_acc 0.6046 | lr 1.30e-03 | 0.3s\n",
      "epoch 004 | train_loss 1.0830 | val_loss 1.0385 | train_acc 0.6089 | val_acc 0.6190 | lr 1.30e-03 | 0.3s\n",
      "epoch 005 | train_loss 1.0591 | val_loss 1.0197 | train_acc 0.6118 | val_acc 0.6190 | lr 1.30e-03 | 0.3s\n",
      "epoch 006 | train_loss 1.0252 | val_loss 1.0297 | train_acc 0.6260 | val_acc 0.6238 | lr 1.30e-03 | 0.3s\n",
      "epoch 007 | train_loss 1.0044 | val_loss 1.0467 | train_acc 0.6294 | val_acc 0.6179 | lr 1.30e-03 | 0.3s\n",
      "epoch 008 | train_loss 0.9815 | val_loss 1.0276 | train_acc 0.6367 | val_acc 0.6216 | lr 1.30e-03 | 0.3s\n",
      "epoch 009 | train_loss 0.9627 | val_loss 1.0272 | train_acc 0.6484 | val_acc 0.6164 | lr 1.30e-03 | 0.3s\n",
      "epoch 010 | train_loss 0.9435 | val_loss 1.0180 | train_acc 0.6514 | val_acc 0.6249 | lr 1.30e-03 | 0.3s\n",
      "epoch 011 | train_loss 0.9294 | val_loss 1.0131 | train_acc 0.6605 | val_acc 0.6319 | lr 1.30e-03 | 0.3s\n",
      "epoch 012 | train_loss 0.9279 | val_loss 1.0127 | train_acc 0.6581 | val_acc 0.6249 | lr 1.30e-03 | 0.3s\n",
      "epoch 013 | train_loss 0.8999 | val_loss 1.0144 | train_acc 0.6702 | val_acc 0.6197 | lr 1.30e-03 | 0.3s\n",
      "epoch 014 | train_loss 0.8863 | val_loss 1.0204 | train_acc 0.6753 | val_acc 0.6253 | lr 1.30e-03 | 0.3s\n",
      "epoch 015 | train_loss 0.8711 | val_loss 1.0081 | train_acc 0.6760 | val_acc 0.6371 | lr 1.30e-03 | 0.3s\n",
      "epoch 016 | train_loss 0.8662 | val_loss 1.0224 | train_acc 0.6783 | val_acc 0.6260 | lr 1.30e-03 | 0.3s\n",
      "epoch 017 | train_loss 0.8466 | val_loss 1.0137 | train_acc 0.6893 | val_acc 0.6271 | lr 1.30e-03 | 0.3s\n",
      "epoch 018 | train_loss 0.8315 | val_loss 1.0169 | train_acc 0.6888 | val_acc 0.6327 | lr 1.30e-03 | 0.3s\n",
      "epoch 019 | train_loss 0.8136 | val_loss 1.0211 | train_acc 0.7008 | val_acc 0.6279 | lr 1.30e-03 | 0.3s\n",
      "epoch 020 | train_loss 0.8023 | val_loss 1.0389 | train_acc 0.7054 | val_acc 0.6349 | lr 1.30e-03 | 0.3s\n",
      "epoch 021 | train_loss 0.7932 | val_loss 1.0239 | train_acc 0.7084 | val_acc 0.6323 | lr 1.30e-03 | 0.3s\n",
      "epoch 022 | train_loss 0.7865 | val_loss 1.0386 | train_acc 0.7073 | val_acc 0.6353 | lr 1.30e-03 | 0.3s\n",
      "epoch 023 | train_loss 0.7843 | val_loss 1.0486 | train_acc 0.7036 | val_acc 0.6316 | lr 1.30e-03 | 0.3s\n",
      "epoch 024 | train_loss 0.7762 | val_loss 1.0476 | train_acc 0.7154 | val_acc 0.6301 | lr 1.30e-03 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:30,355] Trial 18 finished with value: 1.008149977269564 and parameters: {'lr': 0.0013039463440947191, 'num_layers': 2, 'hidden_width': 128, 'batch_size': 64, 'use_scheduler': False}. Best is trial 2 with value: 0.9882662446077718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7543 | val_loss 1.0477 | train_acc 0.7236 | val_acc 0.6279 | lr 1.30e-03 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7144 | val_loss 1.7849 | train_acc 0.4238 | val_acc 0.5455 | lr 1.51e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.3128 | val_loss 1.3854 | train_acc 0.5477 | val_acc 0.5776 | lr 1.51e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.2027 | val_loss 1.2022 | train_acc 0.5767 | val_acc 0.5902 | lr 1.51e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.1428 | val_loss 1.1128 | train_acc 0.5947 | val_acc 0.6061 | lr 1.51e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.1059 | val_loss 1.0786 | train_acc 0.6011 | val_acc 0.6157 | lr 1.50e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0700 | val_loss 1.0555 | train_acc 0.6162 | val_acc 0.6205 | lr 1.50e-04 | 0.2s\n",
      "epoch 007 | train_loss 1.0415 | val_loss 1.0363 | train_acc 0.6282 | val_acc 0.6253 | lr 1.50e-04 | 0.2s\n",
      "epoch 008 | train_loss 1.0104 | val_loss 1.0215 | train_acc 0.6343 | val_acc 0.6279 | lr 1.49e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.9893 | val_loss 1.0067 | train_acc 0.6427 | val_acc 0.6334 | lr 1.48e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.9679 | val_loss 1.0068 | train_acc 0.6472 | val_acc 0.6312 | lr 1.48e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.9418 | val_loss 0.9986 | train_acc 0.6577 | val_acc 0.6404 | lr 1.47e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.9254 | val_loss 0.9982 | train_acc 0.6639 | val_acc 0.6423 | lr 1.46e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.9049 | val_loss 0.9958 | train_acc 0.6733 | val_acc 0.6360 | lr 1.45e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8879 | val_loss 0.9913 | train_acc 0.6766 | val_acc 0.6412 | lr 1.44e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.8675 | val_loss 0.9983 | train_acc 0.6849 | val_acc 0.6349 | lr 1.43e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.8526 | val_loss 0.9909 | train_acc 0.6916 | val_acc 0.6456 | lr 1.42e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.8345 | val_loss 0.9847 | train_acc 0.6958 | val_acc 0.6415 | lr 1.41e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.8216 | val_loss 0.9957 | train_acc 0.7008 | val_acc 0.6449 | lr 1.40e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.8064 | val_loss 0.9882 | train_acc 0.7084 | val_acc 0.6463 | lr 1.38e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.7912 | val_loss 0.9942 | train_acc 0.7095 | val_acc 0.6456 | lr 1.37e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.7719 | val_loss 1.0132 | train_acc 0.7195 | val_acc 0.6423 | lr 1.35e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.7629 | val_loss 1.0001 | train_acc 0.7236 | val_acc 0.6467 | lr 1.34e-04 | 0.2s\n",
      "epoch 023 | train_loss 0.7371 | val_loss 1.0028 | train_acc 0.7327 | val_acc 0.6456 | lr 1.32e-04 | 0.2s\n",
      "epoch 024 | train_loss 0.7301 | val_loss 1.0002 | train_acc 0.7339 | val_acc 0.6497 | lr 1.31e-04 | 0.2s\n",
      "epoch 025 | train_loss 0.7104 | val_loss 1.0115 | train_acc 0.7373 | val_acc 0.6467 | lr 1.29e-04 | 0.2s\n",
      "epoch 026 | train_loss 0.7000 | val_loss 1.0232 | train_acc 0.7441 | val_acc 0.6397 | lr 1.27e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:36,318] Trial 19 finished with value: 0.9847252363640558 and parameters: {'lr': 0.00015136237612748744, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 027 | train_loss 0.6813 | val_loss 1.0199 | train_acc 0.7509 | val_acc 0.6397 | lr 1.26e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5073 | val_loss 1.4773 | train_acc 0.4766 | val_acc 0.5691 | lr 3.62e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.1835 | val_loss 1.1996 | train_acc 0.5748 | val_acc 0.6035 | lr 3.62e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.1146 | val_loss 1.0834 | train_acc 0.5988 | val_acc 0.6168 | lr 3.62e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.0472 | val_loss 1.0657 | train_acc 0.6163 | val_acc 0.6138 | lr 3.62e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.0167 | val_loss 1.0448 | train_acc 0.6324 | val_acc 0.6135 | lr 3.62e-04 | 0.2s\n",
      "epoch 006 | train_loss 0.9697 | val_loss 1.0348 | train_acc 0.6519 | val_acc 0.6149 | lr 3.62e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.9400 | val_loss 1.0407 | train_acc 0.6611 | val_acc 0.6120 | lr 3.62e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.9127 | val_loss 1.0206 | train_acc 0.6634 | val_acc 0.6279 | lr 3.62e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.8866 | val_loss 1.0208 | train_acc 0.6732 | val_acc 0.6245 | lr 3.62e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.8595 | val_loss 1.0036 | train_acc 0.6872 | val_acc 0.6349 | lr 3.62e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.8308 | val_loss 1.0142 | train_acc 0.6987 | val_acc 0.6356 | lr 3.62e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8076 | val_loss 1.0133 | train_acc 0.7051 | val_acc 0.6319 | lr 3.62e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.7809 | val_loss 1.0230 | train_acc 0.7108 | val_acc 0.6353 | lr 3.62e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.7640 | val_loss 1.0396 | train_acc 0.7200 | val_acc 0.6390 | lr 3.62e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.7299 | val_loss 1.0389 | train_acc 0.7291 | val_acc 0.6426 | lr 3.62e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.7215 | val_loss 1.0487 | train_acc 0.7344 | val_acc 0.6341 | lr 3.62e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.6924 | val_loss 1.0374 | train_acc 0.7442 | val_acc 0.6415 | lr 3.62e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.6599 | val_loss 1.0907 | train_acc 0.7585 | val_acc 0.6334 | lr 3.62e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.6578 | val_loss 1.0931 | train_acc 0.7562 | val_acc 0.6390 | lr 3.62e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:40,761] Trial 20 finished with value: 1.0036424238947879 and parameters: {'lr': 0.0003624956575296438, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.6234 | val_loss 1.1105 | train_acc 0.7701 | val_acc 0.6323 | lr 3.62e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7352 | val_loss 1.7542 | train_acc 0.4137 | val_acc 0.5288 | lr 1.36e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.3460 | val_loss 1.4158 | train_acc 0.5347 | val_acc 0.5710 | lr 1.36e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.2315 | val_loss 1.2230 | train_acc 0.5637 | val_acc 0.5824 | lr 1.36e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.1669 | val_loss 1.1389 | train_acc 0.5867 | val_acc 0.5987 | lr 1.36e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.1231 | val_loss 1.1101 | train_acc 0.5997 | val_acc 0.6035 | lr 1.35e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0863 | val_loss 1.0710 | train_acc 0.6087 | val_acc 0.6090 | lr 1.35e-04 | 0.2s\n",
      "epoch 007 | train_loss 1.0577 | val_loss 1.0587 | train_acc 0.6200 | val_acc 0.6120 | lr 1.34e-04 | 0.2s\n",
      "epoch 008 | train_loss 1.0298 | val_loss 1.0518 | train_acc 0.6284 | val_acc 0.6127 | lr 1.34e-04 | 0.2s\n",
      "epoch 009 | train_loss 1.0053 | val_loss 1.0314 | train_acc 0.6358 | val_acc 0.6227 | lr 1.33e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.9927 | val_loss 1.0251 | train_acc 0.6374 | val_acc 0.6231 | lr 1.33e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.9641 | val_loss 1.0201 | train_acc 0.6471 | val_acc 0.6245 | lr 1.32e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.9399 | val_loss 1.0147 | train_acc 0.6573 | val_acc 0.6286 | lr 1.31e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.9285 | val_loss 1.0178 | train_acc 0.6594 | val_acc 0.6234 | lr 1.30e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.9143 | val_loss 1.0030 | train_acc 0.6704 | val_acc 0.6297 | lr 1.30e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.8963 | val_loss 1.0016 | train_acc 0.6742 | val_acc 0.6334 | lr 1.29e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.8747 | val_loss 0.9929 | train_acc 0.6798 | val_acc 0.6364 | lr 1.28e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.8625 | val_loss 0.9970 | train_acc 0.6905 | val_acc 0.6356 | lr 1.27e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.8495 | val_loss 0.9998 | train_acc 0.6914 | val_acc 0.6242 | lr 1.25e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.8223 | val_loss 0.9915 | train_acc 0.6995 | val_acc 0.6382 | lr 1.24e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.8028 | val_loss 1.0075 | train_acc 0.7058 | val_acc 0.6338 | lr 1.23e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.8087 | val_loss 0.9993 | train_acc 0.7055 | val_acc 0.6345 | lr 1.22e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.7831 | val_loss 1.0083 | train_acc 0.7196 | val_acc 0.6349 | lr 1.20e-04 | 0.2s\n",
      "epoch 023 | train_loss 0.7671 | val_loss 1.0016 | train_acc 0.7206 | val_acc 0.6382 | lr 1.19e-04 | 0.2s\n",
      "epoch 024 | train_loss 0.7556 | val_loss 1.0033 | train_acc 0.7266 | val_acc 0.6349 | lr 1.18e-04 | 0.2s\n",
      "epoch 025 | train_loss 0.7471 | val_loss 1.0008 | train_acc 0.7302 | val_acc 0.6412 | lr 1.16e-04 | 0.2s\n",
      "epoch 026 | train_loss 0.7306 | val_loss 1.0163 | train_acc 0.7395 | val_acc 0.6323 | lr 1.15e-04 | 0.2s\n",
      "epoch 027 | train_loss 0.7222 | val_loss 1.0030 | train_acc 0.7353 | val_acc 0.6386 | lr 1.13e-04 | 0.2s\n",
      "epoch 028 | train_loss 0.7108 | val_loss 1.0051 | train_acc 0.7413 | val_acc 0.6401 | lr 1.11e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:47,170] Trial 21 finished with value: 0.9915366482928516 and parameters: {'lr': 0.00013604273106933905, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.6904 | val_loss 1.0172 | train_acc 0.7497 | val_acc 0.6408 | lr 1.10e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6087 | val_loss 1.6189 | train_acc 0.4512 | val_acc 0.5569 | lr 2.21e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2502 | val_loss 1.2822 | train_acc 0.5587 | val_acc 0.5913 | lr 2.21e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.1575 | val_loss 1.1503 | train_acc 0.5878 | val_acc 0.6031 | lr 2.21e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.1041 | val_loss 1.1000 | train_acc 0.6052 | val_acc 0.6020 | lr 2.20e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.0690 | val_loss 1.0622 | train_acc 0.6163 | val_acc 0.6109 | lr 2.20e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0283 | val_loss 1.0373 | train_acc 0.6239 | val_acc 0.6149 | lr 2.19e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.9933 | val_loss 1.0421 | train_acc 0.6359 | val_acc 0.6160 | lr 2.19e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.9776 | val_loss 1.0096 | train_acc 0.6422 | val_acc 0.6319 | lr 2.18e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.9451 | val_loss 1.0016 | train_acc 0.6583 | val_acc 0.6349 | lr 2.17e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.9193 | val_loss 1.0097 | train_acc 0.6620 | val_acc 0.6305 | lr 2.16e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.9002 | val_loss 1.0115 | train_acc 0.6754 | val_acc 0.6282 | lr 2.15e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8659 | val_loss 1.0009 | train_acc 0.6853 | val_acc 0.6345 | lr 2.14e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.8427 | val_loss 0.9888 | train_acc 0.6954 | val_acc 0.6408 | lr 2.12e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8234 | val_loss 0.9998 | train_acc 0.6999 | val_acc 0.6426 | lr 2.11e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.8116 | val_loss 0.9930 | train_acc 0.7057 | val_acc 0.6408 | lr 2.09e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.7884 | val_loss 1.0145 | train_acc 0.7137 | val_acc 0.6353 | lr 2.08e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.7657 | val_loss 0.9989 | train_acc 0.7250 | val_acc 0.6463 | lr 2.06e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.7475 | val_loss 1.0119 | train_acc 0.7307 | val_acc 0.6452 | lr 2.04e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.7237 | val_loss 1.0182 | train_acc 0.7412 | val_acc 0.6378 | lr 2.02e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.7095 | val_loss 1.0092 | train_acc 0.7438 | val_acc 0.6415 | lr 2.00e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.6973 | val_loss 1.0118 | train_acc 0.7469 | val_acc 0.6438 | lr 1.98e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.6717 | val_loss 1.0270 | train_acc 0.7566 | val_acc 0.6449 | lr 1.96e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:52,264] Trial 22 finished with value: 0.9887847939157873 and parameters: {'lr': 0.00022135310889973472, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.6717 | val_loss 1.0415 | train_acc 0.7547 | val_acc 0.6412 | lr 1.94e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6269 | val_loss 1.6923 | train_acc 0.4412 | val_acc 0.5569 | lr 2.36e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2436 | val_loss 1.2801 | train_acc 0.5624 | val_acc 0.5916 | lr 2.35e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.1500 | val_loss 1.1341 | train_acc 0.5881 | val_acc 0.6112 | lr 2.35e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.0907 | val_loss 1.0891 | train_acc 0.6065 | val_acc 0.6142 | lr 2.35e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.0522 | val_loss 1.0691 | train_acc 0.6188 | val_acc 0.6053 | lr 2.34e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0204 | val_loss 1.0320 | train_acc 0.6291 | val_acc 0.6268 | lr 2.33e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.9877 | val_loss 1.0217 | train_acc 0.6446 | val_acc 0.6268 | lr 2.33e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.9580 | val_loss 1.0172 | train_acc 0.6484 | val_acc 0.6282 | lr 2.32e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.9271 | val_loss 1.0241 | train_acc 0.6652 | val_acc 0.6223 | lr 2.31e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.9031 | val_loss 1.0132 | train_acc 0.6655 | val_acc 0.6308 | lr 2.30e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.8702 | val_loss 1.0240 | train_acc 0.6834 | val_acc 0.6279 | lr 2.29e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8612 | val_loss 1.0030 | train_acc 0.6835 | val_acc 0.6419 | lr 2.27e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.8293 | val_loss 1.0160 | train_acc 0.7010 | val_acc 0.6286 | lr 2.26e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8229 | val_loss 1.0010 | train_acc 0.7024 | val_acc 0.6338 | lr 2.24e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.7980 | val_loss 1.0174 | train_acc 0.7030 | val_acc 0.6349 | lr 2.23e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.7709 | val_loss 1.0108 | train_acc 0.7152 | val_acc 0.6356 | lr 2.21e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.7628 | val_loss 1.0186 | train_acc 0.7229 | val_acc 0.6353 | lr 2.19e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.7330 | val_loss 1.0281 | train_acc 0.7334 | val_acc 0.6367 | lr 2.17e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.7156 | val_loss 1.0498 | train_acc 0.7340 | val_acc 0.6353 | lr 2.15e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.7054 | val_loss 1.0235 | train_acc 0.7441 | val_acc 0.6438 | lr 2.13e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.6844 | val_loss 1.0296 | train_acc 0.7527 | val_acc 0.6441 | lr 2.11e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.6613 | val_loss 1.0698 | train_acc 0.7591 | val_acc 0.6290 | lr 2.09e-04 | 0.2s\n",
      "epoch 023 | train_loss 0.6470 | val_loss 1.0465 | train_acc 0.7607 | val_acc 0.6371 | lr 2.06e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:58:57,576] Trial 23 finished with value: 1.0009909920223712 and parameters: {'lr': 0.00023558160090337546, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.6331 | val_loss 1.0506 | train_acc 0.7691 | val_acc 0.6419 | lr 2.04e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4049 | val_loss 1.3060 | train_acc 0.5066 | val_acc 0.5595 | lr 5.60e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.1566 | val_loss 1.1297 | train_acc 0.5822 | val_acc 0.6053 | lr 5.59e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.0806 | val_loss 1.0588 | train_acc 0.6062 | val_acc 0.6098 | lr 5.59e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.0267 | val_loss 1.0527 | train_acc 0.6300 | val_acc 0.6031 | lr 5.58e-04 | 0.2s\n",
      "epoch 005 | train_loss 0.9851 | val_loss 1.0177 | train_acc 0.6450 | val_acc 0.6297 | lr 5.57e-04 | 0.2s\n",
      "epoch 006 | train_loss 0.9429 | val_loss 1.0365 | train_acc 0.6560 | val_acc 0.6171 | lr 5.55e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.9158 | val_loss 1.0097 | train_acc 0.6620 | val_acc 0.6334 | lr 5.53e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.8843 | val_loss 1.0058 | train_acc 0.6771 | val_acc 0.6334 | lr 5.51e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.8494 | val_loss 1.0101 | train_acc 0.6845 | val_acc 0.6312 | lr 5.49e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.8273 | val_loss 1.0404 | train_acc 0.6982 | val_acc 0.6323 | lr 5.46e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.7975 | val_loss 1.0186 | train_acc 0.7123 | val_acc 0.6279 | lr 5.43e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.7696 | val_loss 1.0237 | train_acc 0.7135 | val_acc 0.6253 | lr 5.40e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.7396 | val_loss 1.0308 | train_acc 0.7295 | val_acc 0.6327 | lr 5.37e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.7343 | val_loss 1.0559 | train_acc 0.7340 | val_acc 0.6290 | lr 5.33e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.7022 | val_loss 1.0616 | train_acc 0.7397 | val_acc 0.6249 | lr 5.30e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.6646 | val_loss 1.0855 | train_acc 0.7561 | val_acc 0.6423 | lr 5.25e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.6514 | val_loss 1.0845 | train_acc 0.7587 | val_acc 0.6245 | lr 5.21e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:01,577] Trial 24 finished with value: 1.005836913432356 and parameters: {'lr': 0.000560042237163493, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.6358 | val_loss 1.1186 | train_acc 0.7664 | val_acc 0.6323 | lr 5.16e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6144 | val_loss 1.6701 | train_acc 0.4547 | val_acc 0.5647 | lr 1.95e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2631 | val_loss 1.3137 | train_acc 0.5597 | val_acc 0.5957 | lr 1.95e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.1713 | val_loss 1.1657 | train_acc 0.5810 | val_acc 0.5931 | lr 1.94e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.1108 | val_loss 1.1006 | train_acc 0.6023 | val_acc 0.6098 | lr 1.94e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.0765 | val_loss 1.0568 | train_acc 0.6107 | val_acc 0.6227 | lr 1.94e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0411 | val_loss 1.0437 | train_acc 0.6241 | val_acc 0.6234 | lr 1.93e-04 | 0.2s\n",
      "epoch 007 | train_loss 1.0052 | val_loss 1.0392 | train_acc 0.6377 | val_acc 0.6160 | lr 1.92e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.9687 | val_loss 1.0135 | train_acc 0.6491 | val_acc 0.6238 | lr 1.92e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.9474 | val_loss 1.0143 | train_acc 0.6568 | val_acc 0.6286 | lr 1.91e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.9249 | val_loss 1.0028 | train_acc 0.6613 | val_acc 0.6301 | lr 1.90e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.9062 | val_loss 0.9935 | train_acc 0.6650 | val_acc 0.6323 | lr 1.89e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8900 | val_loss 0.9980 | train_acc 0.6753 | val_acc 0.6364 | lr 1.88e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.8657 | val_loss 0.9932 | train_acc 0.6876 | val_acc 0.6360 | lr 1.87e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8378 | val_loss 0.9960 | train_acc 0.6924 | val_acc 0.6367 | lr 1.85e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.8171 | val_loss 1.0182 | train_acc 0.7027 | val_acc 0.6319 | lr 1.84e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.8084 | val_loss 1.0176 | train_acc 0.7030 | val_acc 0.6371 | lr 1.83e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.7825 | val_loss 1.0089 | train_acc 0.7131 | val_acc 0.6386 | lr 1.81e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.7747 | val_loss 0.9991 | train_acc 0.7197 | val_acc 0.6504 | lr 1.80e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.7558 | val_loss 1.0200 | train_acc 0.7229 | val_acc 0.6364 | lr 1.78e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.7308 | val_loss 1.0051 | train_acc 0.7369 | val_acc 0.6397 | lr 1.76e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.7030 | val_loss 1.0367 | train_acc 0.7444 | val_acc 0.6356 | lr 1.74e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.7001 | val_loss 1.0135 | train_acc 0.7452 | val_acc 0.6467 | lr 1.72e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:06,674] Trial 25 finished with value: 0.9931784645328677 and parameters: {'lr': 0.00019475371236339918, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.6860 | val_loss 1.0294 | train_acc 0.7477 | val_acc 0.6360 | lr 1.70e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5817 | val_loss 1.5971 | train_acc 0.4562 | val_acc 0.5628 | lr 2.60e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2294 | val_loss 1.2568 | train_acc 0.5669 | val_acc 0.5880 | lr 2.60e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.1406 | val_loss 1.1201 | train_acc 0.5917 | val_acc 0.6024 | lr 2.60e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.0801 | val_loss 1.0821 | train_acc 0.6076 | val_acc 0.6086 | lr 2.59e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.0418 | val_loss 1.0432 | train_acc 0.6223 | val_acc 0.6075 | lr 2.59e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.0013 | val_loss 1.0334 | train_acc 0.6317 | val_acc 0.6190 | lr 2.58e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.9695 | val_loss 1.0225 | train_acc 0.6474 | val_acc 0.6234 | lr 2.57e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.9473 | val_loss 1.0048 | train_acc 0.6614 | val_acc 0.6223 | lr 2.56e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.9140 | val_loss 1.0127 | train_acc 0.6705 | val_acc 0.6312 | lr 2.55e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.8968 | val_loss 0.9994 | train_acc 0.6742 | val_acc 0.6471 | lr 2.54e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.8694 | val_loss 1.0086 | train_acc 0.6854 | val_acc 0.6256 | lr 2.53e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8401 | val_loss 1.0072 | train_acc 0.6933 | val_acc 0.6378 | lr 2.51e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.8155 | val_loss 1.0130 | train_acc 0.7022 | val_acc 0.6371 | lr 2.50e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8035 | val_loss 1.0037 | train_acc 0.7063 | val_acc 0.6456 | lr 2.48e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.7810 | val_loss 1.0263 | train_acc 0.7173 | val_acc 0.6260 | lr 2.46e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.7542 | val_loss 1.0195 | train_acc 0.7220 | val_acc 0.6371 | lr 2.44e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.7308 | val_loss 1.0331 | train_acc 0.7302 | val_acc 0.6330 | lr 2.42e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.7176 | val_loss 1.0147 | train_acc 0.7365 | val_acc 0.6482 | lr 2.40e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.6965 | val_loss 1.0368 | train_acc 0.7443 | val_acc 0.6467 | lr 2.38e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:11,129] Trial 26 finished with value: 0.9994087938194529 and parameters: {'lr': 0.00026049760624095457, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.6808 | val_loss 1.0608 | train_acc 0.7522 | val_acc 0.6349 | lr 2.36e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3533 | val_loss 1.3859 | train_acc 0.5259 | val_acc 0.5843 | lr 3.90e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.0967 | val_loss 1.1159 | train_acc 0.6058 | val_acc 0.6179 | lr 3.90e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.0173 | val_loss 1.0409 | train_acc 0.6258 | val_acc 0.6142 | lr 3.89e-04 | 0.2s\n",
      "epoch 004 | train_loss 0.9662 | val_loss 1.0358 | train_acc 0.6470 | val_acc 0.6175 | lr 3.89e-04 | 0.2s\n",
      "epoch 005 | train_loss 0.9070 | val_loss 1.0479 | train_acc 0.6684 | val_acc 0.6101 | lr 3.88e-04 | 0.2s\n",
      "epoch 006 | train_loss 0.8524 | val_loss 1.0497 | train_acc 0.6873 | val_acc 0.6208 | lr 3.87e-04 | 0.2s\n",
      "epoch 007 | train_loss 0.8128 | val_loss 1.0254 | train_acc 0.7007 | val_acc 0.6290 | lr 3.86e-04 | 0.2s\n",
      "epoch 008 | train_loss 0.7790 | val_loss 1.0121 | train_acc 0.7122 | val_acc 0.6345 | lr 3.84e-04 | 0.2s\n",
      "epoch 009 | train_loss 0.7320 | val_loss 1.0560 | train_acc 0.7326 | val_acc 0.6297 | lr 3.83e-04 | 0.2s\n",
      "epoch 010 | train_loss 0.7045 | val_loss 1.0476 | train_acc 0.7368 | val_acc 0.6371 | lr 3.81e-04 | 0.2s\n",
      "epoch 011 | train_loss 0.6591 | val_loss 1.0729 | train_acc 0.7549 | val_acc 0.6382 | lr 3.79e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.6301 | val_loss 1.1008 | train_acc 0.7670 | val_acc 0.6253 | lr 3.77e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.5971 | val_loss 1.1405 | train_acc 0.7786 | val_acc 0.6242 | lr 3.74e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.5623 | val_loss 1.1425 | train_acc 0.7943 | val_acc 0.6275 | lr 3.72e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.5189 | val_loss 1.1500 | train_acc 0.8093 | val_acc 0.6323 | lr 3.69e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.5052 | val_loss 1.1762 | train_acc 0.8128 | val_acc 0.6353 | lr 3.66e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.4857 | val_loss 1.2051 | train_acc 0.8191 | val_acc 0.6293 | lr 3.63e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:15,175] Trial 27 finished with value: 1.0120931307827201 and parameters: {'lr': 0.0003903554636211914, 'num_layers': 3, 'hidden_width': 768, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.4533 | val_loss 1.2002 | train_acc 0.8307 | val_acc 0.6286 | lr 3.60e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.8251 | val_loss 1.8661 | train_acc 0.3872 | val_acc 0.5018 | lr 1.51e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.4235 | val_loss 1.4850 | train_acc 0.5171 | val_acc 0.5540 | lr 1.51e-04 | 0.2s\n",
      "epoch 003 | train_loss 1.3002 | val_loss 1.2694 | train_acc 0.5481 | val_acc 0.5743 | lr 1.51e-04 | 0.2s\n",
      "epoch 004 | train_loss 1.2303 | val_loss 1.1815 | train_acc 0.5679 | val_acc 0.5891 | lr 1.51e-04 | 0.2s\n",
      "epoch 005 | train_loss 1.1851 | val_loss 1.1378 | train_acc 0.5816 | val_acc 0.5935 | lr 1.51e-04 | 0.2s\n",
      "epoch 006 | train_loss 1.1410 | val_loss 1.1013 | train_acc 0.5949 | val_acc 0.6046 | lr 1.51e-04 | 0.2s\n",
      "epoch 007 | train_loss 1.1167 | val_loss 1.0746 | train_acc 0.6029 | val_acc 0.6105 | lr 1.51e-04 | 0.2s\n",
      "epoch 008 | train_loss 1.0825 | val_loss 1.0609 | train_acc 0.6138 | val_acc 0.6186 | lr 1.51e-04 | 0.2s\n",
      "epoch 009 | train_loss 1.0614 | val_loss 1.0494 | train_acc 0.6157 | val_acc 0.6146 | lr 1.51e-04 | 0.2s\n",
      "epoch 010 | train_loss 1.0477 | val_loss 1.0378 | train_acc 0.6218 | val_acc 0.6227 | lr 1.51e-04 | 0.2s\n",
      "epoch 011 | train_loss 1.0162 | val_loss 1.0276 | train_acc 0.6331 | val_acc 0.6260 | lr 1.51e-04 | 0.2s\n",
      "epoch 012 | train_loss 1.0006 | val_loss 1.0233 | train_acc 0.6367 | val_acc 0.6264 | lr 1.51e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.9857 | val_loss 1.0085 | train_acc 0.6451 | val_acc 0.6301 | lr 1.51e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.9724 | val_loss 1.0049 | train_acc 0.6484 | val_acc 0.6364 | lr 1.51e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.9527 | val_loss 1.0016 | train_acc 0.6537 | val_acc 0.6367 | lr 1.51e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.9445 | val_loss 1.0093 | train_acc 0.6521 | val_acc 0.6319 | lr 1.51e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.9283 | val_loss 1.0105 | train_acc 0.6621 | val_acc 0.6245 | lr 1.51e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.9255 | val_loss 0.9938 | train_acc 0.6617 | val_acc 0.6408 | lr 1.51e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.9035 | val_loss 1.0041 | train_acc 0.6717 | val_acc 0.6393 | lr 1.51e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.8905 | val_loss 0.9912 | train_acc 0.6721 | val_acc 0.6353 | lr 1.51e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.8798 | val_loss 0.9955 | train_acc 0.6765 | val_acc 0.6375 | lr 1.51e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.8623 | val_loss 0.9965 | train_acc 0.6880 | val_acc 0.6371 | lr 1.51e-04 | 0.2s\n",
      "epoch 023 | train_loss 0.8509 | val_loss 1.0038 | train_acc 0.6912 | val_acc 0.6312 | lr 1.51e-04 | 0.2s\n",
      "epoch 024 | train_loss 0.8376 | val_loss 0.9991 | train_acc 0.6980 | val_acc 0.6334 | lr 1.51e-04 | 0.2s\n",
      "epoch 025 | train_loss 0.8262 | val_loss 1.0015 | train_acc 0.6921 | val_acc 0.6360 | lr 1.51e-04 | 0.2s\n",
      "epoch 026 | train_loss 0.8092 | val_loss 0.9990 | train_acc 0.7001 | val_acc 0.6364 | lr 1.51e-04 | 0.2s\n",
      "epoch 027 | train_loss 0.7924 | val_loss 1.0069 | train_acc 0.7122 | val_acc 0.6364 | lr 1.51e-04 | 0.2s\n",
      "epoch 028 | train_loss 0.7975 | val_loss 1.0137 | train_acc 0.7083 | val_acc 0.6253 | lr 1.51e-04 | 0.2s\n",
      "epoch 029 | train_loss 0.7801 | val_loss 1.0021 | train_acc 0.7137 | val_acc 0.6327 | lr 1.51e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:21,774] Trial 28 finished with value: 0.9911838858020103 and parameters: {'lr': 0.00015075433864933106, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 030 | train_loss 0.7820 | val_loss 1.0028 | train_acc 0.7129 | val_acc 0.6434 | lr 1.51e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5893 | val_loss 1.2895 | train_acc 0.4528 | val_acc 0.5610 | lr 1.53e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.2922 | val_loss 1.1711 | train_acc 0.5468 | val_acc 0.5835 | lr 1.53e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.2098 | val_loss 1.0998 | train_acc 0.5650 | val_acc 0.6053 | lr 1.53e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1613 | val_loss 1.0778 | train_acc 0.5810 | val_acc 0.6101 | lr 1.53e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1190 | val_loss 1.0630 | train_acc 0.5996 | val_acc 0.6098 | lr 1.53e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0934 | val_loss 1.0421 | train_acc 0.6062 | val_acc 0.6238 | lr 1.53e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0685 | val_loss 1.0345 | train_acc 0.6168 | val_acc 0.6175 | lr 1.53e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0507 | val_loss 1.0264 | train_acc 0.6177 | val_acc 0.6220 | lr 1.53e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0290 | val_loss 1.0161 | train_acc 0.6291 | val_acc 0.6205 | lr 1.53e-04 | 0.6s\n",
      "epoch 010 | train_loss 1.0052 | val_loss 1.0058 | train_acc 0.6364 | val_acc 0.6275 | lr 1.53e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9915 | val_loss 1.0001 | train_acc 0.6416 | val_acc 0.6271 | lr 1.53e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9717 | val_loss 1.0051 | train_acc 0.6458 | val_acc 0.6275 | lr 1.53e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.9566 | val_loss 0.9999 | train_acc 0.6535 | val_acc 0.6341 | lr 1.53e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9451 | val_loss 1.0054 | train_acc 0.6500 | val_acc 0.6341 | lr 1.53e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9289 | val_loss 0.9967 | train_acc 0.6607 | val_acc 0.6341 | lr 1.53e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.9133 | val_loss 1.0022 | train_acc 0.6648 | val_acc 0.6297 | lr 1.53e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.9012 | val_loss 0.9984 | train_acc 0.6711 | val_acc 0.6323 | lr 1.53e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.8931 | val_loss 1.0058 | train_acc 0.6730 | val_acc 0.6371 | lr 1.53e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.8771 | val_loss 1.0046 | train_acc 0.6743 | val_acc 0.6356 | lr 1.53e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.8646 | val_loss 0.9982 | train_acc 0.6821 | val_acc 0.6378 | lr 1.53e-04 | 2.0s\n",
      "epoch 021 | train_loss 0.8398 | val_loss 1.0137 | train_acc 0.6968 | val_acc 0.6256 | lr 1.53e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.8314 | val_loss 1.0020 | train_acc 0.6912 | val_acc 0.6338 | lr 1.53e-04 | 2.0s\n",
      "epoch 023 | train_loss 0.8250 | val_loss 1.0032 | train_acc 0.6989 | val_acc 0.6378 | lr 1.53e-04 | 2.0s\n",
      "epoch 024 | train_loss 0.8010 | val_loss 1.0020 | train_acc 0.7058 | val_acc 0.6393 | lr 1.53e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:50,409] Trial 29 finished with value: 0.9966606226834384 and parameters: {'lr': 0.00015267734839664233, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7958 | val_loss 1.0195 | train_acc 0.7099 | val_acc 0.6312 | lr 1.53e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2851 | val_loss 1.3307 | train_acc 0.5402 | val_acc 0.5569 | lr 8.60e-04 | 0.4s\n",
      "epoch 002 | train_loss 1.0754 | val_loss 1.0996 | train_acc 0.6103 | val_acc 0.6046 | lr 8.59e-04 | 0.3s\n",
      "epoch 003 | train_loss 0.9985 | val_loss 1.0461 | train_acc 0.6352 | val_acc 0.6157 | lr 8.58e-04 | 0.3s\n",
      "epoch 004 | train_loss 0.9503 | val_loss 1.0220 | train_acc 0.6523 | val_acc 0.6356 | lr 8.57e-04 | 0.3s\n",
      "epoch 005 | train_loss 0.9170 | val_loss 1.0323 | train_acc 0.6632 | val_acc 0.6308 | lr 8.55e-04 | 0.3s\n",
      "epoch 006 | train_loss 0.8713 | val_loss 1.0355 | train_acc 0.6815 | val_acc 0.6271 | lr 8.52e-04 | 0.3s\n",
      "epoch 007 | train_loss 0.8390 | val_loss 1.0130 | train_acc 0.6890 | val_acc 0.6293 | lr 8.50e-04 | 0.3s\n",
      "epoch 008 | train_loss 0.8103 | val_loss 1.0321 | train_acc 0.7013 | val_acc 0.6316 | lr 8.46e-04 | 0.3s\n",
      "epoch 009 | train_loss 0.7874 | val_loss 1.0342 | train_acc 0.7119 | val_acc 0.6290 | lr 8.43e-04 | 0.3s\n",
      "epoch 010 | train_loss 0.7490 | val_loss 1.0147 | train_acc 0.7287 | val_acc 0.6426 | lr 8.39e-04 | 0.3s\n",
      "epoch 011 | train_loss 0.7247 | val_loss 1.0136 | train_acc 0.7393 | val_acc 0.6353 | lr 8.34e-04 | 0.3s\n",
      "epoch 012 | train_loss 0.6954 | val_loss 1.0316 | train_acc 0.7497 | val_acc 0.6312 | lr 8.30e-04 | 0.3s\n",
      "epoch 013 | train_loss 0.6687 | val_loss 1.0361 | train_acc 0.7561 | val_acc 0.6375 | lr 8.25e-04 | 0.3s\n",
      "epoch 014 | train_loss 0.6459 | val_loss 1.0425 | train_acc 0.7655 | val_acc 0.6301 | lr 8.19e-04 | 0.3s\n",
      "epoch 015 | train_loss 0.6285 | val_loss 1.0638 | train_acc 0.7741 | val_acc 0.6282 | lr 8.13e-04 | 0.3s\n",
      "epoch 016 | train_loss 0.6043 | val_loss 1.0698 | train_acc 0.7796 | val_acc 0.6412 | lr 8.07e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 17:59:55,778] Trial 30 finished with value: 1.012997319058674 and parameters: {'lr': 0.0008598983723320728, 'num_layers': 1, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.5860 | val_loss 1.0452 | train_acc 0.7881 | val_acc 0.6330 | lr 8.00e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.8166 | val_loss 1.8008 | train_acc 0.3854 | val_acc 0.5144 | lr 1.73e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.3948 | val_loss 1.4237 | train_acc 0.5248 | val_acc 0.5687 | lr 1.73e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.2666 | val_loss 1.2368 | train_acc 0.5574 | val_acc 0.5813 | lr 1.73e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.2035 | val_loss 1.1607 | train_acc 0.5771 | val_acc 0.5924 | lr 1.73e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.1566 | val_loss 1.1175 | train_acc 0.5857 | val_acc 0.5987 | lr 1.73e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.1164 | val_loss 1.0885 | train_acc 0.6011 | val_acc 0.6138 | lr 1.73e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0870 | val_loss 1.0699 | train_acc 0.6120 | val_acc 0.6153 | lr 1.73e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0801 | val_loss 1.0459 | train_acc 0.6145 | val_acc 0.6253 | lr 1.73e-04 | 0.5s\n",
      "epoch 009 | train_loss 1.0453 | val_loss 1.0355 | train_acc 0.6220 | val_acc 0.6308 | lr 1.73e-04 | 0.5s\n",
      "epoch 010 | train_loss 1.0266 | val_loss 1.0239 | train_acc 0.6261 | val_acc 0.6378 | lr 1.73e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9976 | val_loss 1.0182 | train_acc 0.6364 | val_acc 0.6371 | lr 1.73e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9912 | val_loss 1.0140 | train_acc 0.6379 | val_acc 0.6297 | lr 1.73e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9682 | val_loss 1.0097 | train_acc 0.6513 | val_acc 0.6312 | lr 1.73e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9503 | val_loss 1.0063 | train_acc 0.6516 | val_acc 0.6371 | lr 1.73e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.9342 | val_loss 0.9958 | train_acc 0.6595 | val_acc 0.6386 | lr 1.73e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.9236 | val_loss 1.0007 | train_acc 0.6608 | val_acc 0.6382 | lr 1.73e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.9044 | val_loss 0.9993 | train_acc 0.6753 | val_acc 0.6423 | lr 1.73e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8926 | val_loss 1.0008 | train_acc 0.6735 | val_acc 0.6397 | lr 1.73e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8769 | val_loss 1.0138 | train_acc 0.6820 | val_acc 0.6308 | lr 1.73e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8654 | val_loss 1.0014 | train_acc 0.6885 | val_acc 0.6408 | lr 1.73e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8487 | val_loss 1.0060 | train_acc 0.6903 | val_acc 0.6371 | lr 1.73e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8435 | val_loss 0.9926 | train_acc 0.6949 | val_acc 0.6438 | lr 1.73e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.8240 | val_loss 1.0068 | train_acc 0.7025 | val_acc 0.6415 | lr 1.73e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.8071 | val_loss 1.0076 | train_acc 0.7025 | val_acc 0.6390 | lr 1.73e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7906 | val_loss 1.0082 | train_acc 0.7116 | val_acc 0.6375 | lr 1.73e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7904 | val_loss 1.0140 | train_acc 0.7134 | val_acc 0.6271 | lr 1.73e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7714 | val_loss 1.0043 | train_acc 0.7163 | val_acc 0.6452 | lr 1.73e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.7694 | val_loss 1.0074 | train_acc 0.7219 | val_acc 0.6430 | lr 1.73e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.7494 | val_loss 1.0170 | train_acc 0.7290 | val_acc 0.6452 | lr 1.73e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.7414 | val_loss 1.0284 | train_acc 0.7260 | val_acc 0.6415 | lr 1.73e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.7287 | val_loss 1.0157 | train_acc 0.7325 | val_acc 0.6504 | lr 1.73e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:00:12,359] Trial 31 finished with value: 0.9925520638580774 and parameters: {'lr': 0.00017303699550147116, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 032 | train_loss 0.7296 | val_loss 1.0161 | train_acc 0.7366 | val_acc 0.6415 | lr 1.73e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.9000 | val_loss 1.8614 | train_acc 0.3594 | val_acc 0.5096 | lr 1.38e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.4370 | val_loss 1.4781 | train_acc 0.5190 | val_acc 0.5558 | lr 1.38e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.3109 | val_loss 1.2674 | train_acc 0.5499 | val_acc 0.5835 | lr 1.38e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.2448 | val_loss 1.1881 | train_acc 0.5671 | val_acc 0.5983 | lr 1.38e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.1900 | val_loss 1.1391 | train_acc 0.5786 | val_acc 0.5983 | lr 1.38e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.1570 | val_loss 1.1142 | train_acc 0.5901 | val_acc 0.6020 | lr 1.38e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.1276 | val_loss 1.0926 | train_acc 0.6004 | val_acc 0.6042 | lr 1.38e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.1041 | val_loss 1.0660 | train_acc 0.6087 | val_acc 0.6153 | lr 1.38e-04 | 0.5s\n",
      "epoch 009 | train_loss 1.0854 | val_loss 1.0601 | train_acc 0.6121 | val_acc 0.6190 | lr 1.38e-04 | 0.5s\n",
      "epoch 010 | train_loss 1.0657 | val_loss 1.0461 | train_acc 0.6205 | val_acc 0.6212 | lr 1.38e-04 | 0.5s\n",
      "epoch 011 | train_loss 1.0341 | val_loss 1.0428 | train_acc 0.6232 | val_acc 0.6245 | lr 1.38e-04 | 0.5s\n",
      "epoch 012 | train_loss 1.0231 | val_loss 1.0365 | train_acc 0.6320 | val_acc 0.6327 | lr 1.38e-04 | 0.5s\n",
      "epoch 013 | train_loss 1.0001 | val_loss 1.0239 | train_acc 0.6422 | val_acc 0.6334 | lr 1.38e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9893 | val_loss 1.0243 | train_acc 0.6443 | val_acc 0.6275 | lr 1.38e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.9709 | val_loss 1.0147 | train_acc 0.6447 | val_acc 0.6330 | lr 1.38e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.9507 | val_loss 1.0236 | train_acc 0.6564 | val_acc 0.6253 | lr 1.38e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.9492 | val_loss 1.0170 | train_acc 0.6596 | val_acc 0.6271 | lr 1.38e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.9333 | val_loss 1.0223 | train_acc 0.6633 | val_acc 0.6223 | lr 1.38e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.9220 | val_loss 1.0095 | train_acc 0.6618 | val_acc 0.6345 | lr 1.38e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.9142 | val_loss 1.0020 | train_acc 0.6679 | val_acc 0.6319 | lr 1.38e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8983 | val_loss 1.0028 | train_acc 0.6765 | val_acc 0.6338 | lr 1.38e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8832 | val_loss 1.0020 | train_acc 0.6829 | val_acc 0.6353 | lr 1.38e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.8713 | val_loss 1.0052 | train_acc 0.6836 | val_acc 0.6330 | lr 1.38e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.8618 | val_loss 1.0082 | train_acc 0.6878 | val_acc 0.6341 | lr 1.38e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.8497 | val_loss 1.0008 | train_acc 0.6956 | val_acc 0.6356 | lr 1.38e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.8397 | val_loss 1.0053 | train_acc 0.6982 | val_acc 0.6364 | lr 1.38e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.8269 | val_loss 0.9987 | train_acc 0.7019 | val_acc 0.6360 | lr 1.38e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.8119 | val_loss 1.0150 | train_acc 0.7059 | val_acc 0.6282 | lr 1.38e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.8070 | val_loss 1.0088 | train_acc 0.7132 | val_acc 0.6312 | lr 1.38e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.8013 | val_loss 1.0174 | train_acc 0.7083 | val_acc 0.6360 | lr 1.38e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.7812 | val_loss 1.0064 | train_acc 0.7170 | val_acc 0.6419 | lr 1.38e-04 | 0.5s\n",
      "epoch 032 | train_loss 0.7724 | val_loss 1.0169 | train_acc 0.7248 | val_acc 0.6338 | lr 1.38e-04 | 0.5s\n",
      "epoch 033 | train_loss 0.7633 | val_loss 1.0236 | train_acc 0.7289 | val_acc 0.6378 | lr 1.38e-04 | 0.5s\n",
      "epoch 034 | train_loss 0.7612 | val_loss 1.0183 | train_acc 0.7223 | val_acc 0.6371 | lr 1.38e-04 | 0.5s\n",
      "epoch 035 | train_loss 0.7471 | val_loss 1.0187 | train_acc 0.7281 | val_acc 0.6393 | lr 1.38e-04 | 0.5s\n",
      "epoch 036 | train_loss 0.7360 | val_loss 1.0257 | train_acc 0.7329 | val_acc 0.6390 | lr 1.38e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:00:31,528] Trial 32 finished with value: 0.998656941975652 and parameters: {'lr': 0.00013815110161089015, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 037 | train_loss 0.7331 | val_loss 1.0323 | train_acc 0.7376 | val_acc 0.6341 | lr 1.38e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6600 | val_loss 1.6253 | train_acc 0.4366 | val_acc 0.5410 | lr 2.95e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2836 | val_loss 1.3103 | train_acc 0.5502 | val_acc 0.5876 | lr 2.95e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1788 | val_loss 1.1542 | train_acc 0.5819 | val_acc 0.5994 | lr 2.95e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1278 | val_loss 1.1087 | train_acc 0.5985 | val_acc 0.6105 | lr 2.95e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0947 | val_loss 1.0646 | train_acc 0.6043 | val_acc 0.6160 | lr 2.95e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0563 | val_loss 1.0620 | train_acc 0.6215 | val_acc 0.6094 | lr 2.95e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0272 | val_loss 1.0254 | train_acc 0.6290 | val_acc 0.6234 | lr 2.95e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0049 | val_loss 1.0325 | train_acc 0.6317 | val_acc 0.6271 | lr 2.95e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9773 | val_loss 1.0130 | train_acc 0.6443 | val_acc 0.6279 | lr 2.95e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9636 | val_loss 1.0079 | train_acc 0.6539 | val_acc 0.6282 | lr 2.95e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9296 | val_loss 1.0046 | train_acc 0.6627 | val_acc 0.6334 | lr 2.95e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9162 | val_loss 1.0189 | train_acc 0.6614 | val_acc 0.6264 | lr 2.95e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.8977 | val_loss 0.9916 | train_acc 0.6728 | val_acc 0.6434 | lr 2.95e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8775 | val_loss 1.0086 | train_acc 0.6795 | val_acc 0.6415 | lr 2.95e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8544 | val_loss 1.0101 | train_acc 0.6870 | val_acc 0.6382 | lr 2.95e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8459 | val_loss 1.0071 | train_acc 0.6903 | val_acc 0.6268 | lr 2.95e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8174 | val_loss 0.9975 | train_acc 0.7089 | val_acc 0.6386 | lr 2.95e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8054 | val_loss 1.0022 | train_acc 0.7065 | val_acc 0.6419 | lr 2.95e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.7875 | val_loss 0.9964 | train_acc 0.7106 | val_acc 0.6463 | lr 2.95e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.7808 | val_loss 1.0224 | train_acc 0.7144 | val_acc 0.6371 | lr 2.95e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.7604 | val_loss 1.0168 | train_acc 0.7201 | val_acc 0.6382 | lr 2.95e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7541 | val_loss 1.0184 | train_acc 0.7237 | val_acc 0.6486 | lr 2.95e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:00:43,497] Trial 33 finished with value: 0.9916198330285015 and parameters: {'lr': 0.0002953916199970869, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.7264 | val_loss 1.0431 | train_acc 0.7354 | val_acc 0.6323 | lr 2.95e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7712 | val_loss 1.7500 | train_acc 0.3932 | val_acc 0.5370 | lr 1.93e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.3647 | val_loss 1.3872 | train_acc 0.5302 | val_acc 0.5776 | lr 1.93e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.2458 | val_loss 1.2181 | train_acc 0.5670 | val_acc 0.5868 | lr 1.93e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1887 | val_loss 1.1404 | train_acc 0.5832 | val_acc 0.5968 | lr 1.93e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.1454 | val_loss 1.1063 | train_acc 0.5949 | val_acc 0.6061 | lr 1.93e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.1118 | val_loss 1.0719 | train_acc 0.6035 | val_acc 0.6090 | lr 1.93e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0867 | val_loss 1.0640 | train_acc 0.6142 | val_acc 0.6068 | lr 1.93e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0548 | val_loss 1.0400 | train_acc 0.6157 | val_acc 0.6179 | lr 1.93e-04 | 0.5s\n",
      "epoch 009 | train_loss 1.0316 | val_loss 1.0357 | train_acc 0.6273 | val_acc 0.6242 | lr 1.93e-04 | 0.5s\n",
      "epoch 010 | train_loss 1.0198 | val_loss 1.0256 | train_acc 0.6337 | val_acc 0.6290 | lr 1.93e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9904 | val_loss 1.0244 | train_acc 0.6420 | val_acc 0.6260 | lr 1.93e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9758 | val_loss 1.0122 | train_acc 0.6468 | val_acc 0.6323 | lr 1.93e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9534 | val_loss 1.0185 | train_acc 0.6559 | val_acc 0.6256 | lr 1.93e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9399 | val_loss 1.0206 | train_acc 0.6589 | val_acc 0.6245 | lr 1.93e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.9172 | val_loss 1.0189 | train_acc 0.6620 | val_acc 0.6290 | lr 1.93e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.9088 | val_loss 1.0158 | train_acc 0.6681 | val_acc 0.6301 | lr 1.93e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8899 | val_loss 0.9980 | train_acc 0.6759 | val_acc 0.6356 | lr 1.93e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8813 | val_loss 1.0044 | train_acc 0.6807 | val_acc 0.6382 | lr 1.93e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8571 | val_loss 0.9990 | train_acc 0.6861 | val_acc 0.6353 | lr 1.93e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8563 | val_loss 0.9981 | train_acc 0.6883 | val_acc 0.6353 | lr 1.93e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8408 | val_loss 0.9960 | train_acc 0.6962 | val_acc 0.6478 | lr 1.93e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8209 | val_loss 0.9883 | train_acc 0.7010 | val_acc 0.6463 | lr 1.93e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.8091 | val_loss 1.0039 | train_acc 0.7055 | val_acc 0.6386 | lr 1.93e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.8037 | val_loss 0.9969 | train_acc 0.7092 | val_acc 0.6412 | lr 1.93e-04 | 0.4s\n",
      "epoch 025 | train_loss 0.7791 | val_loss 1.0058 | train_acc 0.7160 | val_acc 0.6386 | lr 1.93e-04 | 0.3s\n",
      "epoch 026 | train_loss 0.7738 | val_loss 1.0271 | train_acc 0.7186 | val_acc 0.6268 | lr 1.93e-04 | 0.3s\n",
      "epoch 027 | train_loss 0.7603 | val_loss 1.0124 | train_acc 0.7253 | val_acc 0.6378 | lr 1.93e-04 | 0.3s\n",
      "epoch 028 | train_loss 0.7479 | val_loss 1.0319 | train_acc 0.7287 | val_acc 0.6349 | lr 1.93e-04 | 0.3s\n",
      "epoch 029 | train_loss 0.7368 | val_loss 1.0081 | train_acc 0.7352 | val_acc 0.6356 | lr 1.93e-04 | 0.3s\n",
      "epoch 030 | train_loss 0.7261 | val_loss 1.0213 | train_acc 0.7364 | val_acc 0.6378 | lr 1.93e-04 | 0.3s\n",
      "epoch 031 | train_loss 0.7194 | val_loss 1.0196 | train_acc 0.7385 | val_acc 0.6401 | lr 1.93e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:00:57,988] Trial 34 finished with value: 0.9883290275501835 and parameters: {'lr': 0.00019251043979123296, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 032 | train_loss 0.7140 | val_loss 1.0302 | train_acc 0.7375 | val_acc 0.6305 | lr 1.93e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6048 | val_loss 1.6823 | train_acc 0.4498 | val_acc 0.5547 | lr 1.98e-04 | 0.3s\n",
      "epoch 002 | train_loss 1.2620 | val_loss 1.3090 | train_acc 0.5581 | val_acc 0.5887 | lr 1.98e-04 | 0.3s\n",
      "epoch 003 | train_loss 1.1733 | val_loss 1.1502 | train_acc 0.5837 | val_acc 0.6009 | lr 1.98e-04 | 0.3s\n",
      "epoch 004 | train_loss 1.1168 | val_loss 1.0896 | train_acc 0.5974 | val_acc 0.6057 | lr 1.98e-04 | 0.3s\n",
      "epoch 005 | train_loss 1.0701 | val_loss 1.0487 | train_acc 0.6121 | val_acc 0.6271 | lr 1.98e-04 | 0.3s\n",
      "epoch 006 | train_loss 1.0384 | val_loss 1.0422 | train_acc 0.6210 | val_acc 0.6183 | lr 1.98e-04 | 0.3s\n",
      "epoch 007 | train_loss 1.0087 | val_loss 1.0173 | train_acc 0.6358 | val_acc 0.6323 | lr 1.98e-04 | 0.3s\n",
      "epoch 008 | train_loss 0.9888 | val_loss 1.0088 | train_acc 0.6397 | val_acc 0.6375 | lr 1.98e-04 | 0.3s\n",
      "epoch 009 | train_loss 0.9536 | val_loss 1.0289 | train_acc 0.6537 | val_acc 0.6275 | lr 1.98e-04 | 0.3s\n",
      "epoch 010 | train_loss 0.9365 | val_loss 1.0114 | train_acc 0.6557 | val_acc 0.6334 | lr 1.98e-04 | 0.3s\n",
      "epoch 011 | train_loss 0.9054 | val_loss 1.0009 | train_acc 0.6676 | val_acc 0.6349 | lr 1.98e-04 | 0.2s\n",
      "epoch 012 | train_loss 0.8826 | val_loss 1.0095 | train_acc 0.6787 | val_acc 0.6360 | lr 1.98e-04 | 0.2s\n",
      "epoch 013 | train_loss 0.8633 | val_loss 1.0067 | train_acc 0.6815 | val_acc 0.6330 | lr 1.98e-04 | 0.2s\n",
      "epoch 014 | train_loss 0.8441 | val_loss 1.0017 | train_acc 0.6940 | val_acc 0.6404 | lr 1.98e-04 | 0.2s\n",
      "epoch 015 | train_loss 0.8310 | val_loss 1.0002 | train_acc 0.6952 | val_acc 0.6390 | lr 1.98e-04 | 0.2s\n",
      "epoch 016 | train_loss 0.8013 | val_loss 1.0124 | train_acc 0.7043 | val_acc 0.6353 | lr 1.98e-04 | 0.2s\n",
      "epoch 017 | train_loss 0.7883 | val_loss 1.0028 | train_acc 0.7126 | val_acc 0.6371 | lr 1.98e-04 | 0.2s\n",
      "epoch 018 | train_loss 0.7647 | val_loss 1.0064 | train_acc 0.7219 | val_acc 0.6426 | lr 1.98e-04 | 0.2s\n",
      "epoch 019 | train_loss 0.7464 | val_loss 1.0111 | train_acc 0.7255 | val_acc 0.6375 | lr 1.98e-04 | 0.2s\n",
      "epoch 020 | train_loss 0.7262 | val_loss 1.0294 | train_acc 0.7330 | val_acc 0.6312 | lr 1.98e-04 | 0.2s\n",
      "epoch 021 | train_loss 0.7038 | val_loss 1.0203 | train_acc 0.7437 | val_acc 0.6478 | lr 1.98e-04 | 0.2s\n",
      "epoch 022 | train_loss 0.7009 | val_loss 1.0438 | train_acc 0.7460 | val_acc 0.6282 | lr 1.98e-04 | 0.2s\n",
      "epoch 023 | train_loss 0.6815 | val_loss 1.0487 | train_acc 0.7520 | val_acc 0.6367 | lr 1.98e-04 | 0.2s\n",
      "epoch 024 | train_loss 0.6706 | val_loss 1.0485 | train_acc 0.7531 | val_acc 0.6297 | lr 1.98e-04 | 0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:01:04,050] Trial 35 finished with value: 1.0002377342490558 and parameters: {'lr': 0.00019849102130628317, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': False}. Best is trial 19 with value: 0.9847252363640558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.6548 | val_loss 1.0557 | train_acc 0.7596 | val_acc 0.6356 | lr 1.98e-04 | 0.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7076 | val_loss 1.3978 | train_acc 0.4222 | val_acc 0.5569 | lr 1.01e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.3563 | val_loss 1.2282 | train_acc 0.5249 | val_acc 0.5780 | lr 1.01e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.2695 | val_loss 1.1544 | train_acc 0.5566 | val_acc 0.5920 | lr 1.01e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.2167 | val_loss 1.1162 | train_acc 0.5684 | val_acc 0.5957 | lr 1.01e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1695 | val_loss 1.0862 | train_acc 0.5839 | val_acc 0.6083 | lr 1.01e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.1532 | val_loss 1.0681 | train_acc 0.5870 | val_acc 0.6164 | lr 1.01e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.1207 | val_loss 1.0527 | train_acc 0.5983 | val_acc 0.6208 | lr 1.01e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.1062 | val_loss 1.0456 | train_acc 0.6053 | val_acc 0.6175 | lr 1.01e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0776 | val_loss 1.0354 | train_acc 0.6069 | val_acc 0.6190 | lr 1.01e-04 | 0.6s\n",
      "epoch 010 | train_loss 1.0512 | val_loss 1.0237 | train_acc 0.6253 | val_acc 0.6245 | lr 1.01e-04 | 0.6s\n",
      "epoch 011 | train_loss 1.0413 | val_loss 1.0216 | train_acc 0.6234 | val_acc 0.6268 | lr 1.01e-04 | 0.6s\n",
      "epoch 012 | train_loss 1.0205 | val_loss 1.0138 | train_acc 0.6291 | val_acc 0.6275 | lr 1.01e-04 | 0.6s\n",
      "epoch 013 | train_loss 1.0037 | val_loss 1.0029 | train_acc 0.6387 | val_acc 0.6330 | lr 1.01e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9979 | val_loss 1.0040 | train_acc 0.6361 | val_acc 0.6268 | lr 1.01e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9778 | val_loss 0.9945 | train_acc 0.6492 | val_acc 0.6356 | lr 1.01e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.9645 | val_loss 0.9921 | train_acc 0.6484 | val_acc 0.6397 | lr 1.01e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.9641 | val_loss 0.9936 | train_acc 0.6511 | val_acc 0.6408 | lr 1.01e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.9568 | val_loss 0.9929 | train_acc 0.6527 | val_acc 0.6386 | lr 1.01e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.9286 | val_loss 0.9855 | train_acc 0.6628 | val_acc 0.6353 | lr 1.01e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.9141 | val_loss 0.9908 | train_acc 0.6671 | val_acc 0.6375 | lr 1.01e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.8929 | val_loss 0.9864 | train_acc 0.6713 | val_acc 0.6441 | lr 1.01e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.8999 | val_loss 0.9885 | train_acc 0.6753 | val_acc 0.6364 | lr 1.01e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.8859 | val_loss 0.9830 | train_acc 0.6791 | val_acc 0.6386 | lr 1.01e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.8674 | val_loss 0.9828 | train_acc 0.6895 | val_acc 0.6382 | lr 1.01e-04 | 0.6s\n",
      "epoch 025 | train_loss 0.8511 | val_loss 0.9932 | train_acc 0.6889 | val_acc 0.6356 | lr 1.01e-04 | 0.6s\n",
      "epoch 026 | train_loss 0.8489 | val_loss 1.0043 | train_acc 0.6888 | val_acc 0.6319 | lr 1.01e-04 | 0.6s\n",
      "epoch 027 | train_loss 0.8442 | val_loss 0.9995 | train_acc 0.6938 | val_acc 0.6330 | lr 1.01e-04 | 0.6s\n",
      "epoch 028 | train_loss 0.8295 | val_loss 0.9999 | train_acc 0.6922 | val_acc 0.6338 | lr 1.01e-04 | 2.0s\n",
      "epoch 029 | train_loss 0.8184 | val_loss 0.9930 | train_acc 0.7031 | val_acc 0.6408 | lr 1.01e-04 | 2.0s\n",
      "epoch 030 | train_loss 0.8127 | val_loss 0.9970 | train_acc 0.7052 | val_acc 0.6386 | lr 1.01e-04 | 2.0s\n",
      "epoch 031 | train_loss 0.8094 | val_loss 0.9937 | train_acc 0.7053 | val_acc 0.6401 | lr 1.01e-04 | 2.0s\n",
      "epoch 032 | train_loss 0.7855 | val_loss 0.9994 | train_acc 0.7103 | val_acc 0.6393 | lr 1.01e-04 | 2.0s\n",
      "epoch 033 | train_loss 0.7887 | val_loss 1.0062 | train_acc 0.7164 | val_acc 0.6390 | lr 1.01e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:01:34,381] Trial 36 finished with value: 0.9827516782926967 and parameters: {'lr': 0.00010059681714820224, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 034 | train_loss 0.7680 | val_loss 1.0087 | train_acc 0.7188 | val_acc 0.6456 | lr 1.01e-04 | 0.8s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5370 | val_loss 1.2452 | train_acc 0.4767 | val_acc 0.5576 | lr 1.14e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2389 | val_loss 1.1456 | train_acc 0.5596 | val_acc 0.5872 | lr 1.14e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1541 | val_loss 1.1022 | train_acc 0.5858 | val_acc 0.6024 | lr 1.14e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1070 | val_loss 1.0721 | train_acc 0.6016 | val_acc 0.6168 | lr 1.14e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.0727 | val_loss 1.0546 | train_acc 0.6144 | val_acc 0.6190 | lr 1.14e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0436 | val_loss 1.0402 | train_acc 0.6210 | val_acc 0.6238 | lr 1.14e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0211 | val_loss 1.0318 | train_acc 0.6303 | val_acc 0.6286 | lr 1.14e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9961 | val_loss 1.0236 | train_acc 0.6444 | val_acc 0.6375 | lr 1.14e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9777 | val_loss 1.0159 | train_acc 0.6468 | val_acc 0.6345 | lr 1.14e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9590 | val_loss 1.0068 | train_acc 0.6515 | val_acc 0.6375 | lr 1.14e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9480 | val_loss 1.0006 | train_acc 0.6537 | val_acc 0.6401 | lr 1.14e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9292 | val_loss 0.9957 | train_acc 0.6608 | val_acc 0.6471 | lr 1.14e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9081 | val_loss 1.0038 | train_acc 0.6704 | val_acc 0.6375 | lr 1.14e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8976 | val_loss 0.9986 | train_acc 0.6729 | val_acc 0.6378 | lr 1.14e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8816 | val_loss 0.9931 | train_acc 0.6836 | val_acc 0.6408 | lr 1.14e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8744 | val_loss 0.9904 | train_acc 0.6850 | val_acc 0.6430 | lr 1.14e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8583 | val_loss 0.9919 | train_acc 0.6931 | val_acc 0.6460 | lr 1.14e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8387 | val_loss 0.9917 | train_acc 0.6978 | val_acc 0.6426 | lr 1.14e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8311 | val_loss 0.9871 | train_acc 0.6977 | val_acc 0.6567 | lr 1.14e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8210 | val_loss 0.9897 | train_acc 0.7004 | val_acc 0.6445 | lr 1.14e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8089 | val_loss 0.9873 | train_acc 0.7087 | val_acc 0.6441 | lr 1.14e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7924 | val_loss 0.9923 | train_acc 0.7140 | val_acc 0.6438 | lr 1.14e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7873 | val_loss 0.9898 | train_acc 0.7145 | val_acc 0.6434 | lr 1.14e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7833 | val_loss 0.9868 | train_acc 0.7114 | val_acc 0.6467 | lr 1.14e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7648 | val_loss 0.9965 | train_acc 0.7196 | val_acc 0.6441 | lr 1.14e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7558 | val_loss 0.9903 | train_acc 0.7278 | val_acc 0.6419 | lr 1.14e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7469 | val_loss 0.9940 | train_acc 0.7269 | val_acc 0.6478 | lr 1.14e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.7315 | val_loss 1.0001 | train_acc 0.7367 | val_acc 0.6423 | lr 1.14e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.7282 | val_loss 0.9980 | train_acc 0.7370 | val_acc 0.6390 | lr 1.14e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.7223 | val_loss 0.9980 | train_acc 0.7430 | val_acc 0.6489 | lr 1.14e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.7017 | val_loss 0.9973 | train_acc 0.7457 | val_acc 0.6467 | lr 1.14e-04 | 0.5s\n",
      "epoch 032 | train_loss 0.7014 | val_loss 0.9964 | train_acc 0.7492 | val_acc 0.6500 | lr 1.14e-04 | 0.5s\n",
      "epoch 033 | train_loss 0.6923 | val_loss 0.9917 | train_acc 0.7488 | val_acc 0.6511 | lr 1.14e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:01:50,625] Trial 37 finished with value: 0.9868020979633881 and parameters: {'lr': 0.00011376511555222399, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 034 | train_loss 0.6754 | val_loss 1.0023 | train_acc 0.7561 | val_acc 0.6515 | lr 1.14e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5406 | val_loss 1.2294 | train_acc 0.4770 | val_acc 0.5595 | lr 1.15e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.2332 | val_loss 1.1376 | train_acc 0.5627 | val_acc 0.5961 | lr 1.15e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1537 | val_loss 1.0979 | train_acc 0.5870 | val_acc 0.6079 | lr 1.15e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1057 | val_loss 1.0716 | train_acc 0.6035 | val_acc 0.6061 | lr 1.15e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0738 | val_loss 1.0536 | train_acc 0.6117 | val_acc 0.6168 | lr 1.15e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0448 | val_loss 1.0404 | train_acc 0.6277 | val_acc 0.6242 | lr 1.15e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0196 | val_loss 1.0291 | train_acc 0.6311 | val_acc 0.6234 | lr 1.15e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9959 | val_loss 1.0207 | train_acc 0.6399 | val_acc 0.6305 | lr 1.15e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9815 | val_loss 1.0177 | train_acc 0.6501 | val_acc 0.6308 | lr 1.15e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9632 | val_loss 1.0127 | train_acc 0.6547 | val_acc 0.6330 | lr 1.15e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9454 | val_loss 1.0082 | train_acc 0.6580 | val_acc 0.6397 | lr 1.15e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9289 | val_loss 0.9986 | train_acc 0.6652 | val_acc 0.6408 | lr 1.15e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9115 | val_loss 1.0001 | train_acc 0.6743 | val_acc 0.6401 | lr 1.15e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8992 | val_loss 0.9972 | train_acc 0.6708 | val_acc 0.6386 | lr 1.15e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8853 | val_loss 0.9970 | train_acc 0.6810 | val_acc 0.6404 | lr 1.15e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8652 | val_loss 0.9997 | train_acc 0.6863 | val_acc 0.6393 | lr 1.15e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8515 | val_loss 0.9939 | train_acc 0.6912 | val_acc 0.6452 | lr 1.15e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8376 | val_loss 0.9960 | train_acc 0.6964 | val_acc 0.6349 | lr 1.15e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8288 | val_loss 0.9909 | train_acc 0.7034 | val_acc 0.6456 | lr 1.15e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8246 | val_loss 1.0024 | train_acc 0.7028 | val_acc 0.6371 | lr 1.15e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.7995 | val_loss 0.9946 | train_acc 0.7072 | val_acc 0.6364 | lr 1.15e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8013 | val_loss 0.9974 | train_acc 0.7122 | val_acc 0.6390 | lr 1.15e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7832 | val_loss 0.9949 | train_acc 0.7194 | val_acc 0.6449 | lr 1.15e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7714 | val_loss 0.9926 | train_acc 0.7169 | val_acc 0.6438 | lr 1.15e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7662 | val_loss 0.9924 | train_acc 0.7240 | val_acc 0.6408 | lr 1.15e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7561 | val_loss 0.9938 | train_acc 0.7261 | val_acc 0.6467 | lr 1.15e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7426 | val_loss 1.0068 | train_acc 0.7307 | val_acc 0.6441 | lr 1.15e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.7357 | val_loss 0.9953 | train_acc 0.7371 | val_acc 0.6449 | lr 1.15e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:02:03,924] Trial 38 finished with value: 0.9908632370426491 and parameters: {'lr': 0.0001150162350156928, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7226 | val_loss 1.0081 | train_acc 0.7420 | val_acc 0.6353 | lr 1.15e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3039 | val_loss 1.1550 | train_acc 0.5331 | val_acc 0.5883 | lr 8.56e-03 | 0.5s\n",
      "epoch 002 | train_loss 1.1575 | val_loss 1.1075 | train_acc 0.5830 | val_acc 0.5957 | lr 8.56e-03 | 0.5s\n",
      "epoch 003 | train_loss 1.1161 | val_loss 1.0854 | train_acc 0.5894 | val_acc 0.6116 | lr 8.56e-03 | 0.5s\n",
      "epoch 004 | train_loss 1.0911 | val_loss 1.1100 | train_acc 0.5989 | val_acc 0.5935 | lr 8.56e-03 | 0.5s\n",
      "epoch 005 | train_loss 1.0778 | val_loss 1.1029 | train_acc 0.6011 | val_acc 0.5965 | lr 8.56e-03 | 0.5s\n",
      "epoch 006 | train_loss 1.0690 | val_loss 1.0992 | train_acc 0.6098 | val_acc 0.5854 | lr 8.56e-03 | 0.5s\n",
      "epoch 007 | train_loss 1.0647 | val_loss 1.0912 | train_acc 0.6151 | val_acc 0.5950 | lr 8.56e-03 | 0.5s\n",
      "epoch 008 | train_loss 1.0564 | val_loss 1.1174 | train_acc 0.6115 | val_acc 0.5854 | lr 8.56e-03 | 0.5s\n",
      "epoch 009 | train_loss 1.0589 | val_loss 1.0961 | train_acc 0.6143 | val_acc 0.6035 | lr 8.56e-03 | 0.5s\n",
      "epoch 010 | train_loss 1.0490 | val_loss 1.0927 | train_acc 0.6149 | val_acc 0.5953 | lr 8.56e-03 | 0.5s\n",
      "epoch 011 | train_loss 1.0417 | val_loss 1.0927 | train_acc 0.6183 | val_acc 0.6083 | lr 8.56e-03 | 0.5s\n",
      "epoch 012 | train_loss 1.0357 | val_loss 1.0586 | train_acc 0.6200 | val_acc 0.6086 | lr 8.56e-03 | 0.5s\n",
      "epoch 013 | train_loss 1.0267 | val_loss 1.0637 | train_acc 0.6189 | val_acc 0.6035 | lr 8.56e-03 | 0.5s\n",
      "epoch 014 | train_loss 1.0438 | val_loss 1.0625 | train_acc 0.6133 | val_acc 0.6149 | lr 8.56e-03 | 0.5s\n",
      "epoch 015 | train_loss 1.0317 | val_loss 1.0931 | train_acc 0.6221 | val_acc 0.6005 | lr 8.56e-03 | 0.5s\n",
      "epoch 016 | train_loss 1.0218 | val_loss 1.0655 | train_acc 0.6259 | val_acc 0.6057 | lr 8.56e-03 | 0.5s\n",
      "epoch 017 | train_loss 1.0088 | val_loss 1.0714 | train_acc 0.6301 | val_acc 0.6098 | lr 8.56e-03 | 0.5s\n",
      "epoch 018 | train_loss 1.0139 | val_loss 1.0788 | train_acc 0.6262 | val_acc 0.5961 | lr 8.56e-03 | 0.5s\n",
      "epoch 019 | train_loss 1.0175 | val_loss 1.0667 | train_acc 0.6255 | val_acc 0.6153 | lr 8.56e-03 | 0.5s\n",
      "epoch 020 | train_loss 1.0242 | val_loss 1.0700 | train_acc 0.6207 | val_acc 0.6046 | lr 8.56e-03 | 0.5s\n",
      "epoch 021 | train_loss 1.0126 | val_loss 1.0723 | train_acc 0.6310 | val_acc 0.6138 | lr 8.56e-03 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:02:14,034] Trial 39 finished with value: 1.0586314682421294 and parameters: {'lr': 0.008557538385577355, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 1.0097 | val_loss 1.0672 | train_acc 0.6277 | val_acc 0.6057 | lr 8.56e-03 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5727 | val_loss 1.2363 | train_acc 0.4612 | val_acc 0.5565 | lr 1.20e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.2265 | val_loss 1.1427 | train_acc 0.5707 | val_acc 0.5883 | lr 1.20e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1458 | val_loss 1.0987 | train_acc 0.5911 | val_acc 0.6009 | lr 1.20e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1058 | val_loss 1.0721 | train_acc 0.6058 | val_acc 0.6090 | lr 1.20e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0703 | val_loss 1.0551 | train_acc 0.6124 | val_acc 0.6086 | lr 1.20e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0384 | val_loss 1.0415 | train_acc 0.6285 | val_acc 0.6175 | lr 1.20e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0164 | val_loss 1.0285 | train_acc 0.6283 | val_acc 0.6208 | lr 1.20e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9946 | val_loss 1.0240 | train_acc 0.6433 | val_acc 0.6231 | lr 1.20e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9718 | val_loss 1.0179 | train_acc 0.6509 | val_acc 0.6268 | lr 1.20e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9536 | val_loss 1.0101 | train_acc 0.6524 | val_acc 0.6327 | lr 1.20e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9389 | val_loss 1.0039 | train_acc 0.6621 | val_acc 0.6312 | lr 1.20e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9247 | val_loss 1.0010 | train_acc 0.6644 | val_acc 0.6353 | lr 1.20e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9098 | val_loss 0.9981 | train_acc 0.6708 | val_acc 0.6356 | lr 1.20e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8958 | val_loss 0.9957 | train_acc 0.6754 | val_acc 0.6364 | lr 1.20e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8750 | val_loss 0.9894 | train_acc 0.6853 | val_acc 0.6367 | lr 1.20e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8556 | val_loss 0.9942 | train_acc 0.6926 | val_acc 0.6345 | lr 1.20e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8488 | val_loss 0.9876 | train_acc 0.6920 | val_acc 0.6386 | lr 1.20e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8395 | val_loss 0.9884 | train_acc 0.6956 | val_acc 0.6452 | lr 1.20e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8203 | val_loss 0.9958 | train_acc 0.7071 | val_acc 0.6323 | lr 1.20e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8117 | val_loss 0.9891 | train_acc 0.7091 | val_acc 0.6397 | lr 1.20e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.7998 | val_loss 0.9875 | train_acc 0.7153 | val_acc 0.6408 | lr 1.20e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7902 | val_loss 0.9878 | train_acc 0.7168 | val_acc 0.6360 | lr 1.20e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7745 | val_loss 0.9882 | train_acc 0.7194 | val_acc 0.6438 | lr 1.20e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7682 | val_loss 0.9834 | train_acc 0.7253 | val_acc 0.6404 | lr 1.20e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7587 | val_loss 0.9872 | train_acc 0.7314 | val_acc 0.6445 | lr 1.20e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7465 | val_loss 0.9897 | train_acc 0.7322 | val_acc 0.6434 | lr 1.20e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7380 | val_loss 0.9868 | train_acc 0.7360 | val_acc 0.6430 | lr 1.20e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.7254 | val_loss 0.9911 | train_acc 0.7394 | val_acc 0.6367 | lr 1.20e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.7168 | val_loss 0.9933 | train_acc 0.7399 | val_acc 0.6360 | lr 1.20e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.7053 | val_loss 1.0008 | train_acc 0.7484 | val_acc 0.6438 | lr 1.20e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.6952 | val_loss 0.9982 | train_acc 0.7470 | val_acc 0.6460 | lr 1.20e-04 | 0.5s\n",
      "epoch 032 | train_loss 0.6821 | val_loss 0.9928 | train_acc 0.7558 | val_acc 0.6353 | lr 1.20e-04 | 0.5s\n",
      "epoch 033 | train_loss 0.6837 | val_loss 0.9871 | train_acc 0.7527 | val_acc 0.6460 | lr 1.20e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:02:29,596] Trial 40 finished with value: 0.9833594476040081 and parameters: {'lr': 0.00011995860909617709, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 034 | train_loss 0.6656 | val_loss 0.9931 | train_acc 0.7628 | val_acc 0.6471 | lr 1.20e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5271 | val_loss 1.2313 | train_acc 0.4805 | val_acc 0.5643 | lr 1.25e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.2199 | val_loss 1.1387 | train_acc 0.5714 | val_acc 0.5909 | lr 1.25e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1403 | val_loss 1.0936 | train_acc 0.5966 | val_acc 0.5987 | lr 1.25e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1059 | val_loss 1.0702 | train_acc 0.5999 | val_acc 0.6061 | lr 1.25e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0634 | val_loss 1.0497 | train_acc 0.6202 | val_acc 0.6157 | lr 1.25e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0314 | val_loss 1.0366 | train_acc 0.6280 | val_acc 0.6227 | lr 1.25e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0126 | val_loss 1.0259 | train_acc 0.6359 | val_acc 0.6279 | lr 1.25e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9888 | val_loss 1.0184 | train_acc 0.6426 | val_acc 0.6297 | lr 1.25e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9643 | val_loss 1.0088 | train_acc 0.6498 | val_acc 0.6371 | lr 1.25e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9464 | val_loss 1.0090 | train_acc 0.6586 | val_acc 0.6367 | lr 1.25e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9299 | val_loss 1.0143 | train_acc 0.6651 | val_acc 0.6308 | lr 1.25e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9177 | val_loss 1.0018 | train_acc 0.6669 | val_acc 0.6412 | lr 1.25e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9011 | val_loss 1.0023 | train_acc 0.6713 | val_acc 0.6308 | lr 1.25e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8877 | val_loss 0.9954 | train_acc 0.6766 | val_acc 0.6349 | lr 1.25e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8740 | val_loss 0.9926 | train_acc 0.6846 | val_acc 0.6415 | lr 1.25e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8581 | val_loss 0.9950 | train_acc 0.6843 | val_acc 0.6393 | lr 1.25e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8408 | val_loss 0.9877 | train_acc 0.6920 | val_acc 0.6486 | lr 1.25e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8381 | val_loss 0.9921 | train_acc 0.6959 | val_acc 0.6478 | lr 1.25e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8176 | val_loss 0.9884 | train_acc 0.7079 | val_acc 0.6412 | lr 1.25e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8071 | val_loss 0.9904 | train_acc 0.7103 | val_acc 0.6478 | lr 1.25e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7902 | val_loss 1.0004 | train_acc 0.7181 | val_acc 0.6423 | lr 1.25e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7805 | val_loss 0.9951 | train_acc 0.7195 | val_acc 0.6452 | lr 1.25e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7692 | val_loss 0.9942 | train_acc 0.7225 | val_acc 0.6408 | lr 1.25e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7613 | val_loss 1.0018 | train_acc 0.7245 | val_acc 0.6371 | lr 1.25e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7541 | val_loss 0.9975 | train_acc 0.7296 | val_acc 0.6430 | lr 1.25e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7435 | val_loss 1.0028 | train_acc 0.7325 | val_acc 0.6430 | lr 1.25e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:02:47,662] Trial 41 finished with value: 0.9876751058293728 and parameters: {'lr': 0.0001246898816952937, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 36 with value: 0.9827516782926967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 027 | train_loss 0.7344 | val_loss 0.9966 | train_acc 0.7364 | val_acc 0.6423 | lr 1.25e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5207 | val_loss 1.2417 | train_acc 0.4842 | val_acc 0.5540 | lr 1.14e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2293 | val_loss 1.1446 | train_acc 0.5679 | val_acc 0.5968 | lr 1.14e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1537 | val_loss 1.0999 | train_acc 0.5887 | val_acc 0.6061 | lr 1.14e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0992 | val_loss 1.0730 | train_acc 0.6050 | val_acc 0.6186 | lr 1.14e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0673 | val_loss 1.0510 | train_acc 0.6135 | val_acc 0.6205 | lr 1.14e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0383 | val_loss 1.0397 | train_acc 0.6242 | val_acc 0.6238 | lr 1.14e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0186 | val_loss 1.0254 | train_acc 0.6303 | val_acc 0.6275 | lr 1.14e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9953 | val_loss 1.0156 | train_acc 0.6377 | val_acc 0.6293 | lr 1.14e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9696 | val_loss 1.0159 | train_acc 0.6546 | val_acc 0.6282 | lr 1.14e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9639 | val_loss 1.0030 | train_acc 0.6546 | val_acc 0.6353 | lr 1.14e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9390 | val_loss 1.0037 | train_acc 0.6575 | val_acc 0.6316 | lr 1.14e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9258 | val_loss 1.0052 | train_acc 0.6679 | val_acc 0.6323 | lr 1.14e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9099 | val_loss 0.9955 | train_acc 0.6702 | val_acc 0.6397 | lr 1.14e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8972 | val_loss 0.9928 | train_acc 0.6717 | val_acc 0.6419 | lr 1.14e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8771 | val_loss 0.9883 | train_acc 0.6836 | val_acc 0.6353 | lr 1.14e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8657 | val_loss 0.9926 | train_acc 0.6869 | val_acc 0.6386 | lr 1.14e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8537 | val_loss 0.9933 | train_acc 0.6950 | val_acc 0.6323 | lr 1.14e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8502 | val_loss 0.9884 | train_acc 0.6932 | val_acc 0.6415 | lr 1.14e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8356 | val_loss 0.9825 | train_acc 0.6965 | val_acc 0.6434 | lr 1.14e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8180 | val_loss 0.9868 | train_acc 0.7044 | val_acc 0.6382 | lr 1.14e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8092 | val_loss 0.9878 | train_acc 0.7073 | val_acc 0.6408 | lr 1.14e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7848 | val_loss 0.9891 | train_acc 0.7165 | val_acc 0.6449 | lr 1.14e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7818 | val_loss 0.9914 | train_acc 0.7147 | val_acc 0.6390 | lr 1.14e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7706 | val_loss 0.9854 | train_acc 0.7251 | val_acc 0.6415 | lr 1.14e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7705 | val_loss 0.9920 | train_acc 0.7236 | val_acc 0.6378 | lr 1.14e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7451 | val_loss 0.9916 | train_acc 0.7325 | val_acc 0.6445 | lr 1.14e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7337 | val_loss 0.9976 | train_acc 0.7384 | val_acc 0.6334 | lr 1.14e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7349 | val_loss 0.9936 | train_acc 0.7400 | val_acc 0.6390 | lr 1.14e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:03:21,641] Trial 42 finished with value: 0.9824916641534212 and parameters: {'lr': 0.00011425469060373843, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7266 | val_loss 0.9960 | train_acc 0.7361 | val_acc 0.6364 | lr 1.14e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5677 | val_loss 1.2388 | train_acc 0.4654 | val_acc 0.5617 | lr 1.17e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2331 | val_loss 1.1439 | train_acc 0.5635 | val_acc 0.5928 | lr 1.17e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1528 | val_loss 1.0983 | train_acc 0.5903 | val_acc 0.6038 | lr 1.17e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.1028 | val_loss 1.0717 | train_acc 0.6060 | val_acc 0.6101 | lr 1.17e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0673 | val_loss 1.0596 | train_acc 0.6181 | val_acc 0.6175 | lr 1.17e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0409 | val_loss 1.0385 | train_acc 0.6213 | val_acc 0.6260 | lr 1.17e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0178 | val_loss 1.0353 | train_acc 0.6366 | val_acc 0.6234 | lr 1.17e-04 | 0.7s\n",
      "epoch 008 | train_loss 0.9982 | val_loss 1.0235 | train_acc 0.6424 | val_acc 0.6253 | lr 1.17e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.9775 | val_loss 1.0153 | train_acc 0.6440 | val_acc 0.6305 | lr 1.17e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9475 | val_loss 1.0136 | train_acc 0.6567 | val_acc 0.6367 | lr 1.17e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9358 | val_loss 1.0087 | train_acc 0.6653 | val_acc 0.6271 | lr 1.17e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9213 | val_loss 1.0054 | train_acc 0.6669 | val_acc 0.6319 | lr 1.17e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9068 | val_loss 1.0000 | train_acc 0.6713 | val_acc 0.6330 | lr 1.17e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8939 | val_loss 1.0055 | train_acc 0.6785 | val_acc 0.6308 | lr 1.17e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8855 | val_loss 0.9968 | train_acc 0.6792 | val_acc 0.6412 | lr 1.17e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8633 | val_loss 1.0072 | train_acc 0.6853 | val_acc 0.6390 | lr 1.17e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8505 | val_loss 0.9976 | train_acc 0.6937 | val_acc 0.6330 | lr 1.17e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8366 | val_loss 0.9942 | train_acc 0.7016 | val_acc 0.6397 | lr 1.17e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8362 | val_loss 1.0026 | train_acc 0.7002 | val_acc 0.6316 | lr 1.17e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8144 | val_loss 0.9980 | train_acc 0.7070 | val_acc 0.6338 | lr 1.17e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8025 | val_loss 0.9986 | train_acc 0.7104 | val_acc 0.6415 | lr 1.17e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7896 | val_loss 0.9990 | train_acc 0.7158 | val_acc 0.6415 | lr 1.17e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7768 | val_loss 0.9976 | train_acc 0.7230 | val_acc 0.6378 | lr 1.17e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7669 | val_loss 0.9990 | train_acc 0.7241 | val_acc 0.6408 | lr 1.17e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7607 | val_loss 1.0011 | train_acc 0.7297 | val_acc 0.6434 | lr 1.17e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7445 | val_loss 0.9970 | train_acc 0.7325 | val_acc 0.6430 | lr 1.17e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7453 | val_loss 1.0014 | train_acc 0.7296 | val_acc 0.6434 | lr 1.17e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:03:39,359] Trial 43 finished with value: 0.994217886188166 and parameters: {'lr': 0.00011733536316494683, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 028 | train_loss 0.7317 | val_loss 0.9982 | train_acc 0.7390 | val_acc 0.6397 | lr 1.17e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4935 | val_loss 1.1896 | train_acc 0.4899 | val_acc 0.5761 | lr 1.63e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.1885 | val_loss 1.1163 | train_acc 0.5786 | val_acc 0.5965 | lr 1.63e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1174 | val_loss 1.0775 | train_acc 0.5993 | val_acc 0.6057 | lr 1.63e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.0804 | val_loss 1.0547 | train_acc 0.6136 | val_acc 0.6149 | lr 1.63e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0443 | val_loss 1.0368 | train_acc 0.6218 | val_acc 0.6245 | lr 1.63e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0126 | val_loss 1.0282 | train_acc 0.6348 | val_acc 0.6275 | lr 1.63e-04 | 0.5s\n",
      "epoch 007 | train_loss 0.9875 | val_loss 1.0179 | train_acc 0.6474 | val_acc 0.6286 | lr 1.63e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9627 | val_loss 1.0188 | train_acc 0.6498 | val_acc 0.6264 | lr 1.63e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9382 | val_loss 1.0143 | train_acc 0.6611 | val_acc 0.6327 | lr 1.63e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9280 | val_loss 1.0000 | train_acc 0.6625 | val_acc 0.6323 | lr 1.63e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9046 | val_loss 1.0039 | train_acc 0.6735 | val_acc 0.6330 | lr 1.63e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.8868 | val_loss 1.0130 | train_acc 0.6790 | val_acc 0.6364 | lr 1.63e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.8769 | val_loss 0.9983 | train_acc 0.6814 | val_acc 0.6371 | lr 1.63e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8495 | val_loss 1.0046 | train_acc 0.6917 | val_acc 0.6349 | lr 1.63e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8344 | val_loss 1.0029 | train_acc 0.6965 | val_acc 0.6349 | lr 1.63e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8353 | val_loss 1.0035 | train_acc 0.6986 | val_acc 0.6378 | lr 1.63e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8100 | val_loss 0.9968 | train_acc 0.7058 | val_acc 0.6390 | lr 1.63e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.7909 | val_loss 0.9997 | train_acc 0.7152 | val_acc 0.6404 | lr 1.63e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.7867 | val_loss 1.0093 | train_acc 0.7204 | val_acc 0.6353 | lr 1.63e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.7724 | val_loss 1.0077 | train_acc 0.7196 | val_acc 0.6375 | lr 1.63e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.7617 | val_loss 1.0042 | train_acc 0.7253 | val_acc 0.6375 | lr 1.63e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7484 | val_loss 1.0061 | train_acc 0.7301 | val_acc 0.6371 | lr 1.63e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7325 | val_loss 1.0104 | train_acc 0.7349 | val_acc 0.6401 | lr 1.63e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7247 | val_loss 1.0061 | train_acc 0.7359 | val_acc 0.6375 | lr 1.63e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7116 | val_loss 1.0121 | train_acc 0.7459 | val_acc 0.6419 | lr 1.63e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7099 | val_loss 1.0111 | train_acc 0.7386 | val_acc 0.6404 | lr 1.63e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:03:51,720] Trial 44 finished with value: 0.9968253997900005 and parameters: {'lr': 0.00016261894060382438, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 027 | train_loss 0.6957 | val_loss 1.0155 | train_acc 0.7502 | val_acc 0.6349 | lr 1.63e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6027 | val_loss 1.2518 | train_acc 0.4539 | val_acc 0.5562 | lr 1.04e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.2519 | val_loss 1.1544 | train_acc 0.5612 | val_acc 0.5820 | lr 1.04e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1701 | val_loss 1.1110 | train_acc 0.5820 | val_acc 0.5961 | lr 1.04e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1223 | val_loss 1.0824 | train_acc 0.6003 | val_acc 0.6086 | lr 1.04e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0870 | val_loss 1.0609 | train_acc 0.6143 | val_acc 0.6142 | lr 1.04e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0549 | val_loss 1.0480 | train_acc 0.6256 | val_acc 0.6220 | lr 1.04e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0261 | val_loss 1.0385 | train_acc 0.6331 | val_acc 0.6205 | lr 1.04e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0047 | val_loss 1.0266 | train_acc 0.6408 | val_acc 0.6249 | lr 1.04e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9923 | val_loss 1.0187 | train_acc 0.6437 | val_acc 0.6253 | lr 1.04e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9684 | val_loss 1.0137 | train_acc 0.6536 | val_acc 0.6316 | lr 1.04e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9476 | val_loss 1.0119 | train_acc 0.6590 | val_acc 0.6323 | lr 1.04e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9351 | val_loss 1.0104 | train_acc 0.6594 | val_acc 0.6327 | lr 1.04e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9208 | val_loss 1.0002 | train_acc 0.6662 | val_acc 0.6393 | lr 1.04e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9132 | val_loss 0.9964 | train_acc 0.6755 | val_acc 0.6404 | lr 1.04e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.9012 | val_loss 0.9970 | train_acc 0.6763 | val_acc 0.6382 | lr 1.04e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8829 | val_loss 1.0012 | train_acc 0.6766 | val_acc 0.6341 | lr 1.04e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8641 | val_loss 1.0011 | train_acc 0.6870 | val_acc 0.6353 | lr 1.04e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8571 | val_loss 0.9983 | train_acc 0.6923 | val_acc 0.6386 | lr 1.04e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8465 | val_loss 0.9946 | train_acc 0.6886 | val_acc 0.6393 | lr 1.04e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8404 | val_loss 0.9961 | train_acc 0.6982 | val_acc 0.6415 | lr 1.04e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8259 | val_loss 0.9916 | train_acc 0.7019 | val_acc 0.6393 | lr 1.04e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.8199 | val_loss 0.9905 | train_acc 0.7022 | val_acc 0.6349 | lr 1.04e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7966 | val_loss 0.9918 | train_acc 0.7183 | val_acc 0.6408 | lr 1.04e-04 | 0.5s\n",
      "epoch 024 | train_loss 0.7961 | val_loss 0.9930 | train_acc 0.7109 | val_acc 0.6434 | lr 1.04e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7802 | val_loss 0.9936 | train_acc 0.7209 | val_acc 0.6441 | lr 1.04e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7692 | val_loss 0.9953 | train_acc 0.7238 | val_acc 0.6375 | lr 1.04e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7640 | val_loss 0.9919 | train_acc 0.7290 | val_acc 0.6327 | lr 1.04e-04 | 0.5s\n",
      "epoch 028 | train_loss 0.7566 | val_loss 1.0002 | train_acc 0.7263 | val_acc 0.6375 | lr 1.04e-04 | 0.5s\n",
      "epoch 029 | train_loss 0.7458 | val_loss 0.9930 | train_acc 0.7319 | val_acc 0.6401 | lr 1.04e-04 | 0.5s\n",
      "epoch 030 | train_loss 0.7335 | val_loss 0.9908 | train_acc 0.7394 | val_acc 0.6449 | lr 1.04e-04 | 0.5s\n",
      "epoch 031 | train_loss 0.7277 | val_loss 0.9957 | train_acc 0.7395 | val_acc 0.6364 | lr 1.04e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:04:06,381] Trial 45 finished with value: 0.9904786089307188 and parameters: {'lr': 0.0001040778489059956, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 032 | train_loss 0.7183 | val_loss 0.9964 | train_acc 0.7396 | val_acc 0.6430 | lr 1.04e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4732 | val_loss 1.1875 | train_acc 0.5015 | val_acc 0.5746 | lr 3.14e-04 | 0.5s\n",
      "epoch 002 | train_loss 1.1941 | val_loss 1.1077 | train_acc 0.5780 | val_acc 0.6009 | lr 3.14e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1254 | val_loss 1.0774 | train_acc 0.5974 | val_acc 0.6001 | lr 3.14e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.0738 | val_loss 1.0501 | train_acc 0.6101 | val_acc 0.6212 | lr 3.14e-04 | 1.1s\n",
      "epoch 005 | train_loss 1.0462 | val_loss 1.0389 | train_acc 0.6255 | val_acc 0.6197 | lr 3.14e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0225 | val_loss 1.0257 | train_acc 0.6276 | val_acc 0.6253 | lr 3.14e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9992 | val_loss 1.0280 | train_acc 0.6387 | val_acc 0.6160 | lr 3.14e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9732 | val_loss 1.0212 | train_acc 0.6475 | val_acc 0.6249 | lr 3.14e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9627 | val_loss 1.0103 | train_acc 0.6481 | val_acc 0.6345 | lr 3.14e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9473 | val_loss 1.0144 | train_acc 0.6561 | val_acc 0.6334 | lr 3.14e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9183 | val_loss 1.0137 | train_acc 0.6665 | val_acc 0.6308 | lr 3.14e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9226 | val_loss 1.0110 | train_acc 0.6628 | val_acc 0.6297 | lr 3.14e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8940 | val_loss 1.0156 | train_acc 0.6706 | val_acc 0.6319 | lr 3.14e-04 | 0.9s\n",
      "epoch 014 | train_loss 0.8816 | val_loss 1.0133 | train_acc 0.6767 | val_acc 0.6293 | lr 3.14e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.8733 | val_loss 1.0124 | train_acc 0.6845 | val_acc 0.6301 | lr 3.14e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8644 | val_loss 1.0070 | train_acc 0.6835 | val_acc 0.6390 | lr 3.14e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.8508 | val_loss 0.9990 | train_acc 0.6883 | val_acc 0.6367 | lr 3.14e-04 | 0.8s\n",
      "epoch 018 | train_loss 0.8427 | val_loss 0.9986 | train_acc 0.6949 | val_acc 0.6367 | lr 3.14e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8302 | val_loss 1.0131 | train_acc 0.6966 | val_acc 0.6382 | lr 3.14e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8256 | val_loss 1.0031 | train_acc 0.6979 | val_acc 0.6434 | lr 3.14e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8078 | val_loss 1.0166 | train_acc 0.7059 | val_acc 0.6297 | lr 3.14e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7994 | val_loss 1.0100 | train_acc 0.7075 | val_acc 0.6345 | lr 3.14e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7812 | val_loss 1.0129 | train_acc 0.7170 | val_acc 0.6371 | lr 3.14e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7703 | val_loss 1.0175 | train_acc 0.7184 | val_acc 0.6293 | lr 3.14e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7807 | val_loss 1.0139 | train_acc 0.7095 | val_acc 0.6438 | lr 3.14e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7679 | val_loss 1.0259 | train_acc 0.7152 | val_acc 0.6360 | lr 3.14e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7564 | val_loss 1.0343 | train_acc 0.7214 | val_acc 0.6364 | lr 3.14e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:04:34,631] Trial 46 finished with value: 0.9986218362055438 and parameters: {'lr': 0.0003142482262886236, 'num_layers': 1, 'hidden_width': 128, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 028 | train_loss 0.7354 | val_loss 1.0233 | train_acc 0.7314 | val_acc 0.6445 | lr 3.14e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2570 | val_loss 1.1516 | train_acc 0.5490 | val_acc 0.5953 | lr 2.16e-03 | 1.2s\n",
      "epoch 002 | train_loss 1.1145 | val_loss 1.0637 | train_acc 0.5900 | val_acc 0.6131 | lr 2.16e-03 | 1.2s\n",
      "epoch 003 | train_loss 1.0587 | val_loss 1.0448 | train_acc 0.6135 | val_acc 0.6197 | lr 2.16e-03 | 1.2s\n",
      "epoch 004 | train_loss 1.0234 | val_loss 1.0481 | train_acc 0.6247 | val_acc 0.6105 | lr 2.16e-03 | 1.2s\n",
      "epoch 005 | train_loss 0.9803 | val_loss 1.0387 | train_acc 0.6375 | val_acc 0.6323 | lr 2.16e-03 | 1.2s\n",
      "epoch 006 | train_loss 0.9611 | val_loss 1.0474 | train_acc 0.6453 | val_acc 0.6205 | lr 2.16e-03 | 1.2s\n",
      "epoch 007 | train_loss 0.9356 | val_loss 1.0256 | train_acc 0.6509 | val_acc 0.6301 | lr 2.16e-03 | 1.2s\n",
      "epoch 008 | train_loss 0.9029 | val_loss 1.0309 | train_acc 0.6625 | val_acc 0.6194 | lr 2.16e-03 | 1.2s\n",
      "epoch 009 | train_loss 0.8750 | val_loss 1.0249 | train_acc 0.6769 | val_acc 0.6168 | lr 2.16e-03 | 1.2s\n",
      "epoch 010 | train_loss 0.8594 | val_loss 1.0241 | train_acc 0.6821 | val_acc 0.6301 | lr 2.16e-03 | 1.2s\n",
      "epoch 011 | train_loss 0.8420 | val_loss 1.0344 | train_acc 0.6880 | val_acc 0.6264 | lr 2.16e-03 | 1.2s\n",
      "epoch 012 | train_loss 0.8184 | val_loss 1.0432 | train_acc 0.6954 | val_acc 0.6264 | lr 2.16e-03 | 1.2s\n",
      "epoch 013 | train_loss 0.7937 | val_loss 1.0299 | train_acc 0.7071 | val_acc 0.6386 | lr 2.16e-03 | 1.2s\n",
      "epoch 014 | train_loss 0.7856 | val_loss 1.0340 | train_acc 0.7083 | val_acc 0.6290 | lr 2.16e-03 | 1.2s\n",
      "epoch 015 | train_loss 0.7644 | val_loss 1.0408 | train_acc 0.7118 | val_acc 0.6264 | lr 2.16e-03 | 1.2s\n",
      "epoch 016 | train_loss 0.7548 | val_loss 1.0557 | train_acc 0.7163 | val_acc 0.6301 | lr 2.16e-03 | 1.2s\n",
      "epoch 017 | train_loss 0.7259 | val_loss 1.0640 | train_acc 0.7339 | val_acc 0.6208 | lr 2.16e-03 | 1.2s\n",
      "epoch 018 | train_loss 0.7156 | val_loss 1.0559 | train_acc 0.7367 | val_acc 0.6293 | lr 2.16e-03 | 1.2s\n",
      "epoch 019 | train_loss 0.7010 | val_loss 1.0701 | train_acc 0.7373 | val_acc 0.6312 | lr 2.16e-03 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:04:58,124] Trial 47 finished with value: 1.0240976040396792 and parameters: {'lr': 0.00215636108110128, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.6993 | val_loss 1.0692 | train_acc 0.7363 | val_acc 0.6268 | lr 2.16e-03 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4235 | val_loss 1.1611 | train_acc 0.5048 | val_acc 0.5817 | lr 1.01e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1628 | val_loss 1.0884 | train_acc 0.5828 | val_acc 0.6050 | lr 1.01e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0854 | val_loss 1.0571 | train_acc 0.6095 | val_acc 0.6208 | lr 1.01e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0333 | val_loss 1.0414 | train_acc 0.6260 | val_acc 0.6201 | lr 1.01e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9984 | val_loss 1.0292 | train_acc 0.6363 | val_acc 0.6268 | lr 1.01e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9724 | val_loss 1.0163 | train_acc 0.6480 | val_acc 0.6308 | lr 1.01e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9340 | val_loss 1.0060 | train_acc 0.6668 | val_acc 0.6316 | lr 1.01e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9093 | val_loss 1.0023 | train_acc 0.6718 | val_acc 0.6327 | lr 1.01e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8886 | val_loss 1.0085 | train_acc 0.6770 | val_acc 0.6360 | lr 1.01e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8641 | val_loss 0.9986 | train_acc 0.6858 | val_acc 0.6401 | lr 1.01e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8431 | val_loss 1.0067 | train_acc 0.6916 | val_acc 0.6327 | lr 1.01e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8258 | val_loss 0.9948 | train_acc 0.7017 | val_acc 0.6356 | lr 1.01e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8022 | val_loss 0.9968 | train_acc 0.7098 | val_acc 0.6438 | lr 1.01e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7812 | val_loss 0.9952 | train_acc 0.7164 | val_acc 0.6434 | lr 1.01e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7648 | val_loss 0.9961 | train_acc 0.7287 | val_acc 0.6390 | lr 1.01e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7426 | val_loss 0.9990 | train_acc 0.7331 | val_acc 0.6475 | lr 1.01e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7311 | val_loss 0.9998 | train_acc 0.7361 | val_acc 0.6445 | lr 1.01e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7016 | val_loss 0.9965 | train_acc 0.7554 | val_acc 0.6545 | lr 1.01e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.6954 | val_loss 0.9979 | train_acc 0.7509 | val_acc 0.6438 | lr 1.01e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.6749 | val_loss 0.9948 | train_acc 0.7619 | val_acc 0.6475 | lr 1.01e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.6554 | val_loss 1.0051 | train_acc 0.7704 | val_acc 0.6441 | lr 1.01e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:05:24,314] Trial 48 finished with value: 0.9947645639545021 and parameters: {'lr': 0.0001006235245096149, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.6371 | val_loss 1.0114 | train_acc 0.7825 | val_acc 0.6482 | lr 1.01e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4325 | val_loss 1.1611 | train_acc 0.5037 | val_acc 0.5787 | lr 1.34e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1588 | val_loss 1.0858 | train_acc 0.5806 | val_acc 0.6083 | lr 1.34e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0797 | val_loss 1.0568 | train_acc 0.6083 | val_acc 0.6131 | lr 1.34e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0357 | val_loss 1.0353 | train_acc 0.6262 | val_acc 0.6264 | lr 1.34e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9996 | val_loss 1.0219 | train_acc 0.6375 | val_acc 0.6323 | lr 1.34e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9716 | val_loss 1.0112 | train_acc 0.6494 | val_acc 0.6390 | lr 1.34e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9418 | val_loss 1.0120 | train_acc 0.6590 | val_acc 0.6293 | lr 1.34e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9159 | val_loss 1.0022 | train_acc 0.6668 | val_acc 0.6360 | lr 1.34e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8991 | val_loss 1.0039 | train_acc 0.6727 | val_acc 0.6408 | lr 1.34e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8634 | val_loss 0.9915 | train_acc 0.6858 | val_acc 0.6401 | lr 1.34e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8451 | val_loss 0.9967 | train_acc 0.6922 | val_acc 0.6467 | lr 1.34e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8264 | val_loss 0.9955 | train_acc 0.6968 | val_acc 0.6434 | lr 1.34e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8157 | val_loss 0.9980 | train_acc 0.7063 | val_acc 0.6397 | lr 1.34e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7897 | val_loss 1.0077 | train_acc 0.7154 | val_acc 0.6301 | lr 1.34e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7769 | val_loss 1.0092 | train_acc 0.7234 | val_acc 0.6364 | lr 1.34e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7564 | val_loss 1.0044 | train_acc 0.7278 | val_acc 0.6412 | lr 1.34e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7382 | val_loss 0.9978 | train_acc 0.7373 | val_acc 0.6390 | lr 1.34e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7272 | val_loss 1.0066 | train_acc 0.7391 | val_acc 0.6456 | lr 1.34e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.7027 | val_loss 1.0105 | train_acc 0.7517 | val_acc 0.6349 | lr 1.34e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:05:48,185] Trial 49 finished with value: 0.9914574223981464 and parameters: {'lr': 0.00013350392458290098, 'num_layers': 1, 'hidden_width': 512, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.6961 | val_loss 1.0102 | train_acc 0.7480 | val_acc 0.6415 | lr 1.34e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4989 | val_loss 1.2028 | train_acc 0.4871 | val_acc 0.5754 | lr 1.57e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2015 | val_loss 1.1234 | train_acc 0.5743 | val_acc 0.5946 | lr 1.57e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1219 | val_loss 1.0804 | train_acc 0.5962 | val_acc 0.6086 | lr 1.57e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0824 | val_loss 1.0619 | train_acc 0.6133 | val_acc 0.6101 | lr 1.57e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0419 | val_loss 1.0412 | train_acc 0.6210 | val_acc 0.6142 | lr 1.57e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0172 | val_loss 1.0294 | train_acc 0.6337 | val_acc 0.6208 | lr 1.57e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9848 | val_loss 1.0202 | train_acc 0.6433 | val_acc 0.6308 | lr 1.57e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9609 | val_loss 1.0143 | train_acc 0.6501 | val_acc 0.6264 | lr 1.57e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9454 | val_loss 1.0150 | train_acc 0.6589 | val_acc 0.6330 | lr 1.57e-04 | 1.1s\n",
      "epoch 010 | train_loss 0.9283 | val_loss 1.0190 | train_acc 0.6625 | val_acc 0.6312 | lr 1.57e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9099 | val_loss 1.0051 | train_acc 0.6715 | val_acc 0.6312 | lr 1.57e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8861 | val_loss 1.0051 | train_acc 0.6765 | val_acc 0.6323 | lr 1.57e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8713 | val_loss 0.9957 | train_acc 0.6838 | val_acc 0.6364 | lr 1.57e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8620 | val_loss 1.0047 | train_acc 0.6891 | val_acc 0.6367 | lr 1.57e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8503 | val_loss 1.0120 | train_acc 0.6897 | val_acc 0.6279 | lr 1.57e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8270 | val_loss 0.9967 | train_acc 0.6995 | val_acc 0.6449 | lr 1.57e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8100 | val_loss 1.0005 | train_acc 0.7009 | val_acc 0.6445 | lr 1.57e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8014 | val_loss 1.0013 | train_acc 0.7119 | val_acc 0.6397 | lr 1.57e-04 | 1.1s\n",
      "epoch 019 | train_loss 0.7902 | val_loss 0.9999 | train_acc 0.7149 | val_acc 0.6423 | lr 1.57e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.7726 | val_loss 0.9962 | train_acc 0.7220 | val_acc 0.6371 | lr 1.57e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7615 | val_loss 1.0056 | train_acc 0.7227 | val_acc 0.6364 | lr 1.57e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7437 | val_loss 0.9992 | train_acc 0.7331 | val_acc 0.6471 | lr 1.57e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:06:15,048] Trial 50 finished with value: 0.9957059157485003 and parameters: {'lr': 0.00015710749890881313, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.7441 | val_loss 1.0051 | train_acc 0.7302 | val_acc 0.6393 | lr 1.57e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4924 | val_loss 1.2235 | train_acc 0.4913 | val_acc 0.5650 | lr 1.23e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2197 | val_loss 1.1259 | train_acc 0.5688 | val_acc 0.5990 | lr 1.23e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1384 | val_loss 1.0888 | train_acc 0.5976 | val_acc 0.6164 | lr 1.23e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0957 | val_loss 1.0709 | train_acc 0.6056 | val_acc 0.6105 | lr 1.23e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0556 | val_loss 1.0471 | train_acc 0.6220 | val_acc 0.6234 | lr 1.23e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0289 | val_loss 1.0433 | train_acc 0.6277 | val_acc 0.6175 | lr 1.23e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0087 | val_loss 1.0267 | train_acc 0.6372 | val_acc 0.6341 | lr 1.23e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9874 | val_loss 1.0183 | train_acc 0.6414 | val_acc 0.6364 | lr 1.23e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9696 | val_loss 1.0131 | train_acc 0.6473 | val_acc 0.6330 | lr 1.23e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9439 | val_loss 1.0122 | train_acc 0.6602 | val_acc 0.6408 | lr 1.23e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9347 | val_loss 1.0020 | train_acc 0.6600 | val_acc 0.6412 | lr 1.23e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9157 | val_loss 1.0037 | train_acc 0.6713 | val_acc 0.6393 | lr 1.23e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9042 | val_loss 1.0044 | train_acc 0.6704 | val_acc 0.6390 | lr 1.23e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8908 | val_loss 0.9970 | train_acc 0.6814 | val_acc 0.6423 | lr 1.23e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8716 | val_loss 0.9911 | train_acc 0.6857 | val_acc 0.6401 | lr 1.23e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8534 | val_loss 0.9986 | train_acc 0.6927 | val_acc 0.6434 | lr 1.23e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8393 | val_loss 0.9982 | train_acc 0.6997 | val_acc 0.6393 | lr 1.23e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8301 | val_loss 0.9934 | train_acc 0.6999 | val_acc 0.6452 | lr 1.23e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8202 | val_loss 0.9884 | train_acc 0.7005 | val_acc 0.6419 | lr 1.23e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8144 | val_loss 0.9924 | train_acc 0.7031 | val_acc 0.6438 | lr 1.23e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7960 | val_loss 0.9969 | train_acc 0.7134 | val_acc 0.6438 | lr 1.23e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7953 | val_loss 1.0026 | train_acc 0.7167 | val_acc 0.6434 | lr 1.23e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7719 | val_loss 1.0046 | train_acc 0.7169 | val_acc 0.6327 | lr 1.23e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7631 | val_loss 0.9933 | train_acc 0.7213 | val_acc 0.6404 | lr 1.23e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7471 | val_loss 0.9981 | train_acc 0.7272 | val_acc 0.6367 | lr 1.23e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7373 | val_loss 1.0048 | train_acc 0.7371 | val_acc 0.6327 | lr 1.23e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7292 | val_loss 0.9957 | train_acc 0.7394 | val_acc 0.6441 | lr 1.23e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7250 | val_loss 1.0056 | train_acc 0.7370 | val_acc 0.6382 | lr 1.23e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:06:48,865] Trial 51 finished with value: 0.9884241568275671 and parameters: {'lr': 0.00012338079400158207, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7079 | val_loss 1.0092 | train_acc 0.7447 | val_acc 0.6375 | lr 1.23e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5056 | val_loss 1.2158 | train_acc 0.4910 | val_acc 0.5713 | lr 1.27e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2127 | val_loss 1.1274 | train_acc 0.5684 | val_acc 0.5976 | lr 1.27e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1415 | val_loss 1.0833 | train_acc 0.5939 | val_acc 0.6053 | lr 1.27e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0947 | val_loss 1.0578 | train_acc 0.6095 | val_acc 0.6135 | lr 1.27e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0515 | val_loss 1.0498 | train_acc 0.6245 | val_acc 0.6149 | lr 1.27e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0328 | val_loss 1.0304 | train_acc 0.6255 | val_acc 0.6234 | lr 1.27e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0027 | val_loss 1.0233 | train_acc 0.6345 | val_acc 0.6290 | lr 1.27e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9859 | val_loss 1.0172 | train_acc 0.6411 | val_acc 0.6297 | lr 1.27e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9633 | val_loss 1.0095 | train_acc 0.6529 | val_acc 0.6282 | lr 1.27e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9486 | val_loss 1.0038 | train_acc 0.6565 | val_acc 0.6353 | lr 1.27e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9240 | val_loss 0.9978 | train_acc 0.6612 | val_acc 0.6393 | lr 1.27e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9131 | val_loss 0.9933 | train_acc 0.6706 | val_acc 0.6360 | lr 1.27e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8980 | val_loss 0.9958 | train_acc 0.6709 | val_acc 0.6393 | lr 1.27e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8792 | val_loss 0.9970 | train_acc 0.6806 | val_acc 0.6360 | lr 1.27e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8678 | val_loss 0.9931 | train_acc 0.6853 | val_acc 0.6375 | lr 1.27e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8500 | val_loss 0.9905 | train_acc 0.6934 | val_acc 0.6393 | lr 1.27e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8400 | val_loss 0.9887 | train_acc 0.6931 | val_acc 0.6475 | lr 1.27e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8190 | val_loss 0.9907 | train_acc 0.7051 | val_acc 0.6386 | lr 1.27e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8169 | val_loss 0.9937 | train_acc 0.7054 | val_acc 0.6449 | lr 1.27e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.7992 | val_loss 0.9951 | train_acc 0.7097 | val_acc 0.6449 | lr 1.27e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7902 | val_loss 0.9886 | train_acc 0.7164 | val_acc 0.6404 | lr 1.27e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7766 | val_loss 0.9895 | train_acc 0.7206 | val_acc 0.6463 | lr 1.27e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7699 | val_loss 0.9888 | train_acc 0.7242 | val_acc 0.6482 | lr 1.27e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7602 | val_loss 0.9908 | train_acc 0.7258 | val_acc 0.6430 | lr 1.27e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7472 | val_loss 1.0109 | train_acc 0.7292 | val_acc 0.6367 | lr 1.27e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7354 | val_loss 1.0005 | train_acc 0.7330 | val_acc 0.6426 | lr 1.27e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7260 | val_loss 0.9977 | train_acc 0.7389 | val_acc 0.6367 | lr 1.27e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7104 | val_loss 1.0075 | train_acc 0.7461 | val_acc 0.6475 | lr 1.27e-04 | 1.2s\n",
      "epoch 029 | train_loss 0.7066 | val_loss 0.9937 | train_acc 0.7467 | val_acc 0.6445 | lr 1.27e-04 | 1.2s\n",
      "epoch 030 | train_loss 0.6952 | val_loss 0.9957 | train_acc 0.7497 | val_acc 0.6390 | lr 1.27e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:07:25,196] Trial 52 finished with value: 0.9886135039114546 and parameters: {'lr': 0.00012708236548017947, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 031 | train_loss 0.6948 | val_loss 1.0074 | train_acc 0.7501 | val_acc 0.6323 | lr 1.27e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5470 | val_loss 1.2306 | train_acc 0.4773 | val_acc 0.5599 | lr 1.20e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2333 | val_loss 1.1400 | train_acc 0.5696 | val_acc 0.5961 | lr 1.20e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1564 | val_loss 1.1003 | train_acc 0.5902 | val_acc 0.5979 | lr 1.20e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.1096 | val_loss 1.0738 | train_acc 0.6022 | val_acc 0.6101 | lr 1.20e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0743 | val_loss 1.0496 | train_acc 0.6139 | val_acc 0.6208 | lr 1.20e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0464 | val_loss 1.0445 | train_acc 0.6230 | val_acc 0.6183 | lr 1.20e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0209 | val_loss 1.0343 | train_acc 0.6306 | val_acc 0.6238 | lr 1.20e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9925 | val_loss 1.0219 | train_acc 0.6380 | val_acc 0.6297 | lr 1.20e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9808 | val_loss 1.0127 | train_acc 0.6425 | val_acc 0.6323 | lr 1.20e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9604 | val_loss 1.0081 | train_acc 0.6534 | val_acc 0.6319 | lr 1.20e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9496 | val_loss 1.0113 | train_acc 0.6547 | val_acc 0.6297 | lr 1.20e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9301 | val_loss 1.0043 | train_acc 0.6645 | val_acc 0.6393 | lr 1.20e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9100 | val_loss 1.0072 | train_acc 0.6674 | val_acc 0.6316 | lr 1.20e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8949 | val_loss 1.0018 | train_acc 0.6731 | val_acc 0.6297 | lr 1.20e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8823 | val_loss 0.9980 | train_acc 0.6802 | val_acc 0.6323 | lr 1.20e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8689 | val_loss 0.9930 | train_acc 0.6821 | val_acc 0.6393 | lr 1.20e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8561 | val_loss 0.9941 | train_acc 0.6924 | val_acc 0.6378 | lr 1.20e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8421 | val_loss 0.9971 | train_acc 0.6928 | val_acc 0.6412 | lr 1.20e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8256 | val_loss 0.9904 | train_acc 0.6987 | val_acc 0.6456 | lr 1.20e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8130 | val_loss 0.9910 | train_acc 0.7047 | val_acc 0.6449 | lr 1.20e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8100 | val_loss 0.9892 | train_acc 0.7071 | val_acc 0.6438 | lr 1.20e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7944 | val_loss 0.9933 | train_acc 0.7098 | val_acc 0.6423 | lr 1.20e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7840 | val_loss 0.9910 | train_acc 0.7162 | val_acc 0.6419 | lr 1.20e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7701 | val_loss 0.9959 | train_acc 0.7213 | val_acc 0.6412 | lr 1.20e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7691 | val_loss 0.9916 | train_acc 0.7223 | val_acc 0.6478 | lr 1.20e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7496 | val_loss 0.9983 | train_acc 0.7287 | val_acc 0.6482 | lr 1.20e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7482 | val_loss 1.0007 | train_acc 0.7339 | val_acc 0.6452 | lr 1.20e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7254 | val_loss 0.9955 | train_acc 0.7389 | val_acc 0.6419 | lr 1.20e-04 | 1.2s\n",
      "epoch 029 | train_loss 0.7212 | val_loss 0.9927 | train_acc 0.7390 | val_acc 0.6438 | lr 1.20e-04 | 1.1s\n",
      "epoch 030 | train_loss 0.7154 | val_loss 1.0003 | train_acc 0.7388 | val_acc 0.6415 | lr 1.20e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:08:01,421] Trial 53 finished with value: 0.9891875393727225 and parameters: {'lr': 0.00012038016558037702, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 031 | train_loss 0.6973 | val_loss 0.9954 | train_acc 0.7509 | val_acc 0.6401 | lr 1.20e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3041 | val_loss 1.0998 | train_acc 0.5443 | val_acc 0.5953 | lr 5.05e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1103 | val_loss 1.0552 | train_acc 0.5987 | val_acc 0.6149 | lr 5.05e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0510 | val_loss 1.0436 | train_acc 0.6192 | val_acc 0.6164 | lr 5.05e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0060 | val_loss 1.0281 | train_acc 0.6291 | val_acc 0.6253 | lr 5.05e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9790 | val_loss 1.0175 | train_acc 0.6428 | val_acc 0.6271 | lr 5.05e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9457 | val_loss 1.0131 | train_acc 0.6500 | val_acc 0.6375 | lr 5.05e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9161 | val_loss 1.0086 | train_acc 0.6671 | val_acc 0.6242 | lr 5.05e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8981 | val_loss 1.0132 | train_acc 0.6677 | val_acc 0.6323 | lr 5.05e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8604 | val_loss 1.0030 | train_acc 0.6855 | val_acc 0.6356 | lr 5.05e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8428 | val_loss 1.0176 | train_acc 0.6887 | val_acc 0.6327 | lr 5.05e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8324 | val_loss 1.0067 | train_acc 0.6924 | val_acc 0.6371 | lr 5.05e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8147 | val_loss 1.0128 | train_acc 0.6980 | val_acc 0.6367 | lr 5.05e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7819 | val_loss 1.0074 | train_acc 0.7104 | val_acc 0.6378 | lr 5.05e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7747 | val_loss 1.0248 | train_acc 0.7154 | val_acc 0.6375 | lr 5.05e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7545 | val_loss 1.0215 | train_acc 0.7217 | val_acc 0.6297 | lr 5.05e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7378 | val_loss 1.0121 | train_acc 0.7268 | val_acc 0.6497 | lr 5.05e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7213 | val_loss 1.0229 | train_acc 0.7338 | val_acc 0.6316 | lr 5.05e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7113 | val_loss 1.0201 | train_acc 0.7401 | val_acc 0.6463 | lr 5.05e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:08:23,722] Trial 54 finished with value: 1.0029664831697191 and parameters: {'lr': 0.0005045210504809411, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 019 | train_loss 0.6834 | val_loss 1.0353 | train_acc 0.7481 | val_acc 0.6371 | lr 5.05e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5846 | val_loss 1.2703 | train_acc 0.4638 | val_acc 0.5588 | lr 1.65e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2649 | val_loss 1.1668 | train_acc 0.5576 | val_acc 0.5876 | lr 1.65e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1841 | val_loss 1.1218 | train_acc 0.5861 | val_acc 0.6013 | lr 1.65e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.1356 | val_loss 1.0908 | train_acc 0.5965 | val_acc 0.6016 | lr 1.65e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0984 | val_loss 1.0711 | train_acc 0.6054 | val_acc 0.6105 | lr 1.65e-04 | 1.1s\n",
      "epoch 006 | train_loss 1.0668 | val_loss 1.0600 | train_acc 0.6151 | val_acc 0.6123 | lr 1.65e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0453 | val_loss 1.0487 | train_acc 0.6230 | val_acc 0.6098 | lr 1.65e-04 | 1.2s\n",
      "epoch 008 | train_loss 1.0279 | val_loss 1.0436 | train_acc 0.6298 | val_acc 0.6149 | lr 1.65e-04 | 1.2s\n",
      "epoch 009 | train_loss 1.0078 | val_loss 1.0325 | train_acc 0.6360 | val_acc 0.6168 | lr 1.65e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9838 | val_loss 1.0318 | train_acc 0.6405 | val_acc 0.6268 | lr 1.65e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9718 | val_loss 1.0242 | train_acc 0.6493 | val_acc 0.6223 | lr 1.65e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9587 | val_loss 1.0186 | train_acc 0.6498 | val_acc 0.6275 | lr 1.65e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9568 | val_loss 1.0140 | train_acc 0.6535 | val_acc 0.6312 | lr 1.65e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.9369 | val_loss 1.0188 | train_acc 0.6626 | val_acc 0.6286 | lr 1.65e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.9228 | val_loss 1.0131 | train_acc 0.6610 | val_acc 0.6345 | lr 1.65e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.9107 | val_loss 1.0103 | train_acc 0.6726 | val_acc 0.6286 | lr 1.65e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.9027 | val_loss 1.0145 | train_acc 0.6730 | val_acc 0.6293 | lr 1.65e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8970 | val_loss 1.0097 | train_acc 0.6688 | val_acc 0.6393 | lr 1.65e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8772 | val_loss 1.0035 | train_acc 0.6827 | val_acc 0.6404 | lr 1.65e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8706 | val_loss 1.0065 | train_acc 0.6864 | val_acc 0.6308 | lr 1.65e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8584 | val_loss 1.0104 | train_acc 0.6870 | val_acc 0.6371 | lr 1.65e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.8487 | val_loss 1.0139 | train_acc 0.6933 | val_acc 0.6353 | lr 1.65e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.8528 | val_loss 1.0071 | train_acc 0.6886 | val_acc 0.6375 | lr 1.65e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.8385 | val_loss 1.0102 | train_acc 0.6930 | val_acc 0.6364 | lr 1.65e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.8281 | val_loss 1.0024 | train_acc 0.6984 | val_acc 0.6386 | lr 1.65e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.8183 | val_loss 1.0060 | train_acc 0.7009 | val_acc 0.6386 | lr 1.65e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.8116 | val_loss 1.0050 | train_acc 0.7035 | val_acc 0.6386 | lr 1.65e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.8013 | val_loss 1.0157 | train_acc 0.7111 | val_acc 0.6360 | lr 1.65e-04 | 1.2s\n",
      "epoch 029 | train_loss 0.7933 | val_loss 1.0045 | train_acc 0.7107 | val_acc 0.6423 | lr 1.65e-04 | 1.2s\n",
      "epoch 030 | train_loss 0.7865 | val_loss 1.0068 | train_acc 0.7097 | val_acc 0.6426 | lr 1.65e-04 | 1.2s\n",
      "epoch 031 | train_loss 0.7805 | val_loss 1.0115 | train_acc 0.7168 | val_acc 0.6441 | lr 1.65e-04 | 1.2s\n",
      "epoch 032 | train_loss 0.7762 | val_loss 1.0225 | train_acc 0.7149 | val_acc 0.6415 | lr 1.65e-04 | 1.2s\n",
      "epoch 033 | train_loss 0.7737 | val_loss 1.0195 | train_acc 0.7181 | val_acc 0.6390 | lr 1.65e-04 | 1.2s\n",
      "epoch 034 | train_loss 0.7632 | val_loss 1.0062 | train_acc 0.7217 | val_acc 0.6412 | lr 1.65e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:09:04,747] Trial 55 finished with value: 1.0024065026863362 and parameters: {'lr': 0.00016494605646107287, 'num_layers': 1, 'hidden_width': 128, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 035 | train_loss 0.7560 | val_loss 1.0101 | train_acc 0.7225 | val_acc 0.6382 | lr 1.65e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4748 | val_loss 1.2142 | train_acc 0.4976 | val_acc 0.5606 | lr 2.21e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.1889 | val_loss 1.1151 | train_acc 0.5745 | val_acc 0.5946 | lr 2.21e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1150 | val_loss 1.0774 | train_acc 0.6013 | val_acc 0.6131 | lr 2.21e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.0670 | val_loss 1.0566 | train_acc 0.6192 | val_acc 0.6127 | lr 2.21e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.0264 | val_loss 1.0438 | train_acc 0.6301 | val_acc 0.6260 | lr 2.21e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0038 | val_loss 1.0252 | train_acc 0.6381 | val_acc 0.6249 | lr 2.21e-04 | 0.6s\n",
      "epoch 007 | train_loss 0.9713 | val_loss 1.0201 | train_acc 0.6497 | val_acc 0.6293 | lr 2.21e-04 | 0.6s\n",
      "epoch 008 | train_loss 0.9535 | val_loss 1.0104 | train_acc 0.6557 | val_acc 0.6349 | lr 2.21e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.9286 | val_loss 1.0087 | train_acc 0.6609 | val_acc 0.6341 | lr 2.21e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9132 | val_loss 1.0080 | train_acc 0.6690 | val_acc 0.6349 | lr 2.21e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.8911 | val_loss 1.0063 | train_acc 0.6749 | val_acc 0.6415 | lr 2.21e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.8730 | val_loss 1.0036 | train_acc 0.6804 | val_acc 0.6353 | lr 2.21e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.8545 | val_loss 1.0015 | train_acc 0.6902 | val_acc 0.6434 | lr 2.21e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.8353 | val_loss 0.9963 | train_acc 0.6984 | val_acc 0.6378 | lr 2.21e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.8217 | val_loss 1.0013 | train_acc 0.7062 | val_acc 0.6356 | lr 2.21e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8085 | val_loss 1.0024 | train_acc 0.7083 | val_acc 0.6386 | lr 2.21e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.7853 | val_loss 0.9979 | train_acc 0.7169 | val_acc 0.6401 | lr 2.21e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.7840 | val_loss 0.9986 | train_acc 0.7156 | val_acc 0.6378 | lr 2.21e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.7702 | val_loss 1.0014 | train_acc 0.7215 | val_acc 0.6445 | lr 2.21e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.7566 | val_loss 1.0003 | train_acc 0.7274 | val_acc 0.6438 | lr 2.21e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.7331 | val_loss 1.0178 | train_acc 0.7414 | val_acc 0.6386 | lr 2.21e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.7167 | val_loss 1.0103 | train_acc 0.7455 | val_acc 0.6397 | lr 2.21e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.7141 | val_loss 1.0097 | train_acc 0.7487 | val_acc 0.6404 | lr 2.21e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:09:19,134] Trial 56 finished with value: 0.9962704585202958 and parameters: {'lr': 0.00022053060910351107, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 64, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.6968 | val_loss 1.0106 | train_acc 0.7519 | val_acc 0.6415 | lr 2.21e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4508 | val_loss 1.1852 | train_acc 0.5024 | val_acc 0.5691 | lr 1.08e-04 | 1.3s\n",
      "epoch 002 | train_loss 1.1822 | val_loss 1.1061 | train_acc 0.5757 | val_acc 0.6009 | lr 1.08e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1093 | val_loss 1.0686 | train_acc 0.5999 | val_acc 0.6072 | lr 1.08e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0621 | val_loss 1.0466 | train_acc 0.6209 | val_acc 0.6190 | lr 1.08e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0209 | val_loss 1.0312 | train_acc 0.6267 | val_acc 0.6245 | lr 1.08e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9926 | val_loss 1.0195 | train_acc 0.6389 | val_acc 0.6334 | lr 1.08e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9682 | val_loss 1.0207 | train_acc 0.6487 | val_acc 0.6242 | lr 1.08e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9405 | val_loss 1.0070 | train_acc 0.6604 | val_acc 0.6293 | lr 1.08e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9259 | val_loss 1.0018 | train_acc 0.6593 | val_acc 0.6364 | lr 1.08e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8974 | val_loss 1.0047 | train_acc 0.6699 | val_acc 0.6412 | lr 1.08e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8821 | val_loss 0.9974 | train_acc 0.6824 | val_acc 0.6419 | lr 1.08e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8595 | val_loss 0.9995 | train_acc 0.6902 | val_acc 0.6390 | lr 1.08e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8364 | val_loss 0.9997 | train_acc 0.7008 | val_acc 0.6397 | lr 1.08e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8287 | val_loss 0.9953 | train_acc 0.7002 | val_acc 0.6412 | lr 1.08e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8043 | val_loss 0.9888 | train_acc 0.7105 | val_acc 0.6482 | lr 1.08e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7875 | val_loss 0.9931 | train_acc 0.7145 | val_acc 0.6401 | lr 1.08e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7645 | val_loss 0.9943 | train_acc 0.7273 | val_acc 0.6445 | lr 1.08e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7598 | val_loss 0.9947 | train_acc 0.7280 | val_acc 0.6375 | lr 1.08e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.7355 | val_loss 0.9971 | train_acc 0.7325 | val_acc 0.6463 | lr 1.08e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.7268 | val_loss 1.0035 | train_acc 0.7351 | val_acc 0.6393 | lr 1.08e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7136 | val_loss 0.9993 | train_acc 0.7464 | val_acc 0.6393 | lr 1.08e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.6925 | val_loss 0.9976 | train_acc 0.7527 | val_acc 0.6445 | lr 1.08e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.6856 | val_loss 1.0137 | train_acc 0.7574 | val_acc 0.6375 | lr 1.08e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.6676 | val_loss 1.0016 | train_acc 0.7627 | val_acc 0.6419 | lr 1.08e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:09:48,802] Trial 57 finished with value: 0.9887909246918367 and parameters: {'lr': 0.0001077621089582363, 'num_layers': 1, 'hidden_width': 512, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.6486 | val_loss 1.0067 | train_acc 0.7693 | val_acc 0.6330 | lr 1.08e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3499 | val_loss 1.1334 | train_acc 0.5246 | val_acc 0.5865 | lr 1.36e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1231 | val_loss 1.0635 | train_acc 0.5994 | val_acc 0.6101 | lr 1.36e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0516 | val_loss 1.0402 | train_acc 0.6190 | val_acc 0.6109 | lr 1.36e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0059 | val_loss 1.0209 | train_acc 0.6354 | val_acc 0.6260 | lr 1.36e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9654 | val_loss 1.0093 | train_acc 0.6496 | val_acc 0.6375 | lr 1.36e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9331 | val_loss 0.9970 | train_acc 0.6627 | val_acc 0.6397 | lr 1.36e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.8965 | val_loss 0.9944 | train_acc 0.6748 | val_acc 0.6390 | lr 1.36e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8689 | val_loss 0.9958 | train_acc 0.6850 | val_acc 0.6397 | lr 1.36e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8491 | val_loss 0.9985 | train_acc 0.6937 | val_acc 0.6412 | lr 1.36e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8139 | val_loss 0.9905 | train_acc 0.7057 | val_acc 0.6404 | lr 1.36e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.7960 | val_loss 0.9843 | train_acc 0.7145 | val_acc 0.6449 | lr 1.36e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.7683 | val_loss 0.9837 | train_acc 0.7210 | val_acc 0.6475 | lr 1.36e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7528 | val_loss 0.9970 | train_acc 0.7288 | val_acc 0.6375 | lr 1.36e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7279 | val_loss 0.9886 | train_acc 0.7372 | val_acc 0.6445 | lr 1.36e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.6988 | val_loss 0.9974 | train_acc 0.7500 | val_acc 0.6441 | lr 1.36e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.6840 | val_loss 1.0089 | train_acc 0.7558 | val_acc 0.6404 | lr 1.36e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.6642 | val_loss 0.9928 | train_acc 0.7683 | val_acc 0.6471 | lr 1.36e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.6441 | val_loss 0.9955 | train_acc 0.7744 | val_acc 0.6412 | lr 1.36e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.6267 | val_loss 1.0092 | train_acc 0.7785 | val_acc 0.6382 | lr 1.36e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.6100 | val_loss 1.0121 | train_acc 0.7823 | val_acc 0.6419 | lr 1.36e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.5907 | val_loss 1.0090 | train_acc 0.7956 | val_acc 0.6456 | lr 1.36e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:10:14,927] Trial 58 finished with value: 0.9836578839634051 and parameters: {'lr': 0.0001361202565499474, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.5728 | val_loss 1.0145 | train_acc 0.7982 | val_acc 0.6412 | lr 1.36e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2781 | val_loss 1.1105 | train_acc 0.5501 | val_acc 0.5909 | lr 2.79e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.0822 | val_loss 1.0544 | train_acc 0.6102 | val_acc 0.6208 | lr 2.79e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0099 | val_loss 1.0236 | train_acc 0.6356 | val_acc 0.6231 | lr 2.79e-04 | 1.2s\n",
      "epoch 004 | train_loss 0.9592 | val_loss 1.0154 | train_acc 0.6511 | val_acc 0.6349 | lr 2.78e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9210 | val_loss 1.0240 | train_acc 0.6642 | val_acc 0.6197 | lr 2.78e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.8809 | val_loss 1.0018 | train_acc 0.6766 | val_acc 0.6334 | lr 2.77e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.8507 | val_loss 1.0296 | train_acc 0.6949 | val_acc 0.6242 | lr 2.76e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8213 | val_loss 1.0152 | train_acc 0.7041 | val_acc 0.6345 | lr 2.75e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.7794 | val_loss 1.0086 | train_acc 0.7172 | val_acc 0.6497 | lr 2.74e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.7538 | val_loss 1.0104 | train_acc 0.7264 | val_acc 0.6371 | lr 2.72e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.7231 | val_loss 1.0227 | train_acc 0.7377 | val_acc 0.6275 | lr 2.71e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.6998 | val_loss 1.0090 | train_acc 0.7463 | val_acc 0.6386 | lr 2.69e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.6739 | val_loss 1.0437 | train_acc 0.7578 | val_acc 0.6349 | lr 2.68e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.6526 | val_loss 1.0434 | train_acc 0.7672 | val_acc 0.6316 | lr 2.66e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.6199 | val_loss 1.0292 | train_acc 0.7781 | val_acc 0.6330 | lr 2.64e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:10:33,934] Trial 59 finished with value: 1.0017518220085262 and parameters: {'lr': 0.0002792932094010062, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': True}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 016 | train_loss 0.5990 | val_loss 1.0507 | train_acc 0.7862 | val_acc 0.6341 | lr 2.62e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3969 | val_loss 1.2021 | train_acc 0.5146 | val_acc 0.5931 | lr 1.45e-04 | 0.9s\n",
      "epoch 002 | train_loss 1.1216 | val_loss 1.0712 | train_acc 0.5991 | val_acc 0.6116 | lr 1.45e-04 | 0.8s\n",
      "epoch 003 | train_loss 1.0440 | val_loss 1.0508 | train_acc 0.6200 | val_acc 0.6160 | lr 1.45e-04 | 0.8s\n",
      "epoch 004 | train_loss 1.0002 | val_loss 1.0354 | train_acc 0.6389 | val_acc 0.6268 | lr 1.45e-04 | 0.8s\n",
      "epoch 005 | train_loss 0.9411 | val_loss 1.0314 | train_acc 0.6612 | val_acc 0.6275 | lr 1.45e-04 | 0.8s\n",
      "epoch 006 | train_loss 0.9102 | val_loss 1.0270 | train_acc 0.6705 | val_acc 0.6268 | lr 1.45e-04 | 0.8s\n",
      "epoch 007 | train_loss 0.8659 | val_loss 1.0126 | train_acc 0.6880 | val_acc 0.6323 | lr 1.45e-04 | 0.8s\n",
      "epoch 008 | train_loss 0.8343 | val_loss 1.0111 | train_acc 0.7006 | val_acc 0.6386 | lr 1.45e-04 | 0.8s\n",
      "epoch 009 | train_loss 0.8023 | val_loss 1.0149 | train_acc 0.7106 | val_acc 0.6341 | lr 1.45e-04 | 0.8s\n",
      "epoch 010 | train_loss 0.7715 | val_loss 1.0034 | train_acc 0.7218 | val_acc 0.6390 | lr 1.45e-04 | 0.8s\n",
      "epoch 011 | train_loss 0.7370 | val_loss 1.0106 | train_acc 0.7303 | val_acc 0.6367 | lr 1.45e-04 | 0.8s\n",
      "epoch 012 | train_loss 0.7071 | val_loss 1.0459 | train_acc 0.7419 | val_acc 0.6205 | lr 1.45e-04 | 0.8s\n",
      "epoch 013 | train_loss 0.6827 | val_loss 1.0101 | train_acc 0.7511 | val_acc 0.6463 | lr 1.45e-04 | 0.8s\n",
      "epoch 014 | train_loss 0.6514 | val_loss 1.0172 | train_acc 0.7629 | val_acc 0.6471 | lr 1.45e-04 | 0.8s\n",
      "epoch 015 | train_loss 0.6335 | val_loss 1.0504 | train_acc 0.7686 | val_acc 0.6319 | lr 1.45e-04 | 0.8s\n",
      "epoch 016 | train_loss 0.5999 | val_loss 1.0419 | train_acc 0.7866 | val_acc 0.6275 | lr 1.45e-04 | 0.8s\n",
      "epoch 017 | train_loss 0.5811 | val_loss 1.0562 | train_acc 0.7917 | val_acc 0.6316 | lr 1.45e-04 | 0.8s\n",
      "epoch 018 | train_loss 0.5673 | val_loss 1.0496 | train_acc 0.7938 | val_acc 0.6419 | lr 1.45e-04 | 0.8s\n",
      "epoch 019 | train_loss 0.5423 | val_loss 1.0585 | train_acc 0.8045 | val_acc 0.6386 | lr 1.45e-04 | 0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:10:50,430] Trial 60 finished with value: 1.0033655888225446 and parameters: {'lr': 0.0001452003569453679, 'num_layers': 2, 'hidden_width': 768, 'batch_size': 64, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.5262 | val_loss 1.0788 | train_acc 0.8068 | val_acc 0.6378 | lr 1.45e-04 | 0.8s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3195 | val_loss 1.1125 | train_acc 0.5308 | val_acc 0.5983 | lr 1.82e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.0943 | val_loss 1.0600 | train_acc 0.6027 | val_acc 0.6131 | lr 1.82e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0249 | val_loss 1.0340 | train_acc 0.6300 | val_acc 0.6223 | lr 1.82e-04 | 1.2s\n",
      "epoch 004 | train_loss 0.9815 | val_loss 1.0169 | train_acc 0.6483 | val_acc 0.6275 | lr 1.82e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9408 | val_loss 1.0102 | train_acc 0.6651 | val_acc 0.6330 | lr 1.82e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9047 | val_loss 1.0028 | train_acc 0.6754 | val_acc 0.6382 | lr 1.82e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.8792 | val_loss 1.0011 | train_acc 0.6756 | val_acc 0.6412 | lr 1.82e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8461 | val_loss 1.0026 | train_acc 0.6925 | val_acc 0.6378 | lr 1.82e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8150 | val_loss 1.0011 | train_acc 0.7067 | val_acc 0.6349 | lr 1.82e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.7790 | val_loss 1.0245 | train_acc 0.7235 | val_acc 0.6301 | lr 1.82e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.7629 | val_loss 1.0131 | train_acc 0.7241 | val_acc 0.6371 | lr 1.82e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.7415 | val_loss 1.0151 | train_acc 0.7353 | val_acc 0.6249 | lr 1.82e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7070 | val_loss 1.0401 | train_acc 0.7438 | val_acc 0.6360 | lr 1.82e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.6835 | val_loss 1.0231 | train_acc 0.7494 | val_acc 0.6308 | lr 1.82e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.6608 | val_loss 1.0188 | train_acc 0.7666 | val_acc 0.6415 | lr 1.82e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.6420 | val_loss 1.0440 | train_acc 0.7737 | val_acc 0.6260 | lr 1.82e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:11:10,574] Trial 61 finished with value: 1.001068208540094 and parameters: {'lr': 0.00018167391647737997, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.6253 | val_loss 1.0080 | train_acc 0.7772 | val_acc 0.6449 | lr 1.82e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4126 | val_loss 1.1583 | train_acc 0.5054 | val_acc 0.5868 | lr 1.01e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1535 | val_loss 1.0838 | train_acc 0.5859 | val_acc 0.6064 | lr 1.01e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0763 | val_loss 1.0486 | train_acc 0.6139 | val_acc 0.6183 | lr 1.01e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0335 | val_loss 1.0289 | train_acc 0.6267 | val_acc 0.6279 | lr 1.01e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9939 | val_loss 1.0179 | train_acc 0.6393 | val_acc 0.6330 | lr 1.01e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9585 | val_loss 1.0110 | train_acc 0.6569 | val_acc 0.6349 | lr 1.01e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9309 | val_loss 1.0057 | train_acc 0.6611 | val_acc 0.6353 | lr 1.01e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9123 | val_loss 1.0020 | train_acc 0.6696 | val_acc 0.6408 | lr 1.01e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8855 | val_loss 0.9997 | train_acc 0.6775 | val_acc 0.6401 | lr 1.01e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8582 | val_loss 0.9988 | train_acc 0.6926 | val_acc 0.6445 | lr 1.01e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8389 | val_loss 0.9992 | train_acc 0.6988 | val_acc 0.6408 | lr 1.01e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8159 | val_loss 0.9913 | train_acc 0.7073 | val_acc 0.6475 | lr 1.01e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7924 | val_loss 1.0000 | train_acc 0.7106 | val_acc 0.6353 | lr 1.01e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7784 | val_loss 0.9876 | train_acc 0.7232 | val_acc 0.6471 | lr 1.01e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7558 | val_loss 1.0030 | train_acc 0.7264 | val_acc 0.6397 | lr 1.01e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7390 | val_loss 1.0067 | train_acc 0.7347 | val_acc 0.6441 | lr 1.01e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7179 | val_loss 0.9996 | train_acc 0.7449 | val_acc 0.6456 | lr 1.01e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7085 | val_loss 0.9902 | train_acc 0.7491 | val_acc 0.6511 | lr 1.01e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.6863 | val_loss 1.0045 | train_acc 0.7565 | val_acc 0.6415 | lr 1.01e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.6636 | val_loss 0.9970 | train_acc 0.7669 | val_acc 0.6460 | lr 1.01e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.6489 | val_loss 0.9937 | train_acc 0.7716 | val_acc 0.6526 | lr 1.01e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.6391 | val_loss 0.9976 | train_acc 0.7755 | val_acc 0.6497 | lr 1.01e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.6205 | val_loss 0.9971 | train_acc 0.7853 | val_acc 0.6497 | lr 1.01e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:11:38,926] Trial 62 finished with value: 0.9876444102743336 and parameters: {'lr': 0.00010125808826000366, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.6053 | val_loss 0.9994 | train_acc 0.7910 | val_acc 0.6478 | lr 1.01e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4141 | val_loss 1.1636 | train_acc 0.5037 | val_acc 0.5898 | lr 1.00e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1554 | val_loss 1.0946 | train_acc 0.5850 | val_acc 0.5990 | lr 1.00e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0823 | val_loss 1.0608 | train_acc 0.6060 | val_acc 0.6098 | lr 1.00e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0336 | val_loss 1.0356 | train_acc 0.6247 | val_acc 0.6190 | lr 1.00e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9958 | val_loss 1.0218 | train_acc 0.6386 | val_acc 0.6227 | lr 1.00e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9710 | val_loss 1.0164 | train_acc 0.6497 | val_acc 0.6212 | lr 1.00e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9391 | val_loss 1.0130 | train_acc 0.6611 | val_acc 0.6268 | lr 1.00e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9139 | val_loss 0.9990 | train_acc 0.6691 | val_acc 0.6316 | lr 1.00e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8916 | val_loss 1.0077 | train_acc 0.6761 | val_acc 0.6330 | lr 1.00e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8615 | val_loss 0.9979 | train_acc 0.6918 | val_acc 0.6345 | lr 1.00e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8483 | val_loss 0.9993 | train_acc 0.6973 | val_acc 0.6338 | lr 1.00e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8161 | val_loss 0.9961 | train_acc 0.7068 | val_acc 0.6393 | lr 1.00e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8024 | val_loss 0.9917 | train_acc 0.7125 | val_acc 0.6397 | lr 1.00e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7736 | val_loss 0.9983 | train_acc 0.7212 | val_acc 0.6401 | lr 1.00e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7615 | val_loss 0.9898 | train_acc 0.7322 | val_acc 0.6423 | lr 1.00e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7481 | val_loss 1.0009 | train_acc 0.7308 | val_acc 0.6386 | lr 1.00e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7223 | val_loss 0.9993 | train_acc 0.7432 | val_acc 0.6423 | lr 1.00e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7157 | val_loss 0.9987 | train_acc 0.7473 | val_acc 0.6393 | lr 1.00e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.6931 | val_loss 0.9941 | train_acc 0.7542 | val_acc 0.6456 | lr 1.00e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.6774 | val_loss 0.9971 | train_acc 0.7578 | val_acc 0.6438 | lr 1.00e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.6553 | val_loss 1.0006 | train_acc 0.7705 | val_acc 0.6445 | lr 1.00e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.6453 | val_loss 1.0124 | train_acc 0.7711 | val_acc 0.6438 | lr 1.00e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.6260 | val_loss 0.9986 | train_acc 0.7821 | val_acc 0.6438 | lr 1.00e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.6120 | val_loss 1.0050 | train_acc 0.7862 | val_acc 0.6471 | lr 1.00e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:12:08,590] Trial 63 finished with value: 0.9898494467943224 and parameters: {'lr': 0.0001000525070533818, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.5971 | val_loss 1.0276 | train_acc 0.7899 | val_acc 0.6397 | lr 1.00e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3565 | val_loss 1.1262 | train_acc 0.5229 | val_acc 0.5946 | lr 1.35e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1236 | val_loss 1.0680 | train_acc 0.5978 | val_acc 0.6090 | lr 1.35e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0551 | val_loss 1.0418 | train_acc 0.6175 | val_acc 0.6201 | lr 1.35e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0016 | val_loss 1.0235 | train_acc 0.6398 | val_acc 0.6194 | lr 1.35e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9601 | val_loss 1.0188 | train_acc 0.6510 | val_acc 0.6286 | lr 1.35e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9322 | val_loss 1.0032 | train_acc 0.6664 | val_acc 0.6297 | lr 1.35e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.8983 | val_loss 1.0011 | train_acc 0.6788 | val_acc 0.6430 | lr 1.35e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8732 | val_loss 0.9895 | train_acc 0.6802 | val_acc 0.6486 | lr 1.35e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8437 | val_loss 1.0013 | train_acc 0.6924 | val_acc 0.6338 | lr 1.35e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8201 | val_loss 0.9991 | train_acc 0.7041 | val_acc 0.6463 | lr 1.35e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.7935 | val_loss 0.9924 | train_acc 0.7119 | val_acc 0.6449 | lr 1.35e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.7688 | val_loss 0.9920 | train_acc 0.7270 | val_acc 0.6452 | lr 1.35e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7488 | val_loss 0.9897 | train_acc 0.7321 | val_acc 0.6508 | lr 1.35e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7233 | val_loss 1.0167 | train_acc 0.7424 | val_acc 0.6327 | lr 1.35e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7057 | val_loss 0.9960 | train_acc 0.7492 | val_acc 0.6471 | lr 1.35e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.6846 | val_loss 0.9986 | train_acc 0.7616 | val_acc 0.6456 | lr 1.35e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.6645 | val_loss 1.0035 | train_acc 0.7619 | val_acc 0.6467 | lr 1.35e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:12:29,964] Trial 64 finished with value: 0.9894583348600581 and parameters: {'lr': 0.0001352117525183498, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.6407 | val_loss 1.0020 | train_acc 0.7701 | val_acc 0.6511 | lr 1.35e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2917 | val_loss 1.1098 | train_acc 0.5380 | val_acc 0.5883 | lr 2.35e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.0789 | val_loss 1.0537 | train_acc 0.6084 | val_acc 0.6105 | lr 2.35e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0112 | val_loss 1.0301 | train_acc 0.6332 | val_acc 0.6205 | lr 2.34e-04 | 1.2s\n",
      "epoch 004 | train_loss 0.9728 | val_loss 1.0064 | train_acc 0.6433 | val_acc 0.6338 | lr 2.34e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9216 | val_loss 1.0127 | train_acc 0.6613 | val_acc 0.6293 | lr 2.33e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.8788 | val_loss 1.0105 | train_acc 0.6810 | val_acc 0.6223 | lr 2.33e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.8456 | val_loss 0.9935 | train_acc 0.6957 | val_acc 0.6386 | lr 2.32e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.8126 | val_loss 1.0062 | train_acc 0.7042 | val_acc 0.6316 | lr 2.31e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.7856 | val_loss 1.0058 | train_acc 0.7173 | val_acc 0.6397 | lr 2.30e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.7632 | val_loss 1.0001 | train_acc 0.7242 | val_acc 0.6386 | lr 2.29e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.7248 | val_loss 1.0090 | train_acc 0.7356 | val_acc 0.6426 | lr 2.28e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.7034 | val_loss 1.0015 | train_acc 0.7454 | val_acc 0.6426 | lr 2.27e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.6667 | val_loss 1.0509 | train_acc 0.7631 | val_acc 0.6323 | lr 2.25e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.6567 | val_loss 1.0265 | train_acc 0.7644 | val_acc 0.6345 | lr 2.24e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.6264 | val_loss 1.0343 | train_acc 0.7741 | val_acc 0.6423 | lr 2.22e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.6028 | val_loss 1.0317 | train_acc 0.7862 | val_acc 0.6412 | lr 2.20e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:12:50,042] Trial 65 finished with value: 0.9935342554506864 and parameters: {'lr': 0.00023491587941897737, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': True}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.5918 | val_loss 1.0275 | train_acc 0.7890 | val_acc 0.6378 | lr 2.19e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.2560 | val_loss 1.1522 | train_acc 0.5491 | val_acc 0.5713 | lr 1.58e-03 | 1.2s\n",
      "epoch 002 | train_loss 1.1106 | val_loss 1.0698 | train_acc 0.5936 | val_acc 0.6061 | lr 1.58e-03 | 1.2s\n",
      "epoch 003 | train_loss 1.0549 | val_loss 1.0598 | train_acc 0.6130 | val_acc 0.6064 | lr 1.58e-03 | 1.2s\n",
      "epoch 004 | train_loss 0.9944 | val_loss 1.1153 | train_acc 0.6354 | val_acc 0.6016 | lr 1.58e-03 | 1.2s\n",
      "epoch 005 | train_loss 0.9554 | val_loss 1.0521 | train_acc 0.6482 | val_acc 0.6249 | lr 1.58e-03 | 1.2s\n",
      "epoch 006 | train_loss 0.9127 | val_loss 1.0537 | train_acc 0.6616 | val_acc 0.6175 | lr 1.58e-03 | 1.2s\n",
      "epoch 007 | train_loss 0.8737 | val_loss 1.0356 | train_acc 0.6746 | val_acc 0.6234 | lr 1.58e-03 | 1.2s\n",
      "epoch 008 | train_loss 0.8434 | val_loss 1.0611 | train_acc 0.6837 | val_acc 0.6293 | lr 1.58e-03 | 1.2s\n",
      "epoch 009 | train_loss 0.8138 | val_loss 1.0419 | train_acc 0.6959 | val_acc 0.6319 | lr 1.58e-03 | 1.2s\n",
      "epoch 010 | train_loss 0.7850 | val_loss 1.0548 | train_acc 0.7104 | val_acc 0.6242 | lr 1.58e-03 | 1.2s\n",
      "epoch 011 | train_loss 0.7556 | val_loss 1.0784 | train_acc 0.7194 | val_acc 0.6179 | lr 1.58e-03 | 1.2s\n",
      "epoch 012 | train_loss 0.7284 | val_loss 1.1006 | train_acc 0.7336 | val_acc 0.6249 | lr 1.58e-03 | 1.2s\n",
      "epoch 013 | train_loss 0.7033 | val_loss 1.1166 | train_acc 0.7385 | val_acc 0.6286 | lr 1.58e-03 | 1.2s\n",
      "epoch 014 | train_loss 0.6778 | val_loss 1.1232 | train_acc 0.7463 | val_acc 0.6268 | lr 1.58e-03 | 1.2s\n",
      "epoch 015 | train_loss 0.6555 | val_loss 1.1099 | train_acc 0.7537 | val_acc 0.6234 | lr 1.58e-03 | 1.2s\n",
      "epoch 016 | train_loss 0.6359 | val_loss 1.1206 | train_acc 0.7648 | val_acc 0.6308 | lr 1.58e-03 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:13:10,218] Trial 66 finished with value: 1.0355842635090582 and parameters: {'lr': 0.0015796985576616621, 'num_layers': 1, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 017 | train_loss 0.6168 | val_loss 1.1213 | train_acc 0.7720 | val_acc 0.6242 | lr 1.58e-03 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3597 | val_loss 1.3998 | train_acc 0.5185 | val_acc 0.5307 | lr 3.09e-03 | 1.7s\n",
      "epoch 002 | train_loss 1.1841 | val_loss 1.1196 | train_acc 0.5737 | val_acc 0.5894 | lr 3.09e-03 | 1.6s\n",
      "epoch 003 | train_loss 1.1160 | val_loss 1.0709 | train_acc 0.5925 | val_acc 0.6186 | lr 3.09e-03 | 1.6s\n",
      "epoch 004 | train_loss 1.0733 | val_loss 1.0805 | train_acc 0.6048 | val_acc 0.5957 | lr 3.09e-03 | 1.6s\n",
      "epoch 005 | train_loss 1.0573 | val_loss 1.0573 | train_acc 0.6116 | val_acc 0.6061 | lr 3.09e-03 | 1.6s\n",
      "epoch 006 | train_loss 1.0204 | val_loss 1.0639 | train_acc 0.6227 | val_acc 0.6109 | lr 3.09e-03 | 1.6s\n",
      "epoch 007 | train_loss 0.9947 | val_loss 1.1175 | train_acc 0.6366 | val_acc 0.5939 | lr 3.09e-03 | 1.6s\n",
      "epoch 008 | train_loss 0.9838 | val_loss 1.0733 | train_acc 0.6365 | val_acc 0.6083 | lr 3.09e-03 | 1.6s\n",
      "epoch 009 | train_loss 0.9726 | val_loss 1.0752 | train_acc 0.6358 | val_acc 0.6042 | lr 3.09e-03 | 1.6s\n",
      "epoch 010 | train_loss 0.9575 | val_loss 1.1113 | train_acc 0.6429 | val_acc 0.6031 | lr 3.09e-03 | 1.6s\n",
      "epoch 011 | train_loss 0.9390 | val_loss 1.0614 | train_acc 0.6522 | val_acc 0.6234 | lr 3.09e-03 | 1.6s\n",
      "epoch 012 | train_loss 0.9269 | val_loss 1.0649 | train_acc 0.6555 | val_acc 0.6175 | lr 3.09e-03 | 1.6s\n",
      "epoch 013 | train_loss 0.9261 | val_loss 1.0393 | train_acc 0.6585 | val_acc 0.6242 | lr 3.09e-03 | 1.6s\n",
      "epoch 014 | train_loss 0.9121 | val_loss 1.0446 | train_acc 0.6626 | val_acc 0.6105 | lr 3.09e-03 | 1.6s\n",
      "epoch 015 | train_loss 0.8787 | val_loss 1.0758 | train_acc 0.6695 | val_acc 0.6086 | lr 3.09e-03 | 1.6s\n",
      "epoch 016 | train_loss 0.8753 | val_loss 1.0577 | train_acc 0.6773 | val_acc 0.6220 | lr 3.09e-03 | 1.6s\n",
      "epoch 017 | train_loss 0.8686 | val_loss 1.0654 | train_acc 0.6790 | val_acc 0.6201 | lr 3.09e-03 | 1.6s\n",
      "epoch 018 | train_loss 0.8433 | val_loss 1.0905 | train_acc 0.6840 | val_acc 0.6072 | lr 3.09e-03 | 1.6s\n",
      "epoch 019 | train_loss 0.8551 | val_loss 1.0610 | train_acc 0.6797 | val_acc 0.6153 | lr 3.09e-03 | 1.6s\n",
      "epoch 020 | train_loss 0.8330 | val_loss 1.0678 | train_acc 0.6907 | val_acc 0.6231 | lr 3.09e-03 | 1.6s\n",
      "epoch 021 | train_loss 0.8260 | val_loss 1.1460 | train_acc 0.6948 | val_acc 0.6064 | lr 3.09e-03 | 1.6s\n",
      "epoch 022 | train_loss 0.8149 | val_loss 1.0831 | train_acc 0.6976 | val_acc 0.6175 | lr 3.09e-03 | 1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:13:47,624] Trial 67 finished with value: 1.0392517902546252 and parameters: {'lr': 0.003090340978238463, 'num_layers': 2, 'hidden_width': 768, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.8111 | val_loss 1.0846 | train_acc 0.6987 | val_acc 0.6260 | lr 3.09e-03 | 1.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.9287 | val_loss 1.7557 | train_acc 0.3563 | val_acc 0.4856 | lr 1.49e-04 | 1.0s\n",
      "epoch 002 | train_loss 1.5423 | val_loss 1.4175 | train_acc 0.4817 | val_acc 0.5458 | lr 1.49e-04 | 1.0s\n",
      "epoch 003 | train_loss 1.3987 | val_loss 1.2797 | train_acc 0.5255 | val_acc 0.5684 | lr 1.49e-04 | 1.0s\n",
      "epoch 004 | train_loss 1.3242 | val_loss 1.2172 | train_acc 0.5459 | val_acc 0.5817 | lr 1.49e-04 | 1.0s\n",
      "epoch 005 | train_loss 1.2628 | val_loss 1.1675 | train_acc 0.5587 | val_acc 0.5939 | lr 1.48e-04 | 1.0s\n",
      "epoch 006 | train_loss 1.2292 | val_loss 1.1370 | train_acc 0.5689 | val_acc 0.5998 | lr 1.48e-04 | 1.0s\n",
      "epoch 007 | train_loss 1.2057 | val_loss 1.1273 | train_acc 0.5782 | val_acc 0.5979 | lr 1.47e-04 | 1.0s\n",
      "epoch 008 | train_loss 1.1871 | val_loss 1.1029 | train_acc 0.5861 | val_acc 0.6050 | lr 1.47e-04 | 1.0s\n",
      "epoch 009 | train_loss 1.1567 | val_loss 1.0855 | train_acc 0.5903 | val_acc 0.6105 | lr 1.46e-04 | 1.0s\n",
      "epoch 010 | train_loss 1.1400 | val_loss 1.0726 | train_acc 0.5983 | val_acc 0.6183 | lr 1.45e-04 | 1.0s\n",
      "epoch 011 | train_loss 1.1203 | val_loss 1.0702 | train_acc 0.6033 | val_acc 0.6112 | lr 1.45e-04 | 1.0s\n",
      "epoch 012 | train_loss 1.1070 | val_loss 1.0545 | train_acc 0.6035 | val_acc 0.6208 | lr 1.44e-04 | 1.0s\n",
      "epoch 013 | train_loss 1.0951 | val_loss 1.0529 | train_acc 0.6112 | val_acc 0.6268 | lr 1.43e-04 | 1.0s\n",
      "epoch 014 | train_loss 1.0781 | val_loss 1.0485 | train_acc 0.6134 | val_acc 0.6264 | lr 1.42e-04 | 1.0s\n",
      "epoch 015 | train_loss 1.0711 | val_loss 1.0372 | train_acc 0.6181 | val_acc 0.6264 | lr 1.41e-04 | 1.0s\n",
      "epoch 016 | train_loss 1.0451 | val_loss 1.0335 | train_acc 0.6289 | val_acc 0.6275 | lr 1.40e-04 | 1.0s\n",
      "epoch 017 | train_loss 1.0513 | val_loss 1.0313 | train_acc 0.6220 | val_acc 0.6319 | lr 1.39e-04 | 1.0s\n",
      "epoch 018 | train_loss 1.0417 | val_loss 1.0252 | train_acc 0.6284 | val_acc 0.6338 | lr 1.38e-04 | 1.0s\n",
      "epoch 019 | train_loss 1.0257 | val_loss 1.0233 | train_acc 0.6306 | val_acc 0.6312 | lr 1.36e-04 | 1.0s\n",
      "epoch 020 | train_loss 1.0219 | val_loss 1.0277 | train_acc 0.6383 | val_acc 0.6305 | lr 1.35e-04 | 1.0s\n",
      "epoch 021 | train_loss 1.0032 | val_loss 1.0140 | train_acc 0.6425 | val_acc 0.6323 | lr 1.33e-04 | 1.0s\n",
      "epoch 022 | train_loss 0.9985 | val_loss 1.0161 | train_acc 0.6416 | val_acc 0.6305 | lr 1.32e-04 | 1.0s\n",
      "epoch 023 | train_loss 0.9933 | val_loss 1.0149 | train_acc 0.6442 | val_acc 0.6401 | lr 1.30e-04 | 1.0s\n",
      "epoch 024 | train_loss 0.9925 | val_loss 1.0156 | train_acc 0.6403 | val_acc 0.6305 | lr 1.29e-04 | 1.0s\n",
      "epoch 025 | train_loss 0.9681 | val_loss 1.0131 | train_acc 0.6491 | val_acc 0.6356 | lr 1.27e-04 | 1.0s\n",
      "epoch 026 | train_loss 0.9731 | val_loss 1.0167 | train_acc 0.6515 | val_acc 0.6308 | lr 1.26e-04 | 1.0s\n",
      "epoch 027 | train_loss 0.9633 | val_loss 1.0155 | train_acc 0.6529 | val_acc 0.6323 | lr 1.24e-04 | 1.0s\n",
      "epoch 028 | train_loss 0.9607 | val_loss 1.0154 | train_acc 0.6578 | val_acc 0.6308 | lr 1.22e-04 | 1.0s\n",
      "epoch 029 | train_loss 0.9486 | val_loss 1.0173 | train_acc 0.6617 | val_acc 0.6312 | lr 1.20e-04 | 1.0s\n",
      "epoch 030 | train_loss 0.9496 | val_loss 1.0051 | train_acc 0.6583 | val_acc 0.6367 | lr 1.18e-04 | 1.0s\n",
      "epoch 031 | train_loss 0.9325 | val_loss 1.0109 | train_acc 0.6657 | val_acc 0.6386 | lr 1.16e-04 | 1.0s\n",
      "epoch 032 | train_loss 0.9313 | val_loss 1.0093 | train_acc 0.6683 | val_acc 0.6378 | lr 1.15e-04 | 1.0s\n",
      "epoch 033 | train_loss 0.9297 | val_loss 1.0084 | train_acc 0.6705 | val_acc 0.6367 | lr 1.13e-04 | 1.0s\n",
      "epoch 034 | train_loss 0.9178 | val_loss 1.0073 | train_acc 0.6662 | val_acc 0.6371 | lr 1.10e-04 | 1.0s\n",
      "epoch 035 | train_loss 0.9098 | val_loss 1.0099 | train_acc 0.6734 | val_acc 0.6338 | lr 1.08e-04 | 1.0s\n",
      "epoch 036 | train_loss 0.9081 | val_loss 1.0118 | train_acc 0.6737 | val_acc 0.6341 | lr 1.06e-04 | 1.0s\n",
      "epoch 037 | train_loss 0.9148 | val_loss 1.0068 | train_acc 0.6724 | val_acc 0.6401 | lr 1.04e-04 | 1.0s\n",
      "epoch 038 | train_loss 0.8967 | val_loss 1.0091 | train_acc 0.6839 | val_acc 0.6390 | lr 1.02e-04 | 1.0s\n",
      "epoch 039 | train_loss 0.8824 | val_loss 1.0046 | train_acc 0.6813 | val_acc 0.6378 | lr 9.98e-05 | 1.0s\n",
      "epoch 040 | train_loss 0.8745 | val_loss 1.0099 | train_acc 0.6853 | val_acc 0.6390 | lr 9.76e-05 | 1.0s\n",
      "epoch 041 | train_loss 0.8783 | val_loss 1.0076 | train_acc 0.6780 | val_acc 0.6415 | lr 9.54e-05 | 1.0s\n",
      "epoch 042 | train_loss 0.8694 | val_loss 1.0088 | train_acc 0.6859 | val_acc 0.6378 | lr 9.31e-05 | 1.0s\n",
      "epoch 043 | train_loss 0.8691 | val_loss 1.0101 | train_acc 0.6867 | val_acc 0.6378 | lr 9.08e-05 | 1.0s\n",
      "epoch 044 | train_loss 0.8598 | val_loss 1.0121 | train_acc 0.6919 | val_acc 0.6438 | lr 8.85e-05 | 1.0s\n",
      "epoch 045 | train_loss 0.8573 | val_loss 1.0131 | train_acc 0.6905 | val_acc 0.6408 | lr 8.62e-05 | 1.0s\n",
      "epoch 046 | train_loss 0.8513 | val_loss 1.0165 | train_acc 0.6959 | val_acc 0.6390 | lr 8.39e-05 | 1.0s\n",
      "epoch 047 | train_loss 0.8420 | val_loss 1.0164 | train_acc 0.6964 | val_acc 0.6423 | lr 8.16e-05 | 1.0s\n",
      "epoch 048 | train_loss 0.8455 | val_loss 1.0177 | train_acc 0.6985 | val_acc 0.6356 | lr 7.92e-05 | 1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:14:36,763] Trial 68 finished with value: 1.004637929746511 and parameters: {'lr': 0.0001491124780682831, 'num_layers': 3, 'hidden_width': 128, 'batch_size': 64, 'use_scheduler': True}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 049 | train_loss 0.8428 | val_loss 1.0159 | train_acc 0.6964 | val_acc 0.6356 | lr 7.69e-05 | 1.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3922 | val_loss 1.1410 | train_acc 0.5145 | val_acc 0.5861 | lr 1.93e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1372 | val_loss 1.0752 | train_acc 0.5947 | val_acc 0.6075 | lr 1.93e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.0635 | val_loss 1.0480 | train_acc 0.6171 | val_acc 0.6135 | lr 1.93e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0189 | val_loss 1.0224 | train_acc 0.6333 | val_acc 0.6279 | lr 1.93e-04 | 1.2s\n",
      "epoch 005 | train_loss 0.9852 | val_loss 1.0195 | train_acc 0.6485 | val_acc 0.6286 | lr 1.93e-04 | 1.2s\n",
      "epoch 006 | train_loss 0.9565 | val_loss 1.0151 | train_acc 0.6519 | val_acc 0.6327 | lr 1.93e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9262 | val_loss 1.0056 | train_acc 0.6658 | val_acc 0.6323 | lr 1.93e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9061 | val_loss 1.0071 | train_acc 0.6699 | val_acc 0.6371 | lr 1.93e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.8853 | val_loss 0.9967 | train_acc 0.6798 | val_acc 0.6452 | lr 1.93e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.8510 | val_loss 1.0074 | train_acc 0.6934 | val_acc 0.6330 | lr 1.93e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.8337 | val_loss 0.9885 | train_acc 0.6928 | val_acc 0.6408 | lr 1.93e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8160 | val_loss 1.0047 | train_acc 0.7066 | val_acc 0.6441 | lr 1.93e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.7936 | val_loss 0.9949 | train_acc 0.7159 | val_acc 0.6441 | lr 1.93e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.7818 | val_loss 0.9940 | train_acc 0.7144 | val_acc 0.6397 | lr 1.93e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.7573 | val_loss 1.0109 | train_acc 0.7266 | val_acc 0.6390 | lr 1.93e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.7414 | val_loss 1.0106 | train_acc 0.7325 | val_acc 0.6390 | lr 1.93e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.7266 | val_loss 0.9987 | train_acc 0.7374 | val_acc 0.6408 | lr 1.93e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7092 | val_loss 1.0093 | train_acc 0.7454 | val_acc 0.6323 | lr 1.93e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.6881 | val_loss 1.0075 | train_acc 0.7522 | val_acc 0.6426 | lr 1.93e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.6680 | val_loss 1.0215 | train_acc 0.7594 | val_acc 0.6345 | lr 1.93e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:15:01,683] Trial 69 finished with value: 0.9884855875859679 and parameters: {'lr': 0.00019314344453290197, 'num_layers': 1, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 021 | train_loss 0.6541 | val_loss 1.0283 | train_acc 0.7660 | val_acc 0.6456 | lr 1.93e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3497 | val_loss 1.1352 | train_acc 0.5268 | val_acc 0.5913 | lr 3.33e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.1500 | val_loss 1.0808 | train_acc 0.5871 | val_acc 0.6031 | lr 3.32e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.0790 | val_loss 1.0532 | train_acc 0.6076 | val_acc 0.6149 | lr 3.32e-04 | 2.0s\n",
      "epoch 004 | train_loss 1.0386 | val_loss 1.0400 | train_acc 0.6240 | val_acc 0.6171 | lr 3.31e-04 | 2.0s\n",
      "epoch 005 | train_loss 1.0031 | val_loss 1.0136 | train_acc 0.6298 | val_acc 0.6238 | lr 3.31e-04 | 2.1s\n",
      "epoch 006 | train_loss 0.9546 | val_loss 1.0090 | train_acc 0.6498 | val_acc 0.6264 | lr 3.30e-04 | 2.0s\n",
      "epoch 007 | train_loss 0.9292 | val_loss 1.0055 | train_acc 0.6586 | val_acc 0.6305 | lr 3.29e-04 | 2.1s\n",
      "epoch 008 | train_loss 0.8944 | val_loss 1.0256 | train_acc 0.6676 | val_acc 0.6275 | lr 3.27e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.8670 | val_loss 1.0044 | train_acc 0.6768 | val_acc 0.6275 | lr 3.26e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.8461 | val_loss 1.0258 | train_acc 0.6859 | val_acc 0.6253 | lr 3.25e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.8220 | val_loss 1.0177 | train_acc 0.6951 | val_acc 0.6282 | lr 3.23e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.7969 | val_loss 1.0129 | train_acc 0.7019 | val_acc 0.6338 | lr 3.21e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.7759 | val_loss 1.0459 | train_acc 0.7058 | val_acc 0.6260 | lr 3.19e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.7398 | val_loss 1.0403 | train_acc 0.7216 | val_acc 0.6316 | lr 3.17e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.7266 | val_loss 1.0486 | train_acc 0.7293 | val_acc 0.6301 | lr 3.15e-04 | 2.0s\n",
      "epoch 016 | train_loss 0.6962 | val_loss 1.0591 | train_acc 0.7424 | val_acc 0.6308 | lr 3.12e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.6723 | val_loss 1.0871 | train_acc 0.7521 | val_acc 0.6305 | lr 3.10e-04 | 2.1s\n",
      "epoch 018 | train_loss 0.6558 | val_loss 1.0625 | train_acc 0.7579 | val_acc 0.6404 | lr 3.07e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:15:40,746] Trial 70 finished with value: 1.0044071258480074 and parameters: {'lr': 0.00033269739235273447, 'num_layers': 3, 'hidden_width': 512, 'batch_size': 32, 'use_scheduler': True}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 019 | train_loss 0.6355 | val_loss 1.0987 | train_acc 0.7624 | val_acc 0.6327 | lr 3.04e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5299 | val_loss 1.2404 | train_acc 0.4781 | val_acc 0.5469 | lr 1.18e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2315 | val_loss 1.1479 | train_acc 0.5640 | val_acc 0.5920 | lr 1.18e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1516 | val_loss 1.0974 | train_acc 0.5874 | val_acc 0.6057 | lr 1.18e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.1042 | val_loss 1.0706 | train_acc 0.6005 | val_acc 0.6090 | lr 1.18e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0716 | val_loss 1.0529 | train_acc 0.6137 | val_acc 0.6160 | lr 1.18e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0401 | val_loss 1.0384 | train_acc 0.6288 | val_acc 0.6194 | lr 1.18e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0129 | val_loss 1.0249 | train_acc 0.6375 | val_acc 0.6305 | lr 1.18e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9944 | val_loss 1.0194 | train_acc 0.6378 | val_acc 0.6330 | lr 1.18e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9720 | val_loss 1.0146 | train_acc 0.6505 | val_acc 0.6330 | lr 1.18e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9539 | val_loss 1.0107 | train_acc 0.6545 | val_acc 0.6408 | lr 1.18e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9407 | val_loss 1.0051 | train_acc 0.6616 | val_acc 0.6349 | lr 1.18e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9181 | val_loss 1.0001 | train_acc 0.6693 | val_acc 0.6438 | lr 1.18e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9032 | val_loss 1.0011 | train_acc 0.6709 | val_acc 0.6334 | lr 1.18e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8918 | val_loss 0.9981 | train_acc 0.6805 | val_acc 0.6375 | lr 1.18e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8757 | val_loss 0.9932 | train_acc 0.6855 | val_acc 0.6452 | lr 1.18e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8658 | val_loss 0.9889 | train_acc 0.6862 | val_acc 0.6493 | lr 1.18e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8494 | val_loss 0.9960 | train_acc 0.6961 | val_acc 0.6423 | lr 1.18e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8385 | val_loss 0.9965 | train_acc 0.6955 | val_acc 0.6378 | lr 1.18e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8312 | val_loss 0.9912 | train_acc 0.6948 | val_acc 0.6460 | lr 1.18e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8120 | val_loss 0.9954 | train_acc 0.7034 | val_acc 0.6390 | lr 1.18e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7982 | val_loss 0.9939 | train_acc 0.7128 | val_acc 0.6467 | lr 1.18e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7873 | val_loss 0.9941 | train_acc 0.7133 | val_acc 0.6504 | lr 1.18e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7787 | val_loss 0.9961 | train_acc 0.7186 | val_acc 0.6467 | lr 1.18e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7660 | val_loss 0.9972 | train_acc 0.7268 | val_acc 0.6493 | lr 1.18e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7554 | val_loss 1.0001 | train_acc 0.7277 | val_acc 0.6463 | lr 1.18e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:16:11,070] Trial 71 finished with value: 0.9889432280837211 and parameters: {'lr': 0.0001182847677891521, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 42 with value: 0.9824916641534212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 026 | train_loss 0.7468 | val_loss 0.9993 | train_acc 0.7296 | val_acc 0.6445 | lr 1.18e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5383 | val_loss 1.2380 | train_acc 0.4801 | val_acc 0.5669 | lr 1.14e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2422 | val_loss 1.1409 | train_acc 0.5629 | val_acc 0.5972 | lr 1.14e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1586 | val_loss 1.0950 | train_acc 0.5916 | val_acc 0.6024 | lr 1.14e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.1092 | val_loss 1.0702 | train_acc 0.5976 | val_acc 0.6064 | lr 1.14e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0701 | val_loss 1.0497 | train_acc 0.6202 | val_acc 0.6197 | lr 1.14e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0517 | val_loss 1.0360 | train_acc 0.6240 | val_acc 0.6242 | lr 1.14e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0249 | val_loss 1.0262 | train_acc 0.6327 | val_acc 0.6327 | lr 1.14e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9981 | val_loss 1.0197 | train_acc 0.6402 | val_acc 0.6279 | lr 1.14e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9788 | val_loss 1.0142 | train_acc 0.6427 | val_acc 0.6338 | lr 1.14e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9602 | val_loss 1.0029 | train_acc 0.6499 | val_acc 0.6367 | lr 1.14e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9419 | val_loss 1.0024 | train_acc 0.6599 | val_acc 0.6341 | lr 1.14e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9288 | val_loss 0.9964 | train_acc 0.6581 | val_acc 0.6386 | lr 1.14e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9169 | val_loss 0.9985 | train_acc 0.6679 | val_acc 0.6345 | lr 1.14e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8978 | val_loss 0.9887 | train_acc 0.6754 | val_acc 0.6341 | lr 1.14e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8911 | val_loss 0.9985 | train_acc 0.6766 | val_acc 0.6360 | lr 1.14e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8639 | val_loss 0.9923 | train_acc 0.6876 | val_acc 0.6367 | lr 1.14e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8611 | val_loss 0.9898 | train_acc 0.6900 | val_acc 0.6401 | lr 1.14e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8417 | val_loss 0.9905 | train_acc 0.6979 | val_acc 0.6397 | lr 1.14e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8318 | val_loss 0.9824 | train_acc 0.6998 | val_acc 0.6456 | lr 1.14e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8129 | val_loss 0.9940 | train_acc 0.7072 | val_acc 0.6341 | lr 1.14e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8118 | val_loss 0.9903 | train_acc 0.7050 | val_acc 0.6371 | lr 1.14e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.8037 | val_loss 0.9840 | train_acc 0.7020 | val_acc 0.6452 | lr 1.14e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7869 | val_loss 0.9912 | train_acc 0.7132 | val_acc 0.6390 | lr 1.14e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7741 | val_loss 0.9921 | train_acc 0.7229 | val_acc 0.6415 | lr 1.14e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7679 | val_loss 0.9945 | train_acc 0.7202 | val_acc 0.6375 | lr 1.14e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7620 | val_loss 0.9877 | train_acc 0.7229 | val_acc 0.6404 | lr 1.14e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7524 | val_loss 0.9853 | train_acc 0.7322 | val_acc 0.6404 | lr 1.14e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7431 | val_loss 0.9902 | train_acc 0.7272 | val_acc 0.6415 | lr 1.14e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:16:44,927] Trial 72 finished with value: 0.9823930212417005 and parameters: {'lr': 0.00011382147703182521, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 72 with value: 0.9823930212417005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7281 | val_loss 0.9912 | train_acc 0.7388 | val_acc 0.6404 | lr 1.14e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5315 | val_loss 1.2421 | train_acc 0.4840 | val_acc 0.5639 | lr 1.11e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.2387 | val_loss 1.1481 | train_acc 0.5661 | val_acc 0.5909 | lr 1.11e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1557 | val_loss 1.1002 | train_acc 0.5881 | val_acc 0.6035 | lr 1.11e-04 | 0.8s\n",
      "epoch 004 | train_loss 1.1057 | val_loss 1.0739 | train_acc 0.6060 | val_acc 0.6131 | lr 1.11e-04 | 1.0s\n",
      "epoch 005 | train_loss 1.0746 | val_loss 1.0554 | train_acc 0.6149 | val_acc 0.6171 | lr 1.11e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0452 | val_loss 1.0443 | train_acc 0.6260 | val_acc 0.6208 | lr 1.11e-04 | 1.2s\n",
      "epoch 007 | train_loss 1.0224 | val_loss 1.0325 | train_acc 0.6270 | val_acc 0.6249 | lr 1.11e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9982 | val_loss 1.0294 | train_acc 0.6381 | val_acc 0.6216 | lr 1.11e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9842 | val_loss 1.0180 | train_acc 0.6468 | val_acc 0.6353 | lr 1.11e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9627 | val_loss 1.0153 | train_acc 0.6506 | val_acc 0.6356 | lr 1.11e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9463 | val_loss 1.0078 | train_acc 0.6593 | val_acc 0.6404 | lr 1.11e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.9276 | val_loss 1.0043 | train_acc 0.6629 | val_acc 0.6360 | lr 1.11e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.9153 | val_loss 1.0019 | train_acc 0.6660 | val_acc 0.6390 | lr 1.11e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.9044 | val_loss 1.0074 | train_acc 0.6681 | val_acc 0.6364 | lr 1.11e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8886 | val_loss 0.9974 | train_acc 0.6759 | val_acc 0.6393 | lr 1.11e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8722 | val_loss 1.0042 | train_acc 0.6867 | val_acc 0.6338 | lr 1.11e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8592 | val_loss 0.9948 | train_acc 0.6919 | val_acc 0.6404 | lr 1.11e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.8433 | val_loss 0.9902 | train_acc 0.6932 | val_acc 0.6401 | lr 1.11e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.8357 | val_loss 1.0112 | train_acc 0.7012 | val_acc 0.6305 | lr 1.11e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.8118 | val_loss 0.9914 | train_acc 0.7089 | val_acc 0.6415 | lr 1.11e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.8103 | val_loss 0.9907 | train_acc 0.7046 | val_acc 0.6434 | lr 1.11e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7958 | val_loss 0.9898 | train_acc 0.7131 | val_acc 0.6408 | lr 1.11e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7846 | val_loss 0.9961 | train_acc 0.7221 | val_acc 0.6367 | lr 1.11e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7831 | val_loss 0.9958 | train_acc 0.7205 | val_acc 0.6426 | lr 1.11e-04 | 1.2s\n",
      "epoch 025 | train_loss 0.7742 | val_loss 0.9917 | train_acc 0.7175 | val_acc 0.6456 | lr 1.11e-04 | 1.2s\n",
      "epoch 026 | train_loss 0.7590 | val_loss 0.9972 | train_acc 0.7273 | val_acc 0.6438 | lr 1.11e-04 | 1.2s\n",
      "epoch 027 | train_loss 0.7520 | val_loss 0.9979 | train_acc 0.7287 | val_acc 0.6349 | lr 1.11e-04 | 1.2s\n",
      "epoch 028 | train_loss 0.7390 | val_loss 1.0029 | train_acc 0.7333 | val_acc 0.6367 | lr 1.11e-04 | 1.2s\n",
      "epoch 029 | train_loss 0.7274 | val_loss 0.9964 | train_acc 0.7408 | val_acc 0.6349 | lr 1.11e-04 | 1.2s\n",
      "epoch 030 | train_loss 0.7192 | val_loss 0.9960 | train_acc 0.7442 | val_acc 0.6438 | lr 1.11e-04 | 1.2s\n",
      "epoch 031 | train_loss 0.7033 | val_loss 0.9942 | train_acc 0.7463 | val_acc 0.6426 | lr 1.11e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:17:21,861] Trial 73 finished with value: 0.9898472843748151 and parameters: {'lr': 0.00011137526198031153, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 72 with value: 0.9823930212417005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 032 | train_loss 0.7019 | val_loss 1.0129 | train_acc 0.7485 | val_acc 0.6382 | lr 1.11e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4592 | val_loss 1.1978 | train_acc 0.4955 | val_acc 0.5702 | lr 1.64e-04 | 1.2s\n",
      "epoch 002 | train_loss 1.1901 | val_loss 1.1068 | train_acc 0.5755 | val_acc 0.6072 | lr 1.64e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1194 | val_loss 1.0728 | train_acc 0.5977 | val_acc 0.6086 | lr 1.64e-04 | 1.2s\n",
      "epoch 004 | train_loss 1.0729 | val_loss 1.0495 | train_acc 0.6129 | val_acc 0.6223 | lr 1.64e-04 | 1.2s\n",
      "epoch 005 | train_loss 1.0416 | val_loss 1.0371 | train_acc 0.6257 | val_acc 0.6249 | lr 1.64e-04 | 1.2s\n",
      "epoch 006 | train_loss 1.0100 | val_loss 1.0245 | train_acc 0.6341 | val_acc 0.6308 | lr 1.64e-04 | 1.2s\n",
      "epoch 007 | train_loss 0.9827 | val_loss 1.0158 | train_acc 0.6425 | val_acc 0.6382 | lr 1.64e-04 | 1.2s\n",
      "epoch 008 | train_loss 0.9591 | val_loss 1.0084 | train_acc 0.6533 | val_acc 0.6382 | lr 1.64e-04 | 1.2s\n",
      "epoch 009 | train_loss 0.9442 | val_loss 1.0065 | train_acc 0.6593 | val_acc 0.6364 | lr 1.64e-04 | 1.2s\n",
      "epoch 010 | train_loss 0.9160 | val_loss 1.0080 | train_acc 0.6674 | val_acc 0.6367 | lr 1.64e-04 | 1.2s\n",
      "epoch 011 | train_loss 0.9072 | val_loss 1.0087 | train_acc 0.6724 | val_acc 0.6382 | lr 1.64e-04 | 1.2s\n",
      "epoch 012 | train_loss 0.8778 | val_loss 0.9991 | train_acc 0.6795 | val_acc 0.6397 | lr 1.64e-04 | 1.2s\n",
      "epoch 013 | train_loss 0.8694 | val_loss 0.9986 | train_acc 0.6852 | val_acc 0.6467 | lr 1.64e-04 | 1.2s\n",
      "epoch 014 | train_loss 0.8544 | val_loss 1.0085 | train_acc 0.6887 | val_acc 0.6356 | lr 1.64e-04 | 1.2s\n",
      "epoch 015 | train_loss 0.8309 | val_loss 0.9891 | train_acc 0.7010 | val_acc 0.6449 | lr 1.64e-04 | 1.2s\n",
      "epoch 016 | train_loss 0.8206 | val_loss 0.9927 | train_acc 0.7014 | val_acc 0.6386 | lr 1.64e-04 | 1.2s\n",
      "epoch 017 | train_loss 0.8115 | val_loss 1.0030 | train_acc 0.7052 | val_acc 0.6371 | lr 1.64e-04 | 1.2s\n",
      "epoch 018 | train_loss 0.7932 | val_loss 0.9941 | train_acc 0.7144 | val_acc 0.6386 | lr 1.64e-04 | 1.2s\n",
      "epoch 019 | train_loss 0.7754 | val_loss 0.9987 | train_acc 0.7200 | val_acc 0.6312 | lr 1.64e-04 | 1.2s\n",
      "epoch 020 | train_loss 0.7640 | val_loss 0.9993 | train_acc 0.7256 | val_acc 0.6438 | lr 1.64e-04 | 1.2s\n",
      "epoch 021 | train_loss 0.7570 | val_loss 1.0003 | train_acc 0.7302 | val_acc 0.6386 | lr 1.64e-04 | 1.2s\n",
      "epoch 022 | train_loss 0.7505 | val_loss 1.0031 | train_acc 0.7256 | val_acc 0.6471 | lr 1.64e-04 | 1.2s\n",
      "epoch 023 | train_loss 0.7336 | val_loss 1.0115 | train_acc 0.7364 | val_acc 0.6393 | lr 1.64e-04 | 1.2s\n",
      "epoch 024 | train_loss 0.7133 | val_loss 1.0112 | train_acc 0.7421 | val_acc 0.6382 | lr 1.64e-04 | 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:17:51,158] Trial 74 finished with value: 0.9890944383273016 and parameters: {'lr': 0.00016355256333539458, 'num_layers': 1, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 72 with value: 0.9823930212417005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7096 | val_loss 1.0105 | train_acc 0.7509 | val_acc 0.6456 | lr 1.64e-04 | 1.2s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5429 | val_loss 1.2422 | train_acc 0.4628 | val_acc 0.5872 | lr 1.41e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2456 | val_loss 1.1186 | train_acc 0.5541 | val_acc 0.5994 | lr 1.41e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1597 | val_loss 1.0660 | train_acc 0.5801 | val_acc 0.6190 | lr 1.41e-04 | 2.0s\n",
      "epoch 004 | train_loss 1.1129 | val_loss 1.0517 | train_acc 0.5994 | val_acc 0.6083 | lr 1.41e-04 | 2.0s\n",
      "epoch 005 | train_loss 1.0839 | val_loss 1.0199 | train_acc 0.6024 | val_acc 0.6301 | lr 1.41e-04 | 2.0s\n",
      "epoch 006 | train_loss 1.0451 | val_loss 1.0224 | train_acc 0.6165 | val_acc 0.6238 | lr 1.41e-04 | 2.0s\n",
      "epoch 007 | train_loss 1.0088 | val_loss 1.0078 | train_acc 0.6308 | val_acc 0.6231 | lr 1.41e-04 | 2.0s\n",
      "epoch 008 | train_loss 0.9895 | val_loss 1.0005 | train_acc 0.6461 | val_acc 0.6334 | lr 1.41e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9749 | val_loss 0.9899 | train_acc 0.6446 | val_acc 0.6364 | lr 1.41e-04 | 2.0s\n",
      "epoch 010 | train_loss 0.9438 | val_loss 0.9863 | train_acc 0.6545 | val_acc 0.6327 | lr 1.41e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.9313 | val_loss 0.9890 | train_acc 0.6593 | val_acc 0.6312 | lr 1.41e-04 | 2.0s\n",
      "epoch 012 | train_loss 0.9083 | val_loss 0.9996 | train_acc 0.6705 | val_acc 0.6323 | lr 1.41e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8877 | val_loss 0.9814 | train_acc 0.6739 | val_acc 0.6378 | lr 1.41e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8757 | val_loss 0.9877 | train_acc 0.6777 | val_acc 0.6404 | lr 1.41e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.8507 | val_loss 0.9882 | train_acc 0.6858 | val_acc 0.6419 | lr 1.41e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8249 | val_loss 1.0003 | train_acc 0.6976 | val_acc 0.6360 | lr 1.41e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.8126 | val_loss 0.9880 | train_acc 0.6989 | val_acc 0.6438 | lr 1.41e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.7981 | val_loss 0.9930 | train_acc 0.7070 | val_acc 0.6397 | lr 1.41e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.7729 | val_loss 1.0094 | train_acc 0.7136 | val_acc 0.6356 | lr 1.41e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.7764 | val_loss 1.0004 | train_acc 0.7161 | val_acc 0.6434 | lr 1.41e-04 | 2.0s\n",
      "epoch 021 | train_loss 0.7554 | val_loss 1.0072 | train_acc 0.7204 | val_acc 0.6367 | lr 1.41e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.7428 | val_loss 1.0193 | train_acc 0.7246 | val_acc 0.6360 | lr 1.41e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:18:38,427] Trial 75 finished with value: 0.9813707301287147 and parameters: {'lr': 0.0001409045004251313, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.7185 | val_loss 1.0213 | train_acc 0.7341 | val_acc 0.6308 | lr 1.41e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4690 | val_loss 1.2154 | train_acc 0.4876 | val_acc 0.5761 | lr 2.04e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2047 | val_loss 1.1115 | train_acc 0.5720 | val_acc 0.5953 | lr 2.04e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1313 | val_loss 1.0709 | train_acc 0.5942 | val_acc 0.6024 | lr 2.04e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.0861 | val_loss 1.0582 | train_acc 0.6090 | val_acc 0.6001 | lr 2.04e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0423 | val_loss 1.0391 | train_acc 0.6159 | val_acc 0.6057 | lr 2.04e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0093 | val_loss 1.0213 | train_acc 0.6318 | val_acc 0.6238 | lr 2.04e-04 | 2.1s\n",
      "epoch 007 | train_loss 0.9859 | val_loss 1.0101 | train_acc 0.6374 | val_acc 0.6201 | lr 2.04e-04 | 2.1s\n",
      "epoch 008 | train_loss 0.9539 | val_loss 1.0116 | train_acc 0.6497 | val_acc 0.6197 | lr 2.04e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9320 | val_loss 1.0127 | train_acc 0.6576 | val_acc 0.6290 | lr 2.04e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9143 | val_loss 1.0134 | train_acc 0.6626 | val_acc 0.6256 | lr 2.04e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.8838 | val_loss 1.0062 | train_acc 0.6745 | val_acc 0.6356 | lr 2.04e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.8700 | val_loss 1.0077 | train_acc 0.6790 | val_acc 0.6360 | lr 2.04e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.8449 | val_loss 0.9978 | train_acc 0.6864 | val_acc 0.6290 | lr 2.04e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8283 | val_loss 1.0204 | train_acc 0.6945 | val_acc 0.6356 | lr 2.04e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8099 | val_loss 0.9991 | train_acc 0.6995 | val_acc 0.6367 | lr 2.04e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.7900 | val_loss 1.0123 | train_acc 0.7093 | val_acc 0.6356 | lr 2.04e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.7572 | val_loss 1.0015 | train_acc 0.7167 | val_acc 0.6397 | lr 2.04e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.7544 | val_loss 1.0226 | train_acc 0.7216 | val_acc 0.6308 | lr 2.04e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.7457 | val_loss 1.0281 | train_acc 0.7256 | val_acc 0.6375 | lr 2.04e-04 | 2.1s\n",
      "epoch 020 | train_loss 0.7116 | val_loss 1.0361 | train_acc 0.7342 | val_acc 0.6279 | lr 2.04e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7115 | val_loss 1.0253 | train_acc 0.7340 | val_acc 0.6423 | lr 2.04e-04 | 2.1s\n",
      "epoch 022 | train_loss 0.6890 | val_loss 1.0614 | train_acc 0.7442 | val_acc 0.6164 | lr 2.04e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:19:25,844] Trial 76 finished with value: 0.9977757372154805 and parameters: {'lr': 0.00020403803741273543, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.6764 | val_loss 1.0527 | train_acc 0.7507 | val_acc 0.6271 | lr 2.04e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5410 | val_loss 1.2739 | train_acc 0.4675 | val_acc 0.5743 | lr 1.37e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2511 | val_loss 1.1310 | train_acc 0.5567 | val_acc 0.6016 | lr 1.37e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1673 | val_loss 1.0976 | train_acc 0.5823 | val_acc 0.6001 | lr 1.37e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.1204 | val_loss 1.0574 | train_acc 0.5947 | val_acc 0.6146 | lr 1.37e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0914 | val_loss 1.0371 | train_acc 0.6088 | val_acc 0.6271 | lr 1.37e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0548 | val_loss 1.0221 | train_acc 0.6169 | val_acc 0.6293 | lr 1.37e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0152 | val_loss 1.0093 | train_acc 0.6363 | val_acc 0.6364 | lr 1.37e-04 | 2.0s\n",
      "epoch 008 | train_loss 1.0006 | val_loss 1.0071 | train_acc 0.6342 | val_acc 0.6286 | lr 1.37e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9759 | val_loss 1.0071 | train_acc 0.6419 | val_acc 0.6305 | lr 1.37e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9524 | val_loss 1.0014 | train_acc 0.6505 | val_acc 0.6308 | lr 1.37e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.9279 | val_loss 0.9912 | train_acc 0.6603 | val_acc 0.6419 | lr 1.37e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.9168 | val_loss 1.0156 | train_acc 0.6603 | val_acc 0.6345 | lr 1.37e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8887 | val_loss 0.9897 | train_acc 0.6761 | val_acc 0.6345 | lr 1.37e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8667 | val_loss 0.9842 | train_acc 0.6855 | val_acc 0.6441 | lr 1.37e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8541 | val_loss 0.9971 | train_acc 0.6868 | val_acc 0.6423 | lr 1.37e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8275 | val_loss 1.0105 | train_acc 0.6941 | val_acc 0.6290 | lr 1.37e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.8183 | val_loss 1.0024 | train_acc 0.6982 | val_acc 0.6393 | lr 1.37e-04 | 2.1s\n",
      "epoch 018 | train_loss 0.8064 | val_loss 1.0023 | train_acc 0.7046 | val_acc 0.6393 | lr 1.37e-04 | 2.1s\n",
      "epoch 019 | train_loss 0.7819 | val_loss 0.9926 | train_acc 0.7142 | val_acc 0.6426 | lr 1.37e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.7610 | val_loss 1.0082 | train_acc 0.7217 | val_acc 0.6364 | lr 1.37e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7475 | val_loss 1.0164 | train_acc 0.7310 | val_acc 0.6353 | lr 1.37e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.7316 | val_loss 1.0189 | train_acc 0.7318 | val_acc 0.6393 | lr 1.37e-04 | 2.1s\n",
      "epoch 023 | train_loss 0.7271 | val_loss 1.0312 | train_acc 0.7338 | val_acc 0.6345 | lr 1.37e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:20:15,169] Trial 77 finished with value: 0.9841703170330897 and parameters: {'lr': 0.00013730562774655586, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.7034 | val_loss 1.0202 | train_acc 0.7453 | val_acc 0.6419 | lr 1.37e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5375 | val_loss 1.2570 | train_acc 0.4695 | val_acc 0.5758 | lr 1.38e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2534 | val_loss 1.1292 | train_acc 0.5551 | val_acc 0.5942 | lr 1.38e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1661 | val_loss 1.0786 | train_acc 0.5823 | val_acc 0.6046 | lr 1.38e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.1158 | val_loss 1.0570 | train_acc 0.5975 | val_acc 0.6112 | lr 1.38e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0727 | val_loss 1.0410 | train_acc 0.6158 | val_acc 0.6197 | lr 1.38e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0400 | val_loss 1.0235 | train_acc 0.6232 | val_acc 0.6216 | lr 1.38e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0137 | val_loss 1.0166 | train_acc 0.6355 | val_acc 0.6175 | lr 1.38e-04 | 2.0s\n",
      "epoch 008 | train_loss 0.9866 | val_loss 1.0012 | train_acc 0.6421 | val_acc 0.6327 | lr 1.38e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9688 | val_loss 1.0096 | train_acc 0.6413 | val_acc 0.6205 | lr 1.38e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9434 | val_loss 0.9902 | train_acc 0.6574 | val_acc 0.6297 | lr 1.38e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.9229 | val_loss 0.9916 | train_acc 0.6632 | val_acc 0.6305 | lr 1.38e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.9092 | val_loss 0.9986 | train_acc 0.6642 | val_acc 0.6245 | lr 1.38e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8765 | val_loss 0.9966 | train_acc 0.6755 | val_acc 0.6282 | lr 1.38e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8656 | val_loss 0.9997 | train_acc 0.6817 | val_acc 0.6401 | lr 1.38e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8414 | val_loss 0.9957 | train_acc 0.6921 | val_acc 0.6367 | lr 1.38e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8277 | val_loss 1.0083 | train_acc 0.6974 | val_acc 0.6305 | lr 1.38e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.8016 | val_loss 1.0103 | train_acc 0.7058 | val_acc 0.6238 | lr 1.38e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.7864 | val_loss 1.0123 | train_acc 0.7081 | val_acc 0.6260 | lr 1.38e-04 | 2.1s\n",
      "epoch 019 | train_loss 0.7668 | val_loss 1.0107 | train_acc 0.7196 | val_acc 0.6316 | lr 1.38e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:20:56,373] Trial 78 finished with value: 0.9902470183213904 and parameters: {'lr': 0.00013764829548848642, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.7571 | val_loss 1.0186 | train_acc 0.7241 | val_acc 0.6308 | lr 1.38e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3388 | val_loss 1.1267 | train_acc 0.5213 | val_acc 0.5828 | lr 8.28e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.1651 | val_loss 1.1087 | train_acc 0.5746 | val_acc 0.5817 | lr 8.28e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1070 | val_loss 1.0522 | train_acc 0.5951 | val_acc 0.6190 | lr 8.27e-04 | 2.0s\n",
      "epoch 004 | train_loss 1.0582 | val_loss 1.0341 | train_acc 0.6084 | val_acc 0.6120 | lr 8.25e-04 | 2.0s\n",
      "epoch 005 | train_loss 1.0260 | val_loss 1.0288 | train_acc 0.6206 | val_acc 0.6256 | lr 8.23e-04 | 2.1s\n",
      "epoch 006 | train_loss 0.9944 | val_loss 1.0535 | train_acc 0.6287 | val_acc 0.6256 | lr 8.21e-04 | 2.0s\n",
      "epoch 007 | train_loss 0.9716 | val_loss 1.0404 | train_acc 0.6384 | val_acc 0.6046 | lr 8.18e-04 | 2.1s\n",
      "epoch 008 | train_loss 0.9477 | val_loss 1.0180 | train_acc 0.6473 | val_acc 0.6256 | lr 8.15e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.9230 | val_loss 1.0096 | train_acc 0.6509 | val_acc 0.6316 | lr 8.12e-04 | 2.0s\n",
      "epoch 010 | train_loss 0.8996 | val_loss 1.0020 | train_acc 0.6601 | val_acc 0.6404 | lr 8.08e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.8704 | val_loss 1.0128 | train_acc 0.6707 | val_acc 0.6345 | lr 8.04e-04 | 2.0s\n",
      "epoch 012 | train_loss 0.8472 | val_loss 1.0291 | train_acc 0.6873 | val_acc 0.6327 | lr 7.99e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.8192 | val_loss 1.0515 | train_acc 0.6927 | val_acc 0.6268 | lr 7.94e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8095 | val_loss 1.0504 | train_acc 0.6978 | val_acc 0.6205 | lr 7.89e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.7840 | val_loss 1.0738 | train_acc 0.7064 | val_acc 0.6330 | lr 7.83e-04 | 2.0s\n",
      "epoch 016 | train_loss 0.7599 | val_loss 1.0877 | train_acc 0.7224 | val_acc 0.6305 | lr 7.77e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.7468 | val_loss 1.0979 | train_acc 0.7228 | val_acc 0.6349 | lr 7.71e-04 | 2.1s\n",
      "epoch 018 | train_loss 0.7156 | val_loss 1.0924 | train_acc 0.7339 | val_acc 0.6079 | lr 7.64e-04 | 2.1s\n",
      "epoch 019 | train_loss 0.7220 | val_loss 1.1306 | train_acc 0.7241 | val_acc 0.6345 | lr 7.57e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:21:37,436] Trial 79 finished with value: 1.0019575768898614 and parameters: {'lr': 0.0008283606108640348, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': True}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 020 | train_loss 0.6842 | val_loss 1.1027 | train_acc 0.7449 | val_acc 0.6456 | lr 7.49e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5650 | val_loss 1.4042 | train_acc 0.4664 | val_acc 0.5698 | lr 1.77e-04 | 1.1s\n",
      "epoch 002 | train_loss 1.2535 | val_loss 1.1884 | train_acc 0.5558 | val_acc 0.5791 | lr 1.77e-04 | 1.0s\n",
      "epoch 003 | train_loss 1.1617 | val_loss 1.0920 | train_acc 0.5866 | val_acc 0.6101 | lr 1.77e-04 | 1.0s\n",
      "epoch 004 | train_loss 1.1165 | val_loss 1.0683 | train_acc 0.6009 | val_acc 0.6075 | lr 1.77e-04 | 1.0s\n",
      "epoch 005 | train_loss 1.0658 | val_loss 1.0438 | train_acc 0.6124 | val_acc 0.6179 | lr 1.77e-04 | 1.0s\n",
      "epoch 006 | train_loss 1.0338 | val_loss 1.0421 | train_acc 0.6249 | val_acc 0.6208 | lr 1.77e-04 | 1.0s\n",
      "epoch 007 | train_loss 1.0079 | val_loss 1.0162 | train_acc 0.6362 | val_acc 0.6290 | lr 1.77e-04 | 1.0s\n",
      "epoch 008 | train_loss 0.9802 | val_loss 1.0164 | train_acc 0.6409 | val_acc 0.6220 | lr 1.77e-04 | 1.0s\n",
      "epoch 009 | train_loss 0.9581 | val_loss 1.0016 | train_acc 0.6533 | val_acc 0.6316 | lr 1.77e-04 | 1.0s\n",
      "epoch 010 | train_loss 0.9350 | val_loss 1.0149 | train_acc 0.6589 | val_acc 0.6231 | lr 1.77e-04 | 1.0s\n",
      "epoch 011 | train_loss 0.9125 | val_loss 1.0063 | train_acc 0.6710 | val_acc 0.6253 | lr 1.77e-04 | 1.0s\n",
      "epoch 012 | train_loss 0.8777 | val_loss 1.0097 | train_acc 0.6809 | val_acc 0.6305 | lr 1.77e-04 | 1.0s\n",
      "epoch 013 | train_loss 0.8638 | val_loss 0.9957 | train_acc 0.6843 | val_acc 0.6341 | lr 1.77e-04 | 1.0s\n",
      "epoch 014 | train_loss 0.8500 | val_loss 0.9967 | train_acc 0.6926 | val_acc 0.6378 | lr 1.77e-04 | 1.0s\n",
      "epoch 015 | train_loss 0.8321 | val_loss 1.0034 | train_acc 0.6941 | val_acc 0.6305 | lr 1.77e-04 | 1.0s\n",
      "epoch 016 | train_loss 0.8203 | val_loss 1.0201 | train_acc 0.6973 | val_acc 0.6412 | lr 1.77e-04 | 1.0s\n",
      "epoch 017 | train_loss 0.7952 | val_loss 0.9965 | train_acc 0.7112 | val_acc 0.6419 | lr 1.77e-04 | 1.0s\n",
      "epoch 018 | train_loss 0.7703 | val_loss 1.0086 | train_acc 0.7173 | val_acc 0.6375 | lr 1.77e-04 | 1.0s\n",
      "epoch 019 | train_loss 0.7582 | val_loss 1.0352 | train_acc 0.7239 | val_acc 0.6234 | lr 1.77e-04 | 1.0s\n",
      "epoch 020 | train_loss 0.7472 | val_loss 1.0225 | train_acc 0.7314 | val_acc 0.6393 | lr 1.77e-04 | 1.0s\n",
      "epoch 021 | train_loss 0.7224 | val_loss 1.0208 | train_acc 0.7314 | val_acc 0.6434 | lr 1.77e-04 | 1.0s\n",
      "epoch 022 | train_loss 0.7165 | val_loss 1.0370 | train_acc 0.7398 | val_acc 0.6301 | lr 1.77e-04 | 1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:22:01,113] Trial 80 finished with value: 0.9956807459361097 and parameters: {'lr': 0.00017725877564015767, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 64, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.6940 | val_loss 1.0470 | train_acc 0.7489 | val_acc 0.6316 | lr 1.77e-04 | 1.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5207 | val_loss 1.2435 | train_acc 0.4743 | val_acc 0.5765 | lr 1.42e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2388 | val_loss 1.1189 | train_acc 0.5612 | val_acc 0.6024 | lr 1.42e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1542 | val_loss 1.0650 | train_acc 0.5855 | val_acc 0.6164 | lr 1.42e-04 | 2.0s\n",
      "epoch 004 | train_loss 1.1100 | val_loss 1.0395 | train_acc 0.5999 | val_acc 0.6190 | lr 1.42e-04 | 2.0s\n",
      "epoch 005 | train_loss 1.0818 | val_loss 1.0317 | train_acc 0.6110 | val_acc 0.6268 | lr 1.42e-04 | 2.0s\n",
      "epoch 006 | train_loss 1.0470 | val_loss 1.0161 | train_acc 0.6195 | val_acc 0.6271 | lr 1.42e-04 | 2.0s\n",
      "epoch 007 | train_loss 1.0164 | val_loss 1.0183 | train_acc 0.6288 | val_acc 0.6275 | lr 1.42e-04 | 2.0s\n",
      "epoch 008 | train_loss 0.9891 | val_loss 1.0234 | train_acc 0.6364 | val_acc 0.6179 | lr 1.42e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.9719 | val_loss 1.0066 | train_acc 0.6501 | val_acc 0.6356 | lr 1.42e-04 | 2.0s\n",
      "epoch 010 | train_loss 0.9394 | val_loss 1.0020 | train_acc 0.6535 | val_acc 0.6293 | lr 1.42e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.9240 | val_loss 0.9984 | train_acc 0.6603 | val_acc 0.6341 | lr 1.42e-04 | 2.0s\n",
      "epoch 012 | train_loss 0.9122 | val_loss 0.9889 | train_acc 0.6644 | val_acc 0.6356 | lr 1.42e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8786 | val_loss 0.9910 | train_acc 0.6775 | val_acc 0.6467 | lr 1.42e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8549 | val_loss 0.9929 | train_acc 0.6850 | val_acc 0.6415 | lr 1.42e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.8470 | val_loss 0.9996 | train_acc 0.6882 | val_acc 0.6290 | lr 1.42e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8377 | val_loss 0.9891 | train_acc 0.6922 | val_acc 0.6378 | lr 1.42e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.8110 | val_loss 0.9989 | train_acc 0.6991 | val_acc 0.6426 | lr 1.42e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.8041 | val_loss 1.0100 | train_acc 0.7022 | val_acc 0.6286 | lr 1.42e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.7724 | val_loss 1.0070 | train_acc 0.7173 | val_acc 0.6312 | lr 1.42e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.7564 | val_loss 1.0162 | train_acc 0.7206 | val_acc 0.6341 | lr 1.42e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7451 | val_loss 0.9994 | train_acc 0.7281 | val_acc 0.6434 | lr 1.42e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:22:46,232] Trial 81 finished with value: 0.9889151205949579 and parameters: {'lr': 0.00014169683229278763, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 75 with value: 0.9813707301287147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.7365 | val_loss 1.0174 | train_acc 0.7335 | val_acc 0.6390 | lr 1.42e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5680 | val_loss 1.2971 | train_acc 0.4634 | val_acc 0.5510 | lr 1.15e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2644 | val_loss 1.1477 | train_acc 0.5518 | val_acc 0.5920 | lr 1.15e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1828 | val_loss 1.1046 | train_acc 0.5748 | val_acc 0.6027 | lr 1.15e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.1397 | val_loss 1.0697 | train_acc 0.5848 | val_acc 0.6105 | lr 1.15e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.1011 | val_loss 1.0436 | train_acc 0.6008 | val_acc 0.6242 | lr 1.15e-04 | 2.0s\n",
      "epoch 006 | train_loss 1.0649 | val_loss 1.0373 | train_acc 0.6121 | val_acc 0.6223 | lr 1.15e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0484 | val_loss 1.0276 | train_acc 0.6186 | val_acc 0.6256 | lr 1.15e-04 | 2.1s\n",
      "epoch 008 | train_loss 1.0189 | val_loss 1.0233 | train_acc 0.6315 | val_acc 0.6234 | lr 1.15e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.9969 | val_loss 0.9949 | train_acc 0.6371 | val_acc 0.6382 | lr 1.15e-04 | 2.0s\n",
      "epoch 010 | train_loss 0.9692 | val_loss 0.9930 | train_acc 0.6452 | val_acc 0.6341 | lr 1.15e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.9573 | val_loss 1.0192 | train_acc 0.6471 | val_acc 0.6131 | lr 1.15e-04 | 2.0s\n",
      "epoch 012 | train_loss 0.9354 | val_loss 1.0037 | train_acc 0.6517 | val_acc 0.6323 | lr 1.15e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.9191 | val_loss 0.9813 | train_acc 0.6621 | val_acc 0.6412 | lr 1.15e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8945 | val_loss 0.9894 | train_acc 0.6710 | val_acc 0.6327 | lr 1.15e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.8854 | val_loss 0.9891 | train_acc 0.6758 | val_acc 0.6356 | lr 1.15e-04 | 2.0s\n",
      "epoch 016 | train_loss 0.8589 | val_loss 0.9975 | train_acc 0.6862 | val_acc 0.6253 | lr 1.15e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.8557 | val_loss 0.9903 | train_acc 0.6834 | val_acc 0.6367 | lr 1.15e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.8240 | val_loss 1.0053 | train_acc 0.6994 | val_acc 0.6286 | lr 1.15e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.8235 | val_loss 0.9915 | train_acc 0.6941 | val_acc 0.6353 | lr 1.15e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.8012 | val_loss 0.9964 | train_acc 0.7055 | val_acc 0.6341 | lr 1.15e-04 | 2.0s\n",
      "epoch 021 | train_loss 0.7839 | val_loss 0.9929 | train_acc 0.7147 | val_acc 0.6334 | lr 1.15e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.7747 | val_loss 0.9955 | train_acc 0.7161 | val_acc 0.6275 | lr 1.15e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:23:33,423] Trial 82 finished with value: 0.9813379565610414 and parameters: {'lr': 0.0001149883682760068, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 023 | train_loss 0.7546 | val_loss 1.0036 | train_acc 0.7277 | val_acc 0.6334 | lr 1.15e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5697 | val_loss 1.2750 | train_acc 0.4577 | val_acc 0.5813 | lr 1.26e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2553 | val_loss 1.1504 | train_acc 0.5576 | val_acc 0.5968 | lr 1.26e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1713 | val_loss 1.0891 | train_acc 0.5744 | val_acc 0.6105 | lr 1.26e-04 | 2.0s\n",
      "epoch 004 | train_loss 1.1180 | val_loss 1.0785 | train_acc 0.5959 | val_acc 0.6053 | lr 1.26e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0931 | val_loss 1.0536 | train_acc 0.6061 | val_acc 0.6153 | lr 1.26e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0586 | val_loss 1.0504 | train_acc 0.6164 | val_acc 0.6086 | lr 1.26e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0237 | val_loss 1.0318 | train_acc 0.6247 | val_acc 0.6164 | lr 1.26e-04 | 2.1s\n",
      "epoch 008 | train_loss 1.0076 | val_loss 1.0072 | train_acc 0.6337 | val_acc 0.6345 | lr 1.26e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.9863 | val_loss 1.0102 | train_acc 0.6421 | val_acc 0.6271 | lr 1.26e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9587 | val_loss 1.0051 | train_acc 0.6531 | val_acc 0.6330 | lr 1.26e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.9392 | val_loss 1.0033 | train_acc 0.6559 | val_acc 0.6349 | lr 1.26e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.9206 | val_loss 0.9996 | train_acc 0.6663 | val_acc 0.6312 | lr 1.26e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.8949 | val_loss 0.9982 | train_acc 0.6730 | val_acc 0.6382 | lr 1.26e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8841 | val_loss 1.0027 | train_acc 0.6718 | val_acc 0.6386 | lr 1.26e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8585 | val_loss 0.9979 | train_acc 0.6877 | val_acc 0.6364 | lr 1.26e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8420 | val_loss 0.9995 | train_acc 0.6926 | val_acc 0.6430 | lr 1.26e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.8223 | val_loss 1.0065 | train_acc 0.6980 | val_acc 0.6415 | lr 1.26e-04 | 2.1s\n",
      "epoch 018 | train_loss 0.8134 | val_loss 1.0047 | train_acc 0.7024 | val_acc 0.6419 | lr 1.26e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.7960 | val_loss 1.0278 | train_acc 0.7047 | val_acc 0.6349 | lr 1.26e-04 | 2.1s\n",
      "epoch 020 | train_loss 0.7844 | val_loss 1.0058 | train_acc 0.7112 | val_acc 0.6367 | lr 1.26e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7732 | val_loss 1.0390 | train_acc 0.7155 | val_acc 0.6323 | lr 1.26e-04 | 2.1s\n",
      "epoch 022 | train_loss 0.7470 | val_loss 1.0184 | train_acc 0.7275 | val_acc 0.6338 | lr 1.26e-04 | 2.1s\n",
      "epoch 023 | train_loss 0.7421 | val_loss 1.0198 | train_acc 0.7222 | val_acc 0.6438 | lr 1.26e-04 | 2.1s\n",
      "epoch 024 | train_loss 0.7223 | val_loss 1.0227 | train_acc 0.7321 | val_acc 0.6319 | lr 1.26e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:24:24,837] Trial 83 finished with value: 0.9979394898093901 and parameters: {'lr': 0.00012632085745596967, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7136 | val_loss 1.0263 | train_acc 0.7349 | val_acc 0.6415 | lr 1.26e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5152 | val_loss 1.2368 | train_acc 0.4709 | val_acc 0.5687 | lr 1.53e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2342 | val_loss 1.1198 | train_acc 0.5575 | val_acc 0.6016 | lr 1.53e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1603 | val_loss 1.0708 | train_acc 0.5849 | val_acc 0.6190 | lr 1.53e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.1032 | val_loss 1.0450 | train_acc 0.5988 | val_acc 0.6238 | lr 1.53e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0675 | val_loss 1.0280 | train_acc 0.6114 | val_acc 0.6327 | lr 1.53e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0348 | val_loss 1.0224 | train_acc 0.6282 | val_acc 0.6312 | lr 1.53e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0104 | val_loss 1.0193 | train_acc 0.6350 | val_acc 0.6264 | lr 1.53e-04 | 2.0s\n",
      "epoch 008 | train_loss 0.9725 | val_loss 1.0083 | train_acc 0.6503 | val_acc 0.6190 | lr 1.53e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9683 | val_loss 1.0082 | train_acc 0.6455 | val_acc 0.6305 | lr 1.53e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9282 | val_loss 1.0014 | train_acc 0.6595 | val_acc 0.6275 | lr 1.53e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.9166 | val_loss 1.0029 | train_acc 0.6616 | val_acc 0.6319 | lr 1.53e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.8892 | val_loss 0.9942 | train_acc 0.6766 | val_acc 0.6319 | lr 1.53e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8609 | val_loss 0.9972 | train_acc 0.6806 | val_acc 0.6408 | lr 1.53e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8456 | val_loss 0.9933 | train_acc 0.6902 | val_acc 0.6471 | lr 1.53e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8433 | val_loss 0.9934 | train_acc 0.6937 | val_acc 0.6393 | lr 1.53e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.8202 | val_loss 1.0041 | train_acc 0.6908 | val_acc 0.6360 | lr 1.53e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.7929 | val_loss 0.9978 | train_acc 0.7087 | val_acc 0.6367 | lr 1.53e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.7824 | val_loss 0.9974 | train_acc 0.7105 | val_acc 0.6408 | lr 1.53e-04 | 2.1s\n",
      "epoch 019 | train_loss 0.7562 | val_loss 0.9983 | train_acc 0.7226 | val_acc 0.6463 | lr 1.53e-04 | 2.1s\n",
      "epoch 020 | train_loss 0.7501 | val_loss 1.0028 | train_acc 0.7213 | val_acc 0.6467 | lr 1.53e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7368 | val_loss 1.0325 | train_acc 0.7287 | val_acc 0.6386 | lr 1.53e-04 | 2.0s\n",
      "epoch 022 | train_loss 0.7189 | val_loss 1.0307 | train_acc 0.7319 | val_acc 0.6449 | lr 1.53e-04 | 2.0s\n",
      "epoch 023 | train_loss 0.7073 | val_loss 1.0429 | train_acc 0.7400 | val_acc 0.6293 | lr 1.53e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:25:14,187] Trial 84 finished with value: 0.9932672606515426 and parameters: {'lr': 0.00015304180615835757, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 024 | train_loss 0.6953 | val_loss 1.0500 | train_acc 0.7428 | val_acc 0.6279 | lr 1.53e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6742 | val_loss 1.7113 | train_acc 0.4338 | val_acc 0.5451 | lr 1.75e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2961 | val_loss 1.3360 | train_acc 0.5473 | val_acc 0.5928 | lr 1.75e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.1916 | val_loss 1.1744 | train_acc 0.5789 | val_acc 0.6024 | lr 1.75e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1330 | val_loss 1.0986 | train_acc 0.5925 | val_acc 0.6053 | lr 1.75e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.0833 | val_loss 1.0759 | train_acc 0.6118 | val_acc 0.6068 | lr 1.75e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.0538 | val_loss 1.0570 | train_acc 0.6220 | val_acc 0.6160 | lr 1.75e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0228 | val_loss 1.0576 | train_acc 0.6336 | val_acc 0.6127 | lr 1.75e-04 | 0.5s\n",
      "epoch 008 | train_loss 0.9914 | val_loss 1.0334 | train_acc 0.6446 | val_acc 0.6220 | lr 1.75e-04 | 0.5s\n",
      "epoch 009 | train_loss 0.9719 | val_loss 1.0338 | train_acc 0.6499 | val_acc 0.6175 | lr 1.75e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9426 | val_loss 1.0272 | train_acc 0.6571 | val_acc 0.6249 | lr 1.75e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9207 | val_loss 1.0260 | train_acc 0.6671 | val_acc 0.6271 | lr 1.75e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9036 | val_loss 1.0087 | train_acc 0.6717 | val_acc 0.6334 | lr 1.75e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.8782 | val_loss 1.0157 | train_acc 0.6767 | val_acc 0.6227 | lr 1.75e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.8563 | val_loss 1.0165 | train_acc 0.6920 | val_acc 0.6175 | lr 1.75e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8384 | val_loss 1.0109 | train_acc 0.6939 | val_acc 0.6312 | lr 1.75e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8239 | val_loss 1.0191 | train_acc 0.6988 | val_acc 0.6338 | lr 1.75e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.7995 | val_loss 1.0205 | train_acc 0.7071 | val_acc 0.6301 | lr 1.75e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.7817 | val_loss 1.0295 | train_acc 0.7104 | val_acc 0.6238 | lr 1.75e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.7686 | val_loss 1.0400 | train_acc 0.7187 | val_acc 0.6249 | lr 1.75e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.7507 | val_loss 1.0360 | train_acc 0.7256 | val_acc 0.6264 | lr 1.75e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.7273 | val_loss 1.0301 | train_acc 0.7377 | val_acc 0.6327 | lr 1.75e-04 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:25:25,748] Trial 85 finished with value: 1.008671520114033 and parameters: {'lr': 0.0001748899016452668, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.7183 | val_loss 1.0391 | train_acc 0.7426 | val_acc 0.6356 | lr 1.75e-04 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4536 | val_loss 1.2006 | train_acc 0.4907 | val_acc 0.5758 | lr 2.11e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.1994 | val_loss 1.0842 | train_acc 0.5708 | val_acc 0.6149 | lr 2.11e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1287 | val_loss 1.0691 | train_acc 0.5912 | val_acc 0.6105 | lr 2.11e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.0846 | val_loss 1.0345 | train_acc 0.6051 | val_acc 0.6208 | lr 2.11e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0456 | val_loss 1.0426 | train_acc 0.6149 | val_acc 0.6112 | lr 2.11e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.0121 | val_loss 1.0220 | train_acc 0.6364 | val_acc 0.6264 | lr 2.11e-04 | 2.0s\n",
      "epoch 007 | train_loss 0.9847 | val_loss 1.0000 | train_acc 0.6408 | val_acc 0.6286 | lr 2.11e-04 | 2.1s\n",
      "epoch 008 | train_loss 0.9482 | val_loss 1.0195 | train_acc 0.6567 | val_acc 0.6234 | lr 2.11e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9325 | val_loss 1.0080 | train_acc 0.6546 | val_acc 0.6327 | lr 2.11e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9125 | val_loss 0.9947 | train_acc 0.6636 | val_acc 0.6316 | lr 2.11e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.8918 | val_loss 1.0383 | train_acc 0.6723 | val_acc 0.6220 | lr 2.11e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.8717 | val_loss 0.9890 | train_acc 0.6758 | val_acc 0.6327 | lr 2.11e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.8513 | val_loss 1.0000 | train_acc 0.6857 | val_acc 0.6293 | lr 2.11e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8276 | val_loss 0.9986 | train_acc 0.6981 | val_acc 0.6375 | lr 2.11e-04 | 2.1s\n",
      "epoch 015 | train_loss 0.8110 | val_loss 0.9954 | train_acc 0.7003 | val_acc 0.6316 | lr 2.11e-04 | 2.1s\n",
      "epoch 016 | train_loss 0.7960 | val_loss 1.0103 | train_acc 0.7077 | val_acc 0.6356 | lr 2.11e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.7829 | val_loss 1.0114 | train_acc 0.7091 | val_acc 0.6404 | lr 2.11e-04 | 2.0s\n",
      "epoch 018 | train_loss 0.7455 | val_loss 1.0018 | train_acc 0.7213 | val_acc 0.6471 | lr 2.11e-04 | 2.1s\n",
      "epoch 019 | train_loss 0.7363 | val_loss 1.0347 | train_acc 0.7290 | val_acc 0.6312 | lr 2.11e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.7197 | val_loss 1.0305 | train_acc 0.7372 | val_acc 0.6341 | lr 2.11e-04 | 2.0s\n",
      "epoch 021 | train_loss 0.7153 | val_loss 1.0324 | train_acc 0.7336 | val_acc 0.6434 | lr 2.11e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:26:10,970] Trial 86 finished with value: 0.9889509720178506 and parameters: {'lr': 0.00021057614466771322, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 022 | train_loss 0.6889 | val_loss 1.0293 | train_acc 0.7495 | val_acc 0.6371 | lr 2.11e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.4206 | val_loss 1.1561 | train_acc 0.5059 | val_acc 0.5891 | lr 2.54e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.1831 | val_loss 1.0929 | train_acc 0.5792 | val_acc 0.6068 | lr 2.54e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1259 | val_loss 1.0633 | train_acc 0.5909 | val_acc 0.6135 | lr 2.54e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.0751 | val_loss 1.0259 | train_acc 0.6090 | val_acc 0.6131 | lr 2.54e-04 | 2.0s\n",
      "epoch 005 | train_loss 1.0345 | val_loss 1.0285 | train_acc 0.6199 | val_acc 0.6127 | lr 2.54e-04 | 2.0s\n",
      "epoch 006 | train_loss 1.0024 | val_loss 1.0021 | train_acc 0.6364 | val_acc 0.6286 | lr 2.54e-04 | 2.0s\n",
      "epoch 007 | train_loss 0.9771 | val_loss 1.0099 | train_acc 0.6379 | val_acc 0.6186 | lr 2.54e-04 | 2.1s\n",
      "epoch 008 | train_loss 0.9502 | val_loss 0.9963 | train_acc 0.6517 | val_acc 0.6323 | lr 2.54e-04 | 2.0s\n",
      "epoch 009 | train_loss 0.9315 | val_loss 1.0028 | train_acc 0.6585 | val_acc 0.6194 | lr 2.54e-04 | 2.0s\n",
      "epoch 010 | train_loss 0.9064 | val_loss 0.9981 | train_acc 0.6670 | val_acc 0.6330 | lr 2.54e-04 | 2.0s\n",
      "epoch 011 | train_loss 0.8708 | val_loss 1.0035 | train_acc 0.6823 | val_acc 0.6316 | lr 2.54e-04 | 2.0s\n",
      "epoch 012 | train_loss 0.8564 | val_loss 1.0064 | train_acc 0.6827 | val_acc 0.6242 | lr 2.54e-04 | 2.0s\n",
      "epoch 013 | train_loss 0.8405 | val_loss 1.0059 | train_acc 0.6864 | val_acc 0.6312 | lr 2.54e-04 | 2.0s\n",
      "epoch 014 | train_loss 0.8176 | val_loss 1.0233 | train_acc 0.6957 | val_acc 0.6282 | lr 2.54e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.7992 | val_loss 1.0115 | train_acc 0.7065 | val_acc 0.6404 | lr 2.54e-04 | 2.0s\n",
      "epoch 016 | train_loss 0.7828 | val_loss 1.0366 | train_acc 0.7106 | val_acc 0.6364 | lr 2.54e-04 | 2.0s\n",
      "epoch 017 | train_loss 0.7682 | val_loss 1.0191 | train_acc 0.7124 | val_acc 0.6360 | lr 2.54e-04 | 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:26:47,933] Trial 87 finished with value: 0.9963254000818121 and parameters: {'lr': 0.00025363140771870633, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 018 | train_loss 0.7436 | val_loss 1.0178 | train_acc 0.7244 | val_acc 0.6345 | lr 2.54e-04 | 2.0s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5890 | val_loss 1.3026 | train_acc 0.4562 | val_acc 0.5565 | lr 1.13e-04 | 2.1s\n",
      "epoch 002 | train_loss 1.2730 | val_loss 1.1723 | train_acc 0.5519 | val_acc 0.5831 | lr 1.13e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.1908 | val_loss 1.1231 | train_acc 0.5715 | val_acc 0.5965 | lr 1.13e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.1350 | val_loss 1.0803 | train_acc 0.5939 | val_acc 0.6046 | lr 1.13e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.0951 | val_loss 1.0581 | train_acc 0.6062 | val_acc 0.6094 | lr 1.13e-04 | 2.0s\n",
      "epoch 006 | train_loss 1.0621 | val_loss 1.0352 | train_acc 0.6137 | val_acc 0.6123 | lr 1.13e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.0360 | val_loss 1.0233 | train_acc 0.6199 | val_acc 0.6194 | lr 1.13e-04 | 2.1s\n",
      "epoch 008 | train_loss 1.0135 | val_loss 1.0213 | train_acc 0.6333 | val_acc 0.6249 | lr 1.13e-04 | 2.1s\n",
      "epoch 009 | train_loss 0.9960 | val_loss 1.0011 | train_acc 0.6358 | val_acc 0.6297 | lr 1.13e-04 | 2.1s\n",
      "epoch 010 | train_loss 0.9713 | val_loss 1.0077 | train_acc 0.6439 | val_acc 0.6282 | lr 1.13e-04 | 2.1s\n",
      "epoch 011 | train_loss 0.9539 | val_loss 1.0011 | train_acc 0.6517 | val_acc 0.6282 | lr 1.13e-04 | 2.1s\n",
      "epoch 012 | train_loss 0.9274 | val_loss 0.9955 | train_acc 0.6609 | val_acc 0.6338 | lr 1.13e-04 | 2.1s\n",
      "epoch 013 | train_loss 0.9094 | val_loss 0.9988 | train_acc 0.6678 | val_acc 0.6264 | lr 1.13e-04 | 2.1s\n",
      "epoch 014 | train_loss 0.8852 | val_loss 0.9945 | train_acc 0.6758 | val_acc 0.6371 | lr 1.13e-04 | 2.0s\n",
      "epoch 015 | train_loss 0.8808 | val_loss 0.9885 | train_acc 0.6764 | val_acc 0.6341 | lr 1.13e-04 | 2.0s\n",
      "epoch 016 | train_loss 0.8622 | val_loss 0.9959 | train_acc 0.6825 | val_acc 0.6334 | lr 1.13e-04 | 2.1s\n",
      "epoch 017 | train_loss 0.8452 | val_loss 1.0015 | train_acc 0.6925 | val_acc 0.6353 | lr 1.13e-04 | 2.1s\n",
      "epoch 018 | train_loss 0.8226 | val_loss 0.9998 | train_acc 0.7007 | val_acc 0.6419 | lr 1.13e-04 | 2.0s\n",
      "epoch 019 | train_loss 0.8176 | val_loss 1.0053 | train_acc 0.7029 | val_acc 0.6412 | lr 1.13e-04 | 2.0s\n",
      "epoch 020 | train_loss 0.8070 | val_loss 0.9980 | train_acc 0.7006 | val_acc 0.6330 | lr 1.13e-04 | 2.1s\n",
      "epoch 021 | train_loss 0.7782 | val_loss 1.0109 | train_acc 0.7166 | val_acc 0.6360 | lr 1.13e-04 | 2.1s\n",
      "epoch 022 | train_loss 0.7628 | val_loss 1.0137 | train_acc 0.7180 | val_acc 0.6345 | lr 1.13e-04 | 2.1s\n",
      "epoch 023 | train_loss 0.7618 | val_loss 1.0133 | train_acc 0.7195 | val_acc 0.6341 | lr 1.13e-04 | 2.1s\n",
      "epoch 024 | train_loss 0.7477 | val_loss 1.0175 | train_acc 0.7257 | val_acc 0.6327 | lr 1.13e-04 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:27:39,356] Trial 88 finished with value: 0.9885340892026271 and parameters: {'lr': 0.00011304968029915321, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7308 | val_loss 1.0212 | train_acc 0.7338 | val_acc 0.6338 | lr 1.13e-04 | 2.1s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7556 | val_loss 1.7955 | train_acc 0.4053 | val_acc 0.5070 | lr 1.29e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.3578 | val_loss 1.4182 | train_acc 0.5260 | val_acc 0.5654 | lr 1.29e-04 | 0.5s\n",
      "epoch 003 | train_loss 1.2390 | val_loss 1.2309 | train_acc 0.5681 | val_acc 0.5905 | lr 1.29e-04 | 0.5s\n",
      "epoch 004 | train_loss 1.1853 | val_loss 1.1386 | train_acc 0.5829 | val_acc 0.6038 | lr 1.28e-04 | 0.5s\n",
      "epoch 005 | train_loss 1.1331 | val_loss 1.1052 | train_acc 0.5965 | val_acc 0.6072 | lr 1.28e-04 | 0.5s\n",
      "epoch 006 | train_loss 1.1012 | val_loss 1.0816 | train_acc 0.6089 | val_acc 0.6098 | lr 1.28e-04 | 0.5s\n",
      "epoch 007 | train_loss 1.0806 | val_loss 1.0580 | train_acc 0.6102 | val_acc 0.6149 | lr 1.27e-04 | 0.5s\n",
      "epoch 008 | train_loss 1.0446 | val_loss 1.0561 | train_acc 0.6253 | val_acc 0.6068 | lr 1.27e-04 | 0.5s\n",
      "epoch 009 | train_loss 1.0274 | val_loss 1.0366 | train_acc 0.6298 | val_acc 0.6186 | lr 1.26e-04 | 0.5s\n",
      "epoch 010 | train_loss 0.9997 | val_loss 1.0188 | train_acc 0.6429 | val_acc 0.6260 | lr 1.26e-04 | 0.5s\n",
      "epoch 011 | train_loss 0.9755 | val_loss 1.0172 | train_acc 0.6463 | val_acc 0.6253 | lr 1.25e-04 | 0.5s\n",
      "epoch 012 | train_loss 0.9649 | val_loss 1.0127 | train_acc 0.6480 | val_acc 0.6212 | lr 1.24e-04 | 0.5s\n",
      "epoch 013 | train_loss 0.9492 | val_loss 1.0124 | train_acc 0.6522 | val_acc 0.6249 | lr 1.24e-04 | 0.5s\n",
      "epoch 014 | train_loss 0.9267 | val_loss 1.0040 | train_acc 0.6596 | val_acc 0.6323 | lr 1.23e-04 | 0.5s\n",
      "epoch 015 | train_loss 0.8998 | val_loss 1.0073 | train_acc 0.6794 | val_acc 0.6231 | lr 1.22e-04 | 0.5s\n",
      "epoch 016 | train_loss 0.8907 | val_loss 0.9991 | train_acc 0.6783 | val_acc 0.6301 | lr 1.21e-04 | 0.5s\n",
      "epoch 017 | train_loss 0.8779 | val_loss 1.0001 | train_acc 0.6809 | val_acc 0.6268 | lr 1.20e-04 | 0.5s\n",
      "epoch 018 | train_loss 0.8584 | val_loss 1.0088 | train_acc 0.6881 | val_acc 0.6264 | lr 1.19e-04 | 0.5s\n",
      "epoch 019 | train_loss 0.8484 | val_loss 0.9971 | train_acc 0.6892 | val_acc 0.6305 | lr 1.18e-04 | 0.5s\n",
      "epoch 020 | train_loss 0.8284 | val_loss 0.9948 | train_acc 0.7046 | val_acc 0.6293 | lr 1.17e-04 | 0.5s\n",
      "epoch 021 | train_loss 0.8146 | val_loss 0.9974 | train_acc 0.7067 | val_acc 0.6323 | lr 1.15e-04 | 0.5s\n",
      "epoch 022 | train_loss 0.7968 | val_loss 1.0086 | train_acc 0.7132 | val_acc 0.6286 | lr 1.14e-04 | 0.5s\n",
      "epoch 023 | train_loss 0.7924 | val_loss 1.0147 | train_acc 0.7101 | val_acc 0.6305 | lr 1.13e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.7752 | val_loss 1.0016 | train_acc 0.7179 | val_acc 0.6364 | lr 1.11e-04 | 0.5s\n",
      "epoch 025 | train_loss 0.7535 | val_loss 1.0121 | train_acc 0.7278 | val_acc 0.6341 | lr 1.10e-04 | 0.5s\n",
      "epoch 026 | train_loss 0.7404 | val_loss 1.0069 | train_acc 0.7327 | val_acc 0.6293 | lr 1.09e-04 | 0.5s\n",
      "epoch 027 | train_loss 0.7361 | val_loss 1.0130 | train_acc 0.7362 | val_acc 0.6338 | lr 1.07e-04 | 0.3s\n",
      "epoch 028 | train_loss 0.7126 | val_loss 1.0229 | train_acc 0.7415 | val_acc 0.6382 | lr 1.05e-04 | 0.3s\n",
      "epoch 029 | train_loss 0.7115 | val_loss 1.0354 | train_acc 0.7370 | val_acc 0.6301 | lr 1.04e-04 | 0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:27:54,378] Trial 89 finished with value: 0.994820498310013 and parameters: {'lr': 0.00012885472805442837, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 128, 'use_scheduler': True}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 030 | train_loss 0.6938 | val_loss 1.0199 | train_acc 0.7472 | val_acc 0.6353 | lr 1.02e-04 | 0.3s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5892 | val_loss 1.2912 | train_acc 0.4455 | val_acc 0.5621 | lr 1.13e-04 | 2.2s\n",
      "epoch 002 | train_loss 1.2729 | val_loss 1.1574 | train_acc 0.5506 | val_acc 0.5835 | lr 1.13e-04 | 1.2s\n",
      "epoch 003 | train_loss 1.1830 | val_loss 1.0853 | train_acc 0.5752 | val_acc 0.6098 | lr 1.13e-04 | 1.0s\n",
      "epoch 004 | train_loss 1.1388 | val_loss 1.0778 | train_acc 0.5902 | val_acc 0.6090 | lr 1.13e-04 | 1.0s\n",
      "epoch 005 | train_loss 1.0945 | val_loss 1.0430 | train_acc 0.6000 | val_acc 0.6186 | lr 1.13e-04 | 1.0s\n",
      "epoch 006 | train_loss 1.0692 | val_loss 1.0345 | train_acc 0.6119 | val_acc 0.6223 | lr 1.13e-04 | 0.7s\n",
      "epoch 007 | train_loss 1.0398 | val_loss 1.0140 | train_acc 0.6243 | val_acc 0.6253 | lr 1.13e-04 | 0.7s\n",
      "epoch 008 | train_loss 1.0152 | val_loss 1.0074 | train_acc 0.6305 | val_acc 0.6293 | lr 1.13e-04 | 0.7s\n",
      "epoch 009 | train_loss 0.9821 | val_loss 1.0148 | train_acc 0.6428 | val_acc 0.6245 | lr 1.13e-04 | 0.7s\n",
      "epoch 010 | train_loss 0.9692 | val_loss 1.0082 | train_acc 0.6504 | val_acc 0.6242 | lr 1.13e-04 | 0.7s\n",
      "epoch 011 | train_loss 0.9491 | val_loss 0.9901 | train_acc 0.6525 | val_acc 0.6338 | lr 1.13e-04 | 0.7s\n",
      "epoch 012 | train_loss 0.9195 | val_loss 1.0086 | train_acc 0.6652 | val_acc 0.6234 | lr 1.13e-04 | 0.7s\n",
      "epoch 013 | train_loss 0.9062 | val_loss 1.0037 | train_acc 0.6702 | val_acc 0.6216 | lr 1.13e-04 | 0.7s\n",
      "epoch 014 | train_loss 0.8902 | val_loss 0.9960 | train_acc 0.6771 | val_acc 0.6393 | lr 1.13e-04 | 0.7s\n",
      "epoch 015 | train_loss 0.8812 | val_loss 0.9892 | train_acc 0.6769 | val_acc 0.6356 | lr 1.13e-04 | 0.7s\n",
      "epoch 016 | train_loss 0.8578 | val_loss 0.9895 | train_acc 0.6877 | val_acc 0.6279 | lr 1.13e-04 | 0.7s\n",
      "epoch 017 | train_loss 0.8388 | val_loss 0.9923 | train_acc 0.6939 | val_acc 0.6419 | lr 1.13e-04 | 0.7s\n",
      "epoch 018 | train_loss 0.8301 | val_loss 0.9892 | train_acc 0.6990 | val_acc 0.6301 | lr 1.13e-04 | 0.7s\n",
      "epoch 019 | train_loss 0.8132 | val_loss 0.9909 | train_acc 0.6990 | val_acc 0.6423 | lr 1.13e-04 | 0.7s\n",
      "epoch 020 | train_loss 0.7957 | val_loss 0.9966 | train_acc 0.7069 | val_acc 0.6345 | lr 1.13e-04 | 0.7s\n",
      "epoch 021 | train_loss 0.7915 | val_loss 0.9981 | train_acc 0.7113 | val_acc 0.6334 | lr 1.13e-04 | 0.7s\n",
      "epoch 022 | train_loss 0.7614 | val_loss 1.0068 | train_acc 0.7231 | val_acc 0.6338 | lr 1.13e-04 | 0.7s\n",
      "epoch 023 | train_loss 0.7547 | val_loss 1.0137 | train_acc 0.7242 | val_acc 0.6364 | lr 1.13e-04 | 0.7s\n",
      "epoch 024 | train_loss 0.7351 | val_loss 1.0212 | train_acc 0.7334 | val_acc 0.6279 | lr 1.13e-04 | 0.7s\n",
      "epoch 025 | train_loss 0.7238 | val_loss 1.0084 | train_acc 0.7349 | val_acc 0.6426 | lr 1.13e-04 | 0.7s\n",
      "epoch 026 | train_loss 0.7078 | val_loss 1.0259 | train_acc 0.7418 | val_acc 0.6393 | lr 1.13e-04 | 0.7s\n",
      "epoch 027 | train_loss 0.7052 | val_loss 1.0213 | train_acc 0.7386 | val_acc 0.6390 | lr 1.13e-04 | 0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:28:16,208] Trial 90 finished with value: 0.9891789923397947 and parameters: {'lr': 0.00011309932051103808, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 028 | train_loss 0.6895 | val_loss 1.0331 | train_acc 0.7478 | val_acc 0.6268 | lr 1.13e-04 | 0.7s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6225 | val_loss 1.3320 | train_acc 0.4481 | val_acc 0.5673 | lr 1.45e-04 | 0.7s\n",
      "epoch 002 | train_loss 1.2992 | val_loss 1.1693 | train_acc 0.5480 | val_acc 0.5894 | lr 1.45e-04 | 0.7s\n",
      "epoch 003 | train_loss 1.2272 | val_loss 1.1147 | train_acc 0.5663 | val_acc 0.5998 | lr 1.45e-04 | 0.7s\n",
      "epoch 004 | train_loss 1.1650 | val_loss 1.0731 | train_acc 0.5821 | val_acc 0.6112 | lr 1.45e-04 | 0.7s\n",
      "epoch 005 | train_loss 1.1255 | val_loss 1.0519 | train_acc 0.5947 | val_acc 0.6153 | lr 1.45e-04 | 0.7s\n",
      "epoch 006 | train_loss 1.0971 | val_loss 1.0461 | train_acc 0.6002 | val_acc 0.6208 | lr 1.45e-04 | 0.7s\n",
      "epoch 007 | train_loss 1.0775 | val_loss 1.0216 | train_acc 0.6096 | val_acc 0.6297 | lr 1.45e-04 | 0.7s\n",
      "epoch 008 | train_loss 1.0509 | val_loss 1.0152 | train_acc 0.6160 | val_acc 0.6327 | lr 1.45e-04 | 0.7s\n",
      "epoch 009 | train_loss 1.0400 | val_loss 1.0153 | train_acc 0.6182 | val_acc 0.6227 | lr 1.45e-04 | 0.7s\n",
      "epoch 010 | train_loss 1.0126 | val_loss 1.0010 | train_acc 0.6296 | val_acc 0.6353 | lr 1.45e-04 | 0.7s\n",
      "epoch 011 | train_loss 1.0017 | val_loss 0.9966 | train_acc 0.6364 | val_acc 0.6349 | lr 1.45e-04 | 0.7s\n",
      "epoch 012 | train_loss 0.9810 | val_loss 0.9930 | train_acc 0.6412 | val_acc 0.6316 | lr 1.45e-04 | 0.7s\n",
      "epoch 013 | train_loss 0.9641 | val_loss 0.9901 | train_acc 0.6465 | val_acc 0.6390 | lr 1.45e-04 | 0.7s\n",
      "epoch 014 | train_loss 0.9454 | val_loss 1.0020 | train_acc 0.6571 | val_acc 0.6334 | lr 1.45e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9336 | val_loss 0.9920 | train_acc 0.6589 | val_acc 0.6367 | lr 1.45e-04 | 0.7s\n",
      "epoch 016 | train_loss 0.9215 | val_loss 0.9896 | train_acc 0.6596 | val_acc 0.6378 | lr 1.45e-04 | 0.7s\n",
      "epoch 017 | train_loss 0.9045 | val_loss 0.9924 | train_acc 0.6699 | val_acc 0.6356 | lr 1.45e-04 | 0.7s\n",
      "epoch 018 | train_loss 0.8957 | val_loss 0.9910 | train_acc 0.6725 | val_acc 0.6378 | lr 1.45e-04 | 0.7s\n",
      "epoch 019 | train_loss 0.8769 | val_loss 0.9925 | train_acc 0.6760 | val_acc 0.6412 | lr 1.45e-04 | 0.7s\n",
      "epoch 020 | train_loss 0.8464 | val_loss 0.9962 | train_acc 0.6880 | val_acc 0.6367 | lr 1.45e-04 | 0.8s\n",
      "epoch 021 | train_loss 0.8535 | val_loss 0.9968 | train_acc 0.6872 | val_acc 0.6305 | lr 1.45e-04 | 0.7s\n",
      "epoch 022 | train_loss 0.8402 | val_loss 1.0110 | train_acc 0.6895 | val_acc 0.6334 | lr 1.45e-04 | 0.7s\n",
      "epoch 023 | train_loss 0.8344 | val_loss 1.0136 | train_acc 0.6959 | val_acc 0.6275 | lr 1.45e-04 | 0.7s\n",
      "epoch 024 | train_loss 0.8234 | val_loss 0.9969 | train_acc 0.6949 | val_acc 0.6356 | lr 1.45e-04 | 0.7s\n",
      "epoch 025 | train_loss 0.8143 | val_loss 0.9964 | train_acc 0.7038 | val_acc 0.6308 | lr 1.45e-04 | 1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:28:33,776] Trial 91 finished with value: 0.9896310469175565 and parameters: {'lr': 0.0001452271136325534, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 026 | train_loss 0.7893 | val_loss 1.0128 | train_acc 0.7058 | val_acc 0.6375 | lr 1.45e-04 | 0.7s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6368 | val_loss 1.2994 | train_acc 0.4459 | val_acc 0.5643 | lr 1.11e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2883 | val_loss 1.1741 | train_acc 0.5459 | val_acc 0.5909 | lr 1.11e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1963 | val_loss 1.1266 | train_acc 0.5775 | val_acc 0.6027 | lr 1.11e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1485 | val_loss 1.0879 | train_acc 0.5868 | val_acc 0.6135 | lr 1.11e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1061 | val_loss 1.0733 | train_acc 0.6018 | val_acc 0.6157 | lr 1.11e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0778 | val_loss 1.0508 | train_acc 0.6145 | val_acc 0.6201 | lr 1.11e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0537 | val_loss 1.0353 | train_acc 0.6220 | val_acc 0.6245 | lr 1.11e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0293 | val_loss 1.0374 | train_acc 0.6280 | val_acc 0.6256 | lr 1.11e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0176 | val_loss 1.0252 | train_acc 0.6293 | val_acc 0.6286 | lr 1.11e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9983 | val_loss 1.0233 | train_acc 0.6405 | val_acc 0.6279 | lr 1.11e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9736 | val_loss 1.0102 | train_acc 0.6467 | val_acc 0.6305 | lr 1.11e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9528 | val_loss 1.0125 | train_acc 0.6568 | val_acc 0.6305 | lr 1.11e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.9420 | val_loss 1.0048 | train_acc 0.6596 | val_acc 0.6253 | lr 1.11e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9222 | val_loss 1.0053 | train_acc 0.6636 | val_acc 0.6319 | lr 1.11e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9161 | val_loss 1.0000 | train_acc 0.6642 | val_acc 0.6330 | lr 1.11e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8938 | val_loss 0.9961 | train_acc 0.6784 | val_acc 0.6378 | lr 1.11e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.8792 | val_loss 0.9936 | train_acc 0.6765 | val_acc 0.6301 | lr 1.11e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.8528 | val_loss 0.9965 | train_acc 0.6901 | val_acc 0.6353 | lr 1.11e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.8615 | val_loss 0.9961 | train_acc 0.6840 | val_acc 0.6312 | lr 1.11e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.8378 | val_loss 0.9870 | train_acc 0.6965 | val_acc 0.6441 | lr 1.11e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.8290 | val_loss 0.9936 | train_acc 0.7025 | val_acc 0.6404 | lr 1.11e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.8178 | val_loss 0.9938 | train_acc 0.7012 | val_acc 0.6430 | lr 1.11e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.7951 | val_loss 0.9860 | train_acc 0.7126 | val_acc 0.6341 | lr 1.11e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.7929 | val_loss 0.9921 | train_acc 0.7109 | val_acc 0.6338 | lr 1.11e-04 | 0.6s\n",
      "epoch 025 | train_loss 0.7814 | val_loss 0.9936 | train_acc 0.7114 | val_acc 0.6397 | lr 1.11e-04 | 0.6s\n",
      "epoch 026 | train_loss 0.7700 | val_loss 1.0059 | train_acc 0.7149 | val_acc 0.6323 | lr 1.11e-04 | 0.6s\n",
      "epoch 027 | train_loss 0.7485 | val_loss 1.0140 | train_acc 0.7312 | val_acc 0.6312 | lr 1.11e-04 | 0.6s\n",
      "epoch 028 | train_loss 0.7475 | val_loss 1.0056 | train_acc 0.7261 | val_acc 0.6438 | lr 1.11e-04 | 0.6s\n",
      "epoch 029 | train_loss 0.7404 | val_loss 1.0027 | train_acc 0.7305 | val_acc 0.6375 | lr 1.11e-04 | 0.6s\n",
      "epoch 030 | train_loss 0.7247 | val_loss 1.0051 | train_acc 0.7376 | val_acc 0.6478 | lr 1.11e-04 | 0.6s\n",
      "epoch 031 | train_loss 0.7189 | val_loss 1.0148 | train_acc 0.7363 | val_acc 0.6463 | lr 1.11e-04 | 0.6s\n",
      "epoch 032 | train_loss 0.7167 | val_loss 1.0161 | train_acc 0.7387 | val_acc 0.6327 | lr 1.11e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:28:52,449] Trial 92 finished with value: 0.9860155184182606 and parameters: {'lr': 0.00011120887120297369, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 033 | train_loss 0.6955 | val_loss 1.0092 | train_acc 0.7450 | val_acc 0.6426 | lr 1.11e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5936 | val_loss 1.2791 | train_acc 0.4593 | val_acc 0.5565 | lr 1.30e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2636 | val_loss 1.1585 | train_acc 0.5594 | val_acc 0.5876 | lr 1.30e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1778 | val_loss 1.1208 | train_acc 0.5811 | val_acc 0.5983 | lr 1.30e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1247 | val_loss 1.0836 | train_acc 0.5941 | val_acc 0.6131 | lr 1.30e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.0972 | val_loss 1.0579 | train_acc 0.6102 | val_acc 0.6208 | lr 1.30e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0628 | val_loss 1.0460 | train_acc 0.6144 | val_acc 0.6238 | lr 1.30e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0454 | val_loss 1.0341 | train_acc 0.6223 | val_acc 0.6264 | lr 1.30e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0117 | val_loss 1.0428 | train_acc 0.6380 | val_acc 0.6201 | lr 1.30e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.9827 | val_loss 1.0209 | train_acc 0.6477 | val_acc 0.6378 | lr 1.30e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9793 | val_loss 1.0121 | train_acc 0.6415 | val_acc 0.6382 | lr 1.30e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9562 | val_loss 1.0096 | train_acc 0.6528 | val_acc 0.6349 | lr 1.30e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9326 | val_loss 1.0050 | train_acc 0.6641 | val_acc 0.6371 | lr 1.30e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.9237 | val_loss 1.0063 | train_acc 0.6588 | val_acc 0.6397 | lr 1.30e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9044 | val_loss 1.0036 | train_acc 0.6651 | val_acc 0.6415 | lr 1.30e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.8888 | val_loss 0.9973 | train_acc 0.6788 | val_acc 0.6426 | lr 1.30e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8822 | val_loss 0.9937 | train_acc 0.6742 | val_acc 0.6419 | lr 1.30e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.8587 | val_loss 1.0128 | train_acc 0.6862 | val_acc 0.6286 | lr 1.30e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.8491 | val_loss 1.0070 | train_acc 0.6914 | val_acc 0.6364 | lr 1.30e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.8333 | val_loss 0.9898 | train_acc 0.6985 | val_acc 0.6456 | lr 1.30e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.8161 | val_loss 1.0024 | train_acc 0.7027 | val_acc 0.6426 | lr 1.30e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.8063 | val_loss 0.9979 | train_acc 0.7081 | val_acc 0.6434 | lr 1.30e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.7955 | val_loss 0.9958 | train_acc 0.7102 | val_acc 0.6415 | lr 1.30e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.7827 | val_loss 1.0088 | train_acc 0.7155 | val_acc 0.6434 | lr 1.30e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.7768 | val_loss 1.0123 | train_acc 0.7160 | val_acc 0.6360 | lr 1.30e-04 | 0.6s\n",
      "epoch 025 | train_loss 0.7563 | val_loss 0.9995 | train_acc 0.7208 | val_acc 0.6463 | lr 1.30e-04 | 0.6s\n",
      "epoch 026 | train_loss 0.7469 | val_loss 1.0129 | train_acc 0.7253 | val_acc 0.6364 | lr 1.30e-04 | 0.6s\n",
      "epoch 027 | train_loss 0.7321 | val_loss 1.0180 | train_acc 0.7336 | val_acc 0.6367 | lr 1.30e-04 | 0.6s\n",
      "epoch 028 | train_loss 0.7251 | val_loss 1.0142 | train_acc 0.7305 | val_acc 0.6386 | lr 1.30e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:29:08,861] Trial 93 finished with value: 0.9897792488226429 and parameters: {'lr': 0.00013002745537765516, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7120 | val_loss 1.0324 | train_acc 0.7424 | val_acc 0.6297 | lr 1.30e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6104 | val_loss 1.2998 | train_acc 0.4531 | val_acc 0.5625 | lr 1.10e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2908 | val_loss 1.1749 | train_acc 0.5452 | val_acc 0.5828 | lr 1.10e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1963 | val_loss 1.1213 | train_acc 0.5765 | val_acc 0.6024 | lr 1.10e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1475 | val_loss 1.0919 | train_acc 0.5878 | val_acc 0.6094 | lr 1.10e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1193 | val_loss 1.0641 | train_acc 0.5970 | val_acc 0.6164 | lr 1.10e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0888 | val_loss 1.0444 | train_acc 0.6101 | val_acc 0.6286 | lr 1.10e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0527 | val_loss 1.0369 | train_acc 0.6190 | val_acc 0.6205 | lr 1.10e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0281 | val_loss 1.0194 | train_acc 0.6306 | val_acc 0.6286 | lr 1.10e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0075 | val_loss 1.0178 | train_acc 0.6335 | val_acc 0.6312 | lr 1.10e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9917 | val_loss 1.0104 | train_acc 0.6411 | val_acc 0.6279 | lr 1.10e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9682 | val_loss 1.0064 | train_acc 0.6509 | val_acc 0.6312 | lr 1.10e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9497 | val_loss 1.0069 | train_acc 0.6584 | val_acc 0.6293 | lr 1.10e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.9385 | val_loss 1.0049 | train_acc 0.6593 | val_acc 0.6297 | lr 1.10e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9265 | val_loss 1.0007 | train_acc 0.6618 | val_acc 0.6312 | lr 1.10e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9030 | val_loss 0.9961 | train_acc 0.6738 | val_acc 0.6305 | lr 1.10e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8911 | val_loss 0.9958 | train_acc 0.6739 | val_acc 0.6327 | lr 1.10e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.8801 | val_loss 0.9986 | train_acc 0.6824 | val_acc 0.6293 | lr 1.10e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.8612 | val_loss 0.9962 | train_acc 0.6873 | val_acc 0.6364 | lr 1.10e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.8407 | val_loss 0.9964 | train_acc 0.6961 | val_acc 0.6316 | lr 1.10e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.8382 | val_loss 0.9906 | train_acc 0.6927 | val_acc 0.6316 | lr 1.10e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.8180 | val_loss 0.9905 | train_acc 0.7032 | val_acc 0.6275 | lr 1.10e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.8182 | val_loss 1.0005 | train_acc 0.7042 | val_acc 0.6367 | lr 1.10e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.7972 | val_loss 0.9981 | train_acc 0.7078 | val_acc 0.6364 | lr 1.10e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.7822 | val_loss 1.0099 | train_acc 0.7198 | val_acc 0.6367 | lr 1.10e-04 | 0.6s\n",
      "epoch 025 | train_loss 0.7859 | val_loss 0.9965 | train_acc 0.7128 | val_acc 0.6390 | lr 1.10e-04 | 0.6s\n",
      "epoch 026 | train_loss 0.7752 | val_loss 1.0079 | train_acc 0.7188 | val_acc 0.6449 | lr 1.10e-04 | 0.6s\n",
      "epoch 027 | train_loss 0.7619 | val_loss 0.9979 | train_acc 0.7234 | val_acc 0.6390 | lr 1.10e-04 | 0.6s\n",
      "epoch 028 | train_loss 0.7490 | val_loss 1.0066 | train_acc 0.7280 | val_acc 0.6323 | lr 1.10e-04 | 0.6s\n",
      "epoch 029 | train_loss 0.7302 | val_loss 1.0077 | train_acc 0.7305 | val_acc 0.6415 | lr 1.10e-04 | 0.6s\n",
      "epoch 030 | train_loss 0.7258 | val_loss 1.0041 | train_acc 0.7321 | val_acc 0.6430 | lr 1.10e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:29:26,332] Trial 94 finished with value: 0.9904722161233117 and parameters: {'lr': 0.00010988975918576535, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 031 | train_loss 0.7205 | val_loss 1.0116 | train_acc 0.7379 | val_acc 0.6345 | lr 1.10e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5252 | val_loss 1.2273 | train_acc 0.4814 | val_acc 0.5824 | lr 1.67e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2365 | val_loss 1.1229 | train_acc 0.5623 | val_acc 0.6050 | lr 1.67e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1599 | val_loss 1.0809 | train_acc 0.5824 | val_acc 0.6153 | lr 1.67e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1132 | val_loss 1.0577 | train_acc 0.6018 | val_acc 0.6212 | lr 1.67e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.0706 | val_loss 1.0456 | train_acc 0.6092 | val_acc 0.6234 | lr 1.67e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0424 | val_loss 1.0223 | train_acc 0.6230 | val_acc 0.6282 | lr 1.67e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0106 | val_loss 1.0300 | train_acc 0.6338 | val_acc 0.6275 | lr 1.67e-04 | 0.6s\n",
      "epoch 008 | train_loss 0.9942 | val_loss 1.0103 | train_acc 0.6361 | val_acc 0.6301 | lr 1.67e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.9646 | val_loss 1.0137 | train_acc 0.6507 | val_acc 0.6316 | lr 1.67e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9480 | val_loss 1.0218 | train_acc 0.6547 | val_acc 0.6334 | lr 1.67e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9290 | val_loss 1.0235 | train_acc 0.6640 | val_acc 0.6279 | lr 1.67e-04 | 0.6s\n",
      "epoch 012 | train_loss 0.9037 | val_loss 1.0111 | train_acc 0.6665 | val_acc 0.6308 | lr 1.67e-04 | 0.6s\n",
      "epoch 013 | train_loss 0.8898 | val_loss 1.0025 | train_acc 0.6769 | val_acc 0.6404 | lr 1.67e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.8680 | val_loss 1.0067 | train_acc 0.6816 | val_acc 0.6367 | lr 1.67e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.8580 | val_loss 0.9962 | train_acc 0.6888 | val_acc 0.6349 | lr 1.67e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.8338 | val_loss 1.0055 | train_acc 0.6941 | val_acc 0.6349 | lr 1.67e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.8325 | val_loss 1.0058 | train_acc 0.6938 | val_acc 0.6353 | lr 1.67e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.8055 | val_loss 1.0145 | train_acc 0.7038 | val_acc 0.6349 | lr 1.67e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.7904 | val_loss 1.0147 | train_acc 0.7143 | val_acc 0.6452 | lr 1.67e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.7686 | val_loss 1.0086 | train_acc 0.7225 | val_acc 0.6334 | lr 1.67e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.7606 | val_loss 1.0043 | train_acc 0.7180 | val_acc 0.6367 | lr 1.67e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.7482 | val_loss 1.0242 | train_acc 0.7272 | val_acc 0.6271 | lr 1.67e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.7388 | val_loss 1.0248 | train_acc 0.7311 | val_acc 0.6353 | lr 1.67e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.7263 | val_loss 1.0160 | train_acc 0.7302 | val_acc 0.6430 | lr 1.67e-04 | 1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:29:42,568] Trial 95 finished with value: 0.9961925561747019 and parameters: {'lr': 0.00016722029601337103, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 025 | train_loss 0.7125 | val_loss 1.0505 | train_acc 0.7402 | val_acc 0.6234 | lr 1.67e-04 | 1.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.6750 | val_loss 1.3523 | train_acc 0.4455 | val_acc 0.5451 | lr 1.55e-04 | 1.3s\n",
      "epoch 002 | train_loss 1.3415 | val_loss 1.2104 | train_acc 0.5324 | val_acc 0.5798 | lr 1.55e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.2481 | val_loss 1.1658 | train_acc 0.5624 | val_acc 0.5854 | lr 1.55e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.2000 | val_loss 1.1127 | train_acc 0.5753 | val_acc 0.6061 | lr 1.55e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1643 | val_loss 1.0869 | train_acc 0.5877 | val_acc 0.6131 | lr 1.55e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.1432 | val_loss 1.0775 | train_acc 0.5876 | val_acc 0.6120 | lr 1.55e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.1105 | val_loss 1.0595 | train_acc 0.6028 | val_acc 0.6138 | lr 1.55e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0900 | val_loss 1.0517 | train_acc 0.6037 | val_acc 0.6201 | lr 1.55e-04 | 0.6s\n",
      "epoch 009 | train_loss 1.0696 | val_loss 1.0440 | train_acc 0.6122 | val_acc 0.6231 | lr 1.55e-04 | 0.6s\n",
      "epoch 010 | train_loss 1.0549 | val_loss 1.0379 | train_acc 0.6188 | val_acc 0.6194 | lr 1.55e-04 | 0.6s\n",
      "epoch 011 | train_loss 1.0447 | val_loss 1.0406 | train_acc 0.6200 | val_acc 0.6183 | lr 1.55e-04 | 0.6s\n",
      "epoch 012 | train_loss 1.0333 | val_loss 1.0255 | train_acc 0.6290 | val_acc 0.6268 | lr 1.55e-04 | 0.6s\n",
      "epoch 013 | train_loss 1.0089 | val_loss 1.0326 | train_acc 0.6315 | val_acc 0.6205 | lr 1.55e-04 | 0.6s\n",
      "epoch 014 | train_loss 0.9966 | val_loss 1.0291 | train_acc 0.6361 | val_acc 0.6238 | lr 1.55e-04 | 0.6s\n",
      "epoch 015 | train_loss 0.9786 | val_loss 1.0207 | train_acc 0.6465 | val_acc 0.6260 | lr 1.55e-04 | 0.6s\n",
      "epoch 016 | train_loss 0.9751 | val_loss 1.0121 | train_acc 0.6480 | val_acc 0.6301 | lr 1.55e-04 | 0.6s\n",
      "epoch 017 | train_loss 0.9567 | val_loss 1.0226 | train_acc 0.6541 | val_acc 0.6256 | lr 1.55e-04 | 0.6s\n",
      "epoch 018 | train_loss 0.9528 | val_loss 1.0174 | train_acc 0.6496 | val_acc 0.6238 | lr 1.55e-04 | 0.6s\n",
      "epoch 019 | train_loss 0.9409 | val_loss 1.0127 | train_acc 0.6579 | val_acc 0.6279 | lr 1.55e-04 | 0.6s\n",
      "epoch 020 | train_loss 0.9291 | val_loss 1.0145 | train_acc 0.6603 | val_acc 0.6301 | lr 1.55e-04 | 0.6s\n",
      "epoch 021 | train_loss 0.9184 | val_loss 1.0059 | train_acc 0.6644 | val_acc 0.6323 | lr 1.55e-04 | 0.6s\n",
      "epoch 022 | train_loss 0.9039 | val_loss 1.0059 | train_acc 0.6665 | val_acc 0.6271 | lr 1.55e-04 | 0.6s\n",
      "epoch 023 | train_loss 0.9157 | val_loss 1.0108 | train_acc 0.6707 | val_acc 0.6216 | lr 1.55e-04 | 0.6s\n",
      "epoch 024 | train_loss 0.8953 | val_loss 1.0142 | train_acc 0.6728 | val_acc 0.6231 | lr 1.55e-04 | 0.6s\n",
      "epoch 025 | train_loss 0.8889 | val_loss 1.0052 | train_acc 0.6754 | val_acc 0.6319 | lr 1.55e-04 | 0.6s\n",
      "epoch 026 | train_loss 0.8838 | val_loss 1.0131 | train_acc 0.6765 | val_acc 0.6290 | lr 1.55e-04 | 0.6s\n",
      "epoch 027 | train_loss 0.8743 | val_loss 1.0147 | train_acc 0.6819 | val_acc 0.6256 | lr 1.55e-04 | 0.6s\n",
      "epoch 028 | train_loss 0.8541 | val_loss 1.0069 | train_acc 0.6897 | val_acc 0.6308 | lr 1.55e-04 | 0.6s\n",
      "epoch 029 | train_loss 0.8539 | val_loss 1.0053 | train_acc 0.6903 | val_acc 0.6275 | lr 1.55e-04 | 0.6s\n",
      "epoch 030 | train_loss 0.8465 | val_loss 1.0196 | train_acc 0.6913 | val_acc 0.6249 | lr 1.55e-04 | 0.6s\n",
      "epoch 031 | train_loss 0.8398 | val_loss 1.0118 | train_acc 0.6936 | val_acc 0.6323 | lr 1.55e-04 | 0.6s\n",
      "epoch 032 | train_loss 0.8407 | val_loss 1.0218 | train_acc 0.6917 | val_acc 0.6190 | lr 1.55e-04 | 0.6s\n",
      "epoch 033 | train_loss 0.8300 | val_loss 1.0125 | train_acc 0.6969 | val_acc 0.6264 | lr 1.55e-04 | 0.6s\n",
      "epoch 034 | train_loss 0.8234 | val_loss 1.0210 | train_acc 0.6982 | val_acc 0.6208 | lr 1.55e-04 | 0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:30:02,917] Trial 96 finished with value: 1.0051903603082222 and parameters: {'lr': 0.00015518358395539384, 'num_layers': 2, 'hidden_width': 128, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 035 | train_loss 0.8156 | val_loss 1.0278 | train_acc 0.7011 | val_acc 0.6201 | lr 1.55e-04 | 0.6s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.5793 | val_loss 1.2858 | train_acc 0.4610 | val_acc 0.5628 | lr 1.23e-04 | 0.6s\n",
      "epoch 002 | train_loss 1.2777 | val_loss 1.1690 | train_acc 0.5510 | val_acc 0.5931 | lr 1.23e-04 | 0.6s\n",
      "epoch 003 | train_loss 1.1924 | val_loss 1.1121 | train_acc 0.5747 | val_acc 0.5976 | lr 1.23e-04 | 0.6s\n",
      "epoch 004 | train_loss 1.1446 | val_loss 1.0756 | train_acc 0.5969 | val_acc 0.6120 | lr 1.23e-04 | 0.6s\n",
      "epoch 005 | train_loss 1.1028 | val_loss 1.0629 | train_acc 0.6052 | val_acc 0.6123 | lr 1.23e-04 | 0.6s\n",
      "epoch 006 | train_loss 1.0745 | val_loss 1.0520 | train_acc 0.6129 | val_acc 0.6171 | lr 1.23e-04 | 0.6s\n",
      "epoch 007 | train_loss 1.0449 | val_loss 1.0479 | train_acc 0.6217 | val_acc 0.6245 | lr 1.23e-04 | 0.6s\n",
      "epoch 008 | train_loss 1.0197 | val_loss 1.0316 | train_acc 0.6312 | val_acc 0.6220 | lr 1.23e-04 | 0.6s\n",
      "epoch 009 | train_loss 0.9942 | val_loss 1.0245 | train_acc 0.6446 | val_acc 0.6231 | lr 1.23e-04 | 0.6s\n",
      "epoch 010 | train_loss 0.9788 | val_loss 1.0118 | train_acc 0.6437 | val_acc 0.6271 | lr 1.23e-04 | 0.6s\n",
      "epoch 011 | train_loss 0.9589 | val_loss 1.0219 | train_acc 0.6526 | val_acc 0.6212 | lr 1.23e-04 | 1.7s\n",
      "epoch 012 | train_loss 0.9495 | val_loss 1.0111 | train_acc 0.6541 | val_acc 0.6286 | lr 1.23e-04 | 1.7s\n",
      "epoch 013 | train_loss 0.9184 | val_loss 1.0035 | train_acc 0.6648 | val_acc 0.6286 | lr 1.23e-04 | 1.7s\n",
      "epoch 014 | train_loss 0.9017 | val_loss 1.0102 | train_acc 0.6672 | val_acc 0.6305 | lr 1.23e-04 | 1.7s\n",
      "epoch 015 | train_loss 0.9003 | val_loss 1.0016 | train_acc 0.6723 | val_acc 0.6349 | lr 1.23e-04 | 1.7s\n",
      "epoch 016 | train_loss 0.8793 | val_loss 1.0029 | train_acc 0.6736 | val_acc 0.6397 | lr 1.23e-04 | 1.7s\n",
      "epoch 017 | train_loss 0.8610 | val_loss 0.9958 | train_acc 0.6817 | val_acc 0.6345 | lr 1.23e-04 | 1.7s\n",
      "epoch 018 | train_loss 0.8529 | val_loss 0.9995 | train_acc 0.6891 | val_acc 0.6327 | lr 1.23e-04 | 1.7s\n",
      "epoch 019 | train_loss 0.8360 | val_loss 0.9889 | train_acc 0.6967 | val_acc 0.6404 | lr 1.23e-04 | 1.7s\n",
      "epoch 020 | train_loss 0.8271 | val_loss 1.0059 | train_acc 0.6970 | val_acc 0.6360 | lr 1.23e-04 | 1.7s\n",
      "epoch 021 | train_loss 0.8108 | val_loss 1.0072 | train_acc 0.7075 | val_acc 0.6323 | lr 1.23e-04 | 1.7s\n",
      "epoch 022 | train_loss 0.7924 | val_loss 0.9946 | train_acc 0.7103 | val_acc 0.6445 | lr 1.23e-04 | 1.7s\n",
      "epoch 023 | train_loss 0.7951 | val_loss 1.0040 | train_acc 0.7094 | val_acc 0.6364 | lr 1.23e-04 | 1.7s\n",
      "epoch 024 | train_loss 0.7730 | val_loss 1.0061 | train_acc 0.7179 | val_acc 0.6316 | lr 1.23e-04 | 1.7s\n",
      "epoch 025 | train_loss 0.7701 | val_loss 1.0079 | train_acc 0.7156 | val_acc 0.6375 | lr 1.23e-04 | 1.8s\n",
      "epoch 026 | train_loss 0.7437 | val_loss 1.0084 | train_acc 0.7253 | val_acc 0.6371 | lr 1.23e-04 | 1.7s\n",
      "epoch 027 | train_loss 0.7446 | val_loss 1.0345 | train_acc 0.7256 | val_acc 0.6264 | lr 1.23e-04 | 1.7s\n",
      "epoch 028 | train_loss 0.7297 | val_loss 1.0283 | train_acc 0.7336 | val_acc 0.6305 | lr 1.23e-04 | 1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:30:40,869] Trial 97 finished with value: 0.9889418903493211 and parameters: {'lr': 0.00012252170276460722, 'num_layers': 2, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 029 | train_loss 0.7236 | val_loss 1.0132 | train_acc 0.7346 | val_acc 0.6404 | lr 1.23e-04 | 1.7s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.3516 | val_loss 1.7440 | train_acc 0.5233 | val_acc 0.5329 | lr 5.78e-03 | 0.6s\n",
      "epoch 002 | train_loss 1.1578 | val_loss 1.4424 | train_acc 0.5754 | val_acc 0.4989 | lr 5.78e-03 | 0.6s\n",
      "epoch 003 | train_loss 1.0932 | val_loss 1.1402 | train_acc 0.6032 | val_acc 0.5942 | lr 5.78e-03 | 0.6s\n",
      "epoch 004 | train_loss 1.0429 | val_loss 1.0591 | train_acc 0.6130 | val_acc 0.6171 | lr 5.78e-03 | 0.5s\n",
      "epoch 005 | train_loss 1.0032 | val_loss 1.1044 | train_acc 0.6280 | val_acc 0.6038 | lr 5.78e-03 | 0.6s\n",
      "epoch 006 | train_loss 0.9900 | val_loss 1.1211 | train_acc 0.6334 | val_acc 0.5861 | lr 5.78e-03 | 0.5s\n",
      "epoch 007 | train_loss 0.9423 | val_loss 1.0570 | train_acc 0.6513 | val_acc 0.6075 | lr 5.78e-03 | 0.6s\n",
      "epoch 008 | train_loss 0.9330 | val_loss 1.0825 | train_acc 0.6539 | val_acc 0.6027 | lr 5.78e-03 | 0.5s\n",
      "epoch 009 | train_loss 0.9139 | val_loss 1.0563 | train_acc 0.6635 | val_acc 0.6253 | lr 5.78e-03 | 0.6s\n",
      "epoch 010 | train_loss 0.8830 | val_loss 1.0798 | train_acc 0.6731 | val_acc 0.6061 | lr 5.78e-03 | 0.5s\n",
      "epoch 011 | train_loss 0.8726 | val_loss 1.0983 | train_acc 0.6787 | val_acc 0.6149 | lr 5.78e-03 | 0.5s\n",
      "epoch 012 | train_loss 0.8509 | val_loss 1.1061 | train_acc 0.6889 | val_acc 0.5994 | lr 5.78e-03 | 0.6s\n",
      "epoch 013 | train_loss 0.8309 | val_loss 1.0690 | train_acc 0.6890 | val_acc 0.6135 | lr 5.78e-03 | 0.6s\n",
      "epoch 014 | train_loss 0.8168 | val_loss 1.1128 | train_acc 0.6912 | val_acc 0.5961 | lr 5.78e-03 | 0.6s\n",
      "epoch 015 | train_loss 0.8056 | val_loss 1.0645 | train_acc 0.7028 | val_acc 0.6227 | lr 5.78e-03 | 0.6s\n",
      "epoch 016 | train_loss 0.7888 | val_loss 1.1130 | train_acc 0.7118 | val_acc 0.6131 | lr 5.78e-03 | 0.6s\n",
      "epoch 017 | train_loss 0.7893 | val_loss 1.1221 | train_acc 0.7102 | val_acc 0.6293 | lr 5.78e-03 | 0.6s\n",
      "epoch 018 | train_loss 0.7656 | val_loss 1.0748 | train_acc 0.7215 | val_acc 0.6345 | lr 5.78e-03 | 0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:30:51,929] Trial 98 finished with value: 1.0563280605335899 and parameters: {'lr': 0.0057804908923273345, 'num_layers': 3, 'hidden_width': 512, 'batch_size': 128, 'use_scheduler': False}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 019 | train_loss 0.7567 | val_loss 1.0743 | train_acc 0.7224 | val_acc 0.6275 | lr 5.78e-03 | 0.5s\n",
      "Early stopping\n",
      "epoch 001 | train_loss 1.7338 | val_loss 1.4338 | train_acc 0.4098 | val_acc 0.5443 | lr 1.02e-04 | 2.2s\n",
      "epoch 002 | train_loss 1.3855 | val_loss 1.2521 | train_acc 0.5136 | val_acc 0.5661 | lr 1.02e-04 | 2.1s\n",
      "epoch 003 | train_loss 1.2833 | val_loss 1.1697 | train_acc 0.5539 | val_acc 0.5887 | lr 1.02e-04 | 2.1s\n",
      "epoch 004 | train_loss 1.2174 | val_loss 1.1281 | train_acc 0.5632 | val_acc 0.6024 | lr 1.02e-04 | 2.1s\n",
      "epoch 005 | train_loss 1.1771 | val_loss 1.1001 | train_acc 0.5792 | val_acc 0.6072 | lr 1.01e-04 | 2.1s\n",
      "epoch 006 | train_loss 1.1471 | val_loss 1.0821 | train_acc 0.5865 | val_acc 0.6079 | lr 1.01e-04 | 2.1s\n",
      "epoch 007 | train_loss 1.1240 | val_loss 1.0613 | train_acc 0.5987 | val_acc 0.6201 | lr 1.01e-04 | 2.1s\n",
      "epoch 008 | train_loss 1.0957 | val_loss 1.0452 | train_acc 0.6047 | val_acc 0.6208 | lr 1.00e-04 | 2.1s\n",
      "epoch 009 | train_loss 1.0867 | val_loss 1.0310 | train_acc 0.6066 | val_acc 0.6290 | lr 1.00e-04 | 2.1s\n",
      "epoch 010 | train_loss 1.0570 | val_loss 1.0271 | train_acc 0.6151 | val_acc 0.6316 | lr 9.96e-05 | 2.1s\n",
      "epoch 011 | train_loss 1.0473 | val_loss 1.0304 | train_acc 0.6203 | val_acc 0.6334 | lr 9.91e-05 | 2.1s\n",
      "epoch 012 | train_loss 1.0211 | val_loss 1.0246 | train_acc 0.6242 | val_acc 0.6323 | lr 9.85e-05 | 2.1s\n",
      "epoch 013 | train_loss 1.0093 | val_loss 1.0146 | train_acc 0.6344 | val_acc 0.6349 | lr 9.79e-05 | 2.1s\n",
      "epoch 014 | train_loss 0.9816 | val_loss 1.0116 | train_acc 0.6468 | val_acc 0.6364 | lr 9.72e-05 | 2.1s\n",
      "epoch 015 | train_loss 0.9735 | val_loss 0.9973 | train_acc 0.6464 | val_acc 0.6412 | lr 9.65e-05 | 2.1s\n",
      "epoch 016 | train_loss 0.9626 | val_loss 1.0021 | train_acc 0.6539 | val_acc 0.6360 | lr 9.58e-05 | 2.1s\n",
      "epoch 017 | train_loss 0.9573 | val_loss 0.9975 | train_acc 0.6512 | val_acc 0.6404 | lr 9.50e-05 | 2.1s\n",
      "epoch 018 | train_loss 0.9427 | val_loss 1.0005 | train_acc 0.6527 | val_acc 0.6401 | lr 9.41e-05 | 2.1s\n",
      "epoch 019 | train_loss 0.9127 | val_loss 1.0038 | train_acc 0.6644 | val_acc 0.6412 | lr 9.33e-05 | 2.1s\n",
      "epoch 020 | train_loss 0.9161 | val_loss 0.9918 | train_acc 0.6679 | val_acc 0.6426 | lr 9.23e-05 | 2.1s\n",
      "epoch 021 | train_loss 0.8982 | val_loss 0.9964 | train_acc 0.6732 | val_acc 0.6423 | lr 9.14e-05 | 2.1s\n",
      "epoch 022 | train_loss 0.8927 | val_loss 0.9994 | train_acc 0.6767 | val_acc 0.6397 | lr 9.04e-05 | 2.1s\n",
      "epoch 023 | train_loss 0.8826 | val_loss 0.9936 | train_acc 0.6749 | val_acc 0.6404 | lr 8.93e-05 | 2.1s\n",
      "epoch 024 | train_loss 0.8731 | val_loss 0.9960 | train_acc 0.6812 | val_acc 0.6378 | lr 8.83e-05 | 2.1s\n",
      "epoch 025 | train_loss 0.8557 | val_loss 0.9899 | train_acc 0.6888 | val_acc 0.6460 | lr 8.71e-05 | 2.1s\n",
      "epoch 026 | train_loss 0.8517 | val_loss 0.9957 | train_acc 0.6884 | val_acc 0.6438 | lr 8.60e-05 | 2.1s\n",
      "epoch 027 | train_loss 0.8349 | val_loss 0.9957 | train_acc 0.6966 | val_acc 0.6438 | lr 8.48e-05 | 2.1s\n",
      "epoch 028 | train_loss 0.8396 | val_loss 1.0012 | train_acc 0.6935 | val_acc 0.6393 | lr 8.36e-05 | 2.1s\n",
      "epoch 029 | train_loss 0.8143 | val_loss 0.9933 | train_acc 0.7026 | val_acc 0.6460 | lr 8.23e-05 | 2.1s\n",
      "epoch 030 | train_loss 0.8083 | val_loss 1.0006 | train_acc 0.7048 | val_acc 0.6434 | lr 8.10e-05 | 2.1s\n",
      "epoch 031 | train_loss 0.8078 | val_loss 1.0093 | train_acc 0.7083 | val_acc 0.6412 | lr 7.97e-05 | 2.1s\n",
      "epoch 032 | train_loss 0.7865 | val_loss 0.9944 | train_acc 0.7177 | val_acc 0.6434 | lr 7.84e-05 | 2.1s\n",
      "epoch 033 | train_loss 0.7872 | val_loss 1.0094 | train_acc 0.7103 | val_acc 0.6430 | lr 7.70e-05 | 2.1s\n",
      "epoch 034 | train_loss 0.7837 | val_loss 0.9978 | train_acc 0.7134 | val_acc 0.6471 | lr 7.56e-05 | 2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 18:32:06,262] Trial 99 finished with value: 0.9899065764145947 and parameters: {'lr': 0.00010209020143235037, 'num_layers': 3, 'hidden_width': 256, 'batch_size': 32, 'use_scheduler': True}. Best is trial 82 with value: 0.9813379565610414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 035 | train_loss 0.7692 | val_loss 1.0045 | train_acc 0.7213 | val_acc 0.6438 | lr 7.42e-05 | 2.1s\n",
      "Early stopping\n",
      "{'best_val_loss': 0.9813379565610414, 'params': {'lr': 0.0001149883682760068, 'num_layers': 3, 'hidden_width': 384, 'batch_size': 32, 'use_scheduler': False}, 'trial_number': 82}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\n",
    "    \"<style>\"\n",
    "    \"div.output_scroll { max-height: 200px !important; overflow: auto; }\"\n",
    "    \"</style>\"\n",
    "))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = HyperConfig()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # Load pre‑extracted features (change paths if needed)\n",
    "    train_data = torch.load(\"train_dinov2_feats.pt\")\n",
    "    val_data = torch.load(\"val_dinov2_feats.pt\")\n",
    "    X_train, y_train = train_data[\"features\"], train_data[\"labels\"]\n",
    "    X_val, y_val = val_data[\"features\"], val_data[\"labels\"]\n",
    "\n",
    "    search = ASHASearch((X_train, y_train), (X_val, y_val), cfg, use_pruning=False, # Without pruning so I can plot everything\n",
    "                         base_dir=\"runs/asha\")\n",
    "    print(search.run(n_trials=100, timeout=3600 * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6a0c40",
   "metadata": {},
   "source": [
    "### Reporting: \n",
    "1. In your notebook, provide a focused explanation of your hyper-parameter\n",
    "tuning strategy. \n",
    "\n",
    "My approach will be to use a bandit-based method that parallelizes and automatizes the guided search strategy proposed in the instructions, making it more effective and spending less computation in settings that are sub-optimal. The chosen algorithm is \"Asynchronous Successive Halving (ASHA)\", which fixes a resource budget (Epochs) to each hyperparameter configuration (in a continuous or discrete search space depending on which hyperparameter) and then halves that budget for suboptimal trials, allocating them to more promising ones (even pruning them out within a trial). The variable that we aim to optimize is the val-loss to be able to fit for generalizability and not overfit. Another reason why the ASHA approach is superior to the one proposed before is that it doesn't assume independence between hyperparameters, i.e. it works even if there are interaction effects among them that make holding one parameter fixed while adjusting the others unfeasible as an approach.\n",
    "\n",
    "\n",
    "2. Detail your experiments for Learning Rate and MLP Architecture. Show\n",
    "plots (validation loss/accuracy) comparing different LRs and architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b4d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "runs_dir = pathlib.Path(\"runs/asha\")\n",
    "study = search.study\n",
    "\n",
    "# Aggregate\n",
    "records = []\n",
    "for trial in study.trials:\n",
    "    trial_dir = runs_dir / f\"trial_{trial.number:04d}\"\n",
    "    metrics_path = trial_dir / \"metrics.csv\"\n",
    "    if not metrics_path.exists():\n",
    "        continue\n",
    "    metrics = pd.read_csv(metrics_path)\n",
    "    best = metrics.loc[metrics[\"val_loss\"].idxmin()]\n",
    "    records.append({\n",
    "        \"trial\": trial.number,\n",
    "        \"lr\": trial.params.get(\"lr\"),\n",
    "        \"hidden_width\": trial.params.get(\"hidden_width\"),\n",
    "        \"num_layers\": trial.params.get(\"num_layers\"),\n",
    "        \"val_loss\": best[\"val_loss\"],\n",
    "        \"val_acc\": best[\"val_acc\"],\n",
    "        \"trial\": trial.number,\n",
    "        \"use_scheduler\": trial.params.get(\"use_scheduler\"),\n",
    "        \"batch_size\": trial.params.get(\"batch_size\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# grid of plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Learning Rate vs Validation Accuracy\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(df[\"lr\"], df[\"val_acc\"], alpha=0.7)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Learning Rate\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"LR vs Val Accuracy\")\n",
    "\n",
    "# Learning Rate vs Validation Loss\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(df[\"lr\"], df[\"val_loss\"], alpha=0.7)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Learning Rate\")\n",
    "ax.set_ylabel(\"Validation Loss\")\n",
    "ax.set_title(\"LR vs Val Loss\")\n",
    "\n",
    "# Hidden Width vs Validation Accuracy (per layers)\n",
    "ax = axes[1, 0]\n",
    "for nl in sorted(df[\"num_layers\"].unique()):\n",
    "    subset = df[df[\"num_layers\"] == nl]\n",
    "    ax.scatter(\n",
    "        subset[\"hidden_width\"],\n",
    "        subset[\"val_acc\"],\n",
    "        label=f\"{nl} layer{'s' if nl > 1 else ''}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "ax.set_xlabel(\"Hidden Layer Width\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Architecture vs Val Accuracy\")\n",
    "ax.legend()\n",
    "\n",
    "# Hidden Width vs Validation Loss (per layers)\n",
    "ax = axes[1, 1]\n",
    "for nl in sorted(df[\"num_layers\"].unique()):\n",
    "    subset = df[df[\"num_layers\"] == nl]\n",
    "    ax.scatter(\n",
    "        subset[\"hidden_width\"],\n",
    "        subset[\"val_loss\"],\n",
    "        label=f\"{nl} layer{'s' if nl > 1 else ''}\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "ax.set_xlabel(\"Hidden Layer Width\")\n",
    "ax.set_ylabel(\"Validation Loss\")\n",
    "ax.set_title(\"Architecture vs Val Loss\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa7ca11",
   "metadata": {},
   "source": [
    "We can see in the upper plots that smaller learning rates lead to better general performance but also more variance in that performance. On the other hand, we can see that 3 layer deep architectures with 384 neurons lead to the lowest validation loss values. 1 layer architectures with 256 or 768 neurons also peak for best accuracies. However, those architectures also show big variance in their values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e163b",
   "metadata": {},
   "source": [
    "3. Briefly discuss your findings for batch size and the impact of the LR\n",
    "scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9693a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average metrics by batch size (mean ± std):\n",
      "batch_size  val_acc          val_loss         \n",
      "               mean      std     mean      std\n",
      "        32 0.637579 0.007565 0.996475 0.015176\n",
      "        64 0.635563 0.004106 1.004815 0.011520\n",
      "       128 0.635927 0.006704 1.003427 0.018106\n",
      "\n",
      "Average metrics by scheduler usage (mean ± std):\n",
      "use_scheduler  val_acc          val_loss         \n",
      "                  mean      std     mean      std\n",
      "        False 0.637497 0.007183 0.996714 0.015086\n",
      "         True 0.635403 0.006524 1.005881 0.016012\n",
      "\n",
      "T-test (val_acc) scheduler vs no scheduler: t = -1.354, p = 0.182\n",
      "T-test (val_loss) scheduler vs no scheduler: t = 2.515, p = 0.016\n",
      "\n",
      "Batch size 32 vs 64 (val_acc): t = 1.337, p = 0.192\n",
      "Batch size 32 vs 64 (val_loss): t = -2.186, p = 0.042\n",
      "\n",
      "Batch size 32 vs 128 (val_acc): t = 0.968, p = 0.339\n",
      "Batch size 32 vs 128 (val_loss): t = -1.621, p = 0.115\n",
      "\n",
      "Batch size 64 vs 128 (val_acc): t = -0.196, p = 0.846\n",
      "Batch size 64 vs 128 (val_loss): t = 0.272, p = 0.787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import itertools\n",
    "\n",
    "# 1. Summary statistics\n",
    "batch_stats = df.groupby(\"batch_size\")[[\"val_acc\", \"val_loss\"]].agg(['mean', 'std']).reset_index()\n",
    "scheduler_stats = df.groupby(\"use_scheduler\")[[\"val_acc\", \"val_loss\"]].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "print(\"\\nAverage metrics by batch size (mean ± std):\")\n",
    "print(batch_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\nAverage metrics by scheduler usage (mean ± std):\")\n",
    "print(scheduler_stats.to_string(index=False))\n",
    "\n",
    "# 2. T-test: scheduler vs no scheduler\n",
    "acc_sched = df[df[\"use_scheduler\"] == True][\"val_acc\"]\n",
    "acc_nosched = df[df[\"use_scheduler\"] == False][\"val_acc\"]\n",
    "loss_sched = df[df[\"use_scheduler\"] == True][\"val_loss\"]\n",
    "loss_nosched = df[df[\"use_scheduler\"] == False][\"val_loss\"]\n",
    "\n",
    "t_acc_s, p_acc_s = ttest_ind(acc_sched, acc_nosched, equal_var=False)\n",
    "t_loss_s, p_loss_s = ttest_ind(loss_sched, loss_nosched, equal_var=False)\n",
    "\n",
    "print(f\"\\nT-test (val_acc) scheduler vs no scheduler: t = {t_acc_s:.3f}, p = {p_acc_s:.3f}\")\n",
    "print(f\"T-test (val_loss) scheduler vs no scheduler: t = {t_loss_s:.3f}, p = {p_loss_s:.3f}\")\n",
    "\n",
    "# 3. T-tests between batch sizes\n",
    "batch_sizes = sorted(df[\"batch_size\"].unique())\n",
    "for b1, b2 in itertools.combinations(batch_sizes, 2):\n",
    "    acc1 = df[df[\"batch_size\"] == b1][\"val_acc\"]\n",
    "    acc2 = df[df[\"batch_size\"] == b2][\"val_acc\"]\n",
    "    loss1 = df[df[\"batch_size\"] == b1][\"val_loss\"]\n",
    "    loss2 = df[df[\"batch_size\"] == b2][\"val_loss\"]\n",
    "    \n",
    "    t_acc, p_acc = ttest_ind(acc1, acc2, equal_var=False)\n",
    "    t_loss, p_loss = ttest_ind(loss1, loss2, equal_var=False)\n",
    "    \n",
    "    print(f\"\\nBatch size {b1} vs {b2} (val_acc): t = {t_acc:.3f}, p = {p_acc:.3f}\")\n",
    "    print(f\"Batch size {b1} vs {b2} (val_loss): t = {t_loss:.3f}, p = {p_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcfccd8",
   "metadata": {},
   "source": [
    "These 2 hyperparameters are not the most influential ones, but given that they are discrete, it is easy to assess and compare them numerically. \n",
    "\n",
    "If we set an $\\alpha$ of 0.05 we can see that using a scheduler does not improve validation model accuracy significantly and actually increases validation model loss. This might due to the fact that most data-points lie around smaller learning rate values where having a learning rate scheduler doesn't give any advantages or can make learning too slow or even stop it.\n",
    "\n",
    "With the same alpha value, we can see that batch size does not provide any significant changes in accuracy or loss with one single exception when you compare a batch size of 64 with the batch size of 32, obtaining a lower loss with the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41aa93",
   "metadata": {},
   "source": [
    "\n",
    "4. Present your final chosen hyper-parameters for the DinoV2+MLP approach\n",
    "in a table and justify why you believe this set is optimal or near-optimal\n",
    "based on your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e51fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|          lr |   num_layers |   hidden_width |   batch_size | use_scheduler   |   best_val_loss |   trial_number |\n",
      "|------------:|-------------:|---------------:|-------------:|:----------------|----------------:|---------------:|\n",
      "| 0.000114988 |            3 |            384 |           32 | False           |        0.981338 |             82 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the best trial\n",
    "summary_path = \"runs/asha/study_summary.json\"\n",
    "with open(summary_path, \"r\") as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "# Extract hyper-parameters\n",
    "best_params = summary[\"params\"]\n",
    "best_params[\"best_val_loss\"] = summary.get(\"best_val_loss\", None)\n",
    "best_params[\"trial_number\"] = summary.get(\"trial_number\", None)\n",
    "\n",
    "df_best = pd.DataFrame([best_params])\n",
    "print(df_best.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e89006",
   "metadata": {},
   "source": [
    "The finding inferred from the graphs and metrics provided by the last 2 points support the model selected by the ASHA algorithm.\n",
    "- 1) The final learning rate lies around the zone of values where most dots are located (and also the best performing ones). \n",
    "- 2) The layers of size 384 appear in the graph as the ones that achieve the best performing range. In that specific region most dots are green, representing 3 layers\n",
    "- 3) For the batch size and the scheduler, the resulting parameters are coincidental with the ones with the best mean values. However there is not enough statistical power for statistical significancy. Future studies are needed with no trials and computing power.\n",
    "In general terms the winning trial is consistent with the findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
